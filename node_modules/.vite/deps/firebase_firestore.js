import {
  Component,
  LogLevel,
  Logger,
  SDK_VERSION,
  _getProvider,
  _registerComponent,
  _removeServiceInstance,
  createMockUserToken,
  getApp,
  getModularInstance,
  getUA,
  isBrowserExtension,
  isElectron,
  isIE,
  isMobileCordova,
  isReactNative,
  isUWP,
  registerVersion
} from "./chunk-RKOYCJEX.js";
import "./chunk-DFKQJ226.js";

// node_modules/@firebase/webchannel-wrapper/dist/index.esm.js
var extendStatics = function(d, b) {
  extendStatics = Object.setPrototypeOf || { __proto__: [] } instanceof Array && function(d2, b2) {
    d2.__proto__ = b2;
  } || function(d2, b2) {
    for (var p2 in b2)
      if (Object.prototype.hasOwnProperty.call(b2, p2))
        d2[p2] = b2[p2];
  };
  return extendStatics(d, b);
};
function __extends(d, b) {
  extendStatics(d, b);
  function __() {
    this.constructor = d;
  }
  d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
}
function __values(o) {
  var s = typeof Symbol === "function" && Symbol.iterator, m = s && o[s], i = 0;
  if (m)
    return m.call(o);
  if (o && typeof o.length === "number")
    return {
      next: function() {
        if (o && i >= o.length)
          o = void 0;
        return { value: o && o[i++], done: !o };
      }
    };
  throw new TypeError(s ? "Object is not iterable." : "Symbol.iterator is not defined.");
}
var commonjsGlobal = typeof globalThis !== "undefined" ? globalThis : typeof window !== "undefined" ? window : typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : {};
var g;
var goog = goog || {};
var k = commonjsGlobal || self;
function aa() {
}
function ba(a) {
  var b = typeof a;
  b = "object" != b ? b : a ? Array.isArray(a) ? "array" : b : "null";
  return "array" == b || "object" == b && "number" == typeof a.length;
}
function n(a) {
  var b = typeof a;
  return "object" == b && null != a || "function" == b;
}
function ca(a) {
  return Object.prototype.hasOwnProperty.call(a, da) && a[da] || (a[da] = ++ea);
}
var da = "closure_uid_" + (1e9 * Math.random() >>> 0);
var ea = 0;
function fa(a, b, c) {
  return a.call.apply(a.bind, arguments);
}
function ha(a, b, c) {
  if (!a)
    throw Error();
  if (2 < arguments.length) {
    var d = Array.prototype.slice.call(arguments, 2);
    return function() {
      var e = Array.prototype.slice.call(arguments);
      Array.prototype.unshift.apply(e, d);
      return a.apply(b, e);
    };
  }
  return function() {
    return a.apply(b, arguments);
  };
}
function p(a, b, c) {
  Function.prototype.bind && -1 != Function.prototype.bind.toString().indexOf("native code") ? p = fa : p = ha;
  return p.apply(null, arguments);
}
function ia(a, b) {
  var c = Array.prototype.slice.call(arguments, 1);
  return function() {
    var d = c.slice();
    d.push.apply(d, arguments);
    return a.apply(this, d);
  };
}
function q() {
  return Date.now();
}
function r(a, b) {
  function c() {
  }
  c.prototype = b.prototype;
  a.X = b.prototype;
  a.prototype = new c();
  a.prototype.constructor = a;
  a.Pb = function(d, e, f) {
    for (var h = Array(arguments.length - 2), m = 2; m < arguments.length; m++)
      h[m - 2] = arguments[m];
    return b.prototype[e].apply(d, h);
  };
}
function t() {
  this.j = this.j;
  this.i = this.i;
}
var ka = 0;
t.prototype.j = false;
t.prototype.ka = function() {
  if (!this.j && (this.j = true, this.H(), 0 != ka)) {
    var a = ca(this);
  }
};
t.prototype.H = function() {
  if (this.i)
    for (; this.i.length; )
      this.i.shift()();
};
var ma = Array.prototype.indexOf ? function(a, b) {
  return Array.prototype.indexOf.call(a, b, void 0);
} : function(a, b) {
  if ("string" === typeof a)
    return "string" !== typeof b || 1 != b.length ? -1 : a.indexOf(b, 0);
  for (var c = 0; c < a.length; c++)
    if (c in a && a[c] === b)
      return c;
  return -1;
};
var na = Array.prototype.forEach ? function(a, b, c) {
  Array.prototype.forEach.call(a, b, c);
} : function(a, b, c) {
  for (var d = a.length, e = "string" === typeof a ? a.split("") : a, f = 0; f < d; f++)
    f in e && b.call(c, e[f], f, a);
};
function oa(a) {
  a: {
    var b = pa;
    for (var c = a.length, d = "string" === typeof a ? a.split("") : a, e = 0; e < c; e++)
      if (e in d && b.call(void 0, d[e], e, a)) {
        b = e;
        break a;
      }
    b = -1;
  }
  return 0 > b ? null : "string" === typeof a ? a.charAt(b) : a[b];
}
function qa(a) {
  return Array.prototype.concat.apply([], arguments);
}
function ra(a) {
  var b = a.length;
  if (0 < b) {
    for (var c = Array(b), d = 0; d < b; d++)
      c[d] = a[d];
    return c;
  }
  return [];
}
function sa(a) {
  return /^[\s\xa0]*$/.test(a);
}
var ta = String.prototype.trim ? function(a) {
  return a.trim();
} : function(a) {
  return /^[\s\xa0]*([\s\S]*?)[\s\xa0]*$/.exec(a)[1];
};
function u(a, b) {
  return -1 != a.indexOf(b);
}
function ua(a, b) {
  return a < b ? -1 : a > b ? 1 : 0;
}
var w;
a: {
  va2 = k.navigator;
  if (va2) {
    wa2 = va2.userAgent;
    if (wa2) {
      w = wa2;
      break a;
    }
  }
  w = "";
}
var va2;
var wa2;
function xa(a, b, c) {
  for (var d in a)
    b.call(c, a[d], d, a);
}
function ya(a) {
  var b = {};
  for (var c in a)
    b[c] = a[c];
  return b;
}
var za = "constructor hasOwnProperty isPrototypeOf propertyIsEnumerable toLocaleString toString valueOf".split(" ");
function Ca(a, b) {
  var c, d;
  for (var e = 1; e < arguments.length; e++) {
    d = arguments[e];
    for (c in d)
      a[c] = d[c];
    for (var f = 0; f < za.length; f++)
      c = za[f], Object.prototype.hasOwnProperty.call(d, c) && (a[c] = d[c]);
  }
}
function Da(a) {
  Da[" "](a);
  return a;
}
Da[" "] = aa;
function Ea(a, b) {
  var c = Fa;
  return Object.prototype.hasOwnProperty.call(c, a) ? c[a] : c[a] = b(a);
}
var Ga = u(w, "Opera");
var x = u(w, "Trident") || u(w, "MSIE");
var Ha = u(w, "Edge");
var Ia = Ha || x;
var Ja = u(w, "Gecko") && !(u(w.toLowerCase(), "webkit") && !u(w, "Edge")) && !(u(w, "Trident") || u(w, "MSIE")) && !u(w, "Edge");
var Ka = u(w.toLowerCase(), "webkit") && !u(w, "Edge");
function La() {
  var a = k.document;
  return a ? a.documentMode : void 0;
}
var Ma;
a: {
  Na2 = "", Oa2 = function() {
    var a = w;
    if (Ja)
      return /rv:([^\);]+)(\)|;)/.exec(a);
    if (Ha)
      return /Edge\/([\d\.]+)/.exec(a);
    if (x)
      return /\b(?:MSIE|rv)[: ]([^\);]+)(\)|;)/.exec(a);
    if (Ka)
      return /WebKit\/(\S+)/.exec(a);
    if (Ga)
      return /(?:Version)[ \/]?(\S+)/.exec(a);
  }();
  Oa2 && (Na2 = Oa2 ? Oa2[1] : "");
  if (x) {
    Pa2 = La();
    if (null != Pa2 && Pa2 > parseFloat(Na2)) {
      Ma = String(Pa2);
      break a;
    }
  }
  Ma = Na2;
}
var Na2;
var Oa2;
var Pa2;
var Fa = {};
function Qa(a) {
  return Ea(a, function() {
    {
      var b = 0;
      var e = ta(String(Ma)).split("."), f = ta(String(a)).split("."), h = Math.max(e.length, f.length);
      for (var m = 0; 0 == b && m < h; m++) {
        var c = e[m] || "", d = f[m] || "";
        do {
          c = /(\d*)(\D*)(.*)/.exec(c) || ["", "", "", ""];
          d = /(\d*)(\D*)(.*)/.exec(d) || ["", "", "", ""];
          if (0 == c[0].length && 0 == d[0].length)
            break;
          b = ua(0 == c[1].length ? 0 : parseInt(c[1], 10), 0 == d[1].length ? 0 : parseInt(d[1], 10)) || ua(0 == c[2].length, 0 == d[2].length) || ua(c[2], d[2]);
          c = c[3];
          d = d[3];
        } while (0 == b);
      }
    }
    return 0 <= b;
  });
}
var Ra;
if (k.document && x) {
  Sa2 = La();
  Ra = Sa2 ? Sa2 : parseInt(Ma, 10) || void 0;
} else
  Ra = void 0;
var Sa2;
var Ta = Ra;
var Ua = !x || 9 <= Number(Ta);
var Va = x && !Qa("9");
var Wa = function() {
  if (!k.addEventListener || !Object.defineProperty)
    return false;
  var a = false, b = Object.defineProperty({}, "passive", { get: function() {
    a = true;
  } });
  try {
    k.addEventListener("test", aa, b), k.removeEventListener("test", aa, b);
  } catch (c) {
  }
  return a;
}();
function y(a, b) {
  this.type = a;
  this.a = this.target = b;
  this.defaultPrevented = false;
}
y.prototype.b = function() {
  this.defaultPrevented = true;
};
function z(a, b) {
  y.call(this, a ? a.type : "");
  this.relatedTarget = this.a = this.target = null;
  this.button = this.screenY = this.screenX = this.clientY = this.clientX = 0;
  this.key = "";
  this.metaKey = this.shiftKey = this.altKey = this.ctrlKey = false;
  this.pointerId = 0;
  this.pointerType = "";
  this.c = null;
  if (a) {
    var c = this.type = a.type, d = a.changedTouches && a.changedTouches.length ? a.changedTouches[0] : null;
    this.target = a.target || a.srcElement;
    this.a = b;
    if (b = a.relatedTarget) {
      if (Ja) {
        a: {
          try {
            Da(b.nodeName);
            var e = true;
            break a;
          } catch (f) {
          }
          e = false;
        }
        e || (b = null);
      }
    } else
      "mouseover" == c ? b = a.fromElement : "mouseout" == c && (b = a.toElement);
    this.relatedTarget = b;
    d ? (this.clientX = void 0 !== d.clientX ? d.clientX : d.pageX, this.clientY = void 0 !== d.clientY ? d.clientY : d.pageY, this.screenX = d.screenX || 0, this.screenY = d.screenY || 0) : (this.clientX = void 0 !== a.clientX ? a.clientX : a.pageX, this.clientY = void 0 !== a.clientY ? a.clientY : a.pageY, this.screenX = a.screenX || 0, this.screenY = a.screenY || 0);
    this.button = a.button;
    this.key = a.key || "";
    this.ctrlKey = a.ctrlKey;
    this.altKey = a.altKey;
    this.shiftKey = a.shiftKey;
    this.metaKey = a.metaKey;
    this.pointerId = a.pointerId || 0;
    this.pointerType = "string" === typeof a.pointerType ? a.pointerType : Xa[a.pointerType] || "";
    this.c = a;
    a.defaultPrevented && this.b();
  }
}
r(z, y);
var Xa = { 2: "touch", 3: "pen", 4: "mouse" };
z.prototype.b = function() {
  z.X.b.call(this);
  var a = this.c;
  if (a.preventDefault)
    a.preventDefault();
  else if (a.returnValue = false, Va)
    try {
      if (a.ctrlKey || 112 <= a.keyCode && 123 >= a.keyCode)
        a.keyCode = -1;
    } catch (b) {
    }
};
var A = "closure_listenable_" + (1e6 * Math.random() | 0);
var Ya = 0;
function Za(a, b, c, d, e) {
  this.listener = a;
  this.proxy = null;
  this.src = b;
  this.type = c;
  this.capture = !!d;
  this.da = e;
  this.key = ++Ya;
  this.Y = this.Z = false;
}
function $a(a) {
  a.Y = true;
  a.listener = null;
  a.proxy = null;
  a.src = null;
  a.da = null;
}
function ab(a) {
  this.src = a;
  this.a = {};
  this.b = 0;
}
ab.prototype.add = function(a, b, c, d, e) {
  var f = a.toString();
  a = this.a[f];
  a || (a = this.a[f] = [], this.b++);
  var h = bb(a, b, d, e);
  -1 < h ? (b = a[h], c || (b.Z = false)) : (b = new Za(b, this.src, f, !!d, e), b.Z = c, a.push(b));
  return b;
};
function cb(a, b) {
  var c = b.type;
  if (c in a.a) {
    var d = a.a[c], e = ma(d, b), f;
    (f = 0 <= e) && Array.prototype.splice.call(d, e, 1);
    f && ($a(b), 0 == a.a[c].length && (delete a.a[c], a.b--));
  }
}
function bb(a, b, c, d) {
  for (var e = 0; e < a.length; ++e) {
    var f = a[e];
    if (!f.Y && f.listener == b && f.capture == !!c && f.da == d)
      return e;
  }
  return -1;
}
var db = "closure_lm_" + (1e6 * Math.random() | 0);
var eb = {};
function gb(a, b, c, d, e) {
  if (d && d.once)
    return hb(a, b, c, d, e);
  if (Array.isArray(b)) {
    for (var f = 0; f < b.length; f++)
      gb(a, b[f], c, d, e);
    return null;
  }
  c = ib(c);
  return a && a[A] ? a.wa(b, c, n(d) ? !!d.capture : !!d, e) : jb(a, b, c, false, d, e);
}
function jb(a, b, c, d, e, f) {
  if (!b)
    throw Error("Invalid event type");
  var h = n(e) ? !!e.capture : !!e;
  if (h && !Ua)
    return null;
  var m = kb(a);
  m || (a[db] = m = new ab(a));
  c = m.add(b, c, d, h, f);
  if (c.proxy)
    return c;
  d = lb();
  c.proxy = d;
  d.src = a;
  d.listener = c;
  if (a.addEventListener)
    Wa || (e = h), void 0 === e && (e = false), a.addEventListener(b.toString(), d, e);
  else if (a.attachEvent)
    a.attachEvent(mb(b.toString()), d);
  else if (a.addListener && a.removeListener)
    a.addListener(d);
  else
    throw Error("addEventListener and attachEvent are unavailable.");
  return c;
}
function lb() {
  var a = nb, b = Ua ? function(c) {
    return a.call(b.src, b.listener, c);
  } : function(c) {
    c = a.call(b.src, b.listener, c);
    if (!c)
      return c;
  };
  return b;
}
function hb(a, b, c, d, e) {
  if (Array.isArray(b)) {
    for (var f = 0; f < b.length; f++)
      hb(a, b[f], c, d, e);
    return null;
  }
  c = ib(c);
  return a && a[A] ? a.xa(b, c, n(d) ? !!d.capture : !!d, e) : jb(a, b, c, true, d, e);
}
function ob(a, b, c, d, e) {
  if (Array.isArray(b))
    for (var f = 0; f < b.length; f++)
      ob(a, b[f], c, d, e);
  else
    (d = n(d) ? !!d.capture : !!d, c = ib(c), a && a[A]) ? (a = a.c, b = String(b).toString(), b in a.a && (f = a.a[b], c = bb(f, c, d, e), -1 < c && ($a(f[c]), Array.prototype.splice.call(f, c, 1), 0 == f.length && (delete a.a[b], a.b--)))) : a && (a = kb(a)) && (b = a.a[b.toString()], a = -1, b && (a = bb(b, c, d, e)), (c = -1 < a ? b[a] : null) && pb(c));
}
function pb(a) {
  if ("number" !== typeof a && a && !a.Y) {
    var b = a.src;
    if (b && b[A])
      cb(b.c, a);
    else {
      var c = a.type, d = a.proxy;
      b.removeEventListener ? b.removeEventListener(c, d, a.capture) : b.detachEvent ? b.detachEvent(mb(c), d) : b.addListener && b.removeListener && b.removeListener(d);
      (c = kb(b)) ? (cb(c, a), 0 == c.b && (c.src = null, b[db] = null)) : $a(a);
    }
  }
}
function mb(a) {
  return a in eb ? eb[a] : eb[a] = "on" + a;
}
function qb(a, b) {
  var c = a.listener, d = a.da || a.src;
  a.Z && pb(a);
  return c.call(d, b);
}
function nb(a, b) {
  if (a.Y)
    return true;
  if (!Ua) {
    if (!b)
      a: {
        b = ["window", "event"];
        for (var c = k, d = 0; d < b.length; d++)
          if (c = c[b[d]], null == c) {
            b = null;
            break a;
          }
        b = c;
      }
    b = new z(b, this);
    return qb(a, b);
  }
  return qb(a, new z(b, this));
}
function kb(a) {
  a = a[db];
  return a instanceof ab ? a : null;
}
var rb = "__closure_events_fn_" + (1e9 * Math.random() >>> 0);
function ib(a) {
  if ("function" === typeof a)
    return a;
  a[rb] || (a[rb] = function(b) {
    return a.handleEvent(b);
  });
  return a[rb];
}
function D() {
  t.call(this);
  this.c = new ab(this);
  this.J = this;
  this.D = null;
}
r(D, t);
D.prototype[A] = true;
g = D.prototype;
g.addEventListener = function(a, b, c, d) {
  gb(this, a, b, c, d);
};
g.removeEventListener = function(a, b, c, d) {
  ob(this, a, b, c, d);
};
function E(a, b) {
  var c, d = a.D;
  if (d)
    for (c = []; d; d = d.D)
      c.push(d);
  a = a.J;
  d = b.type || b;
  if ("string" === typeof b)
    b = new y(b, a);
  else if (b instanceof y)
    b.target = b.target || a;
  else {
    var e = b;
    b = new y(d, a);
    Ca(b, e);
  }
  e = true;
  if (c)
    for (var f = c.length - 1; 0 <= f; f--) {
      var h = b.a = c[f];
      e = sb(h, d, true, b) && e;
    }
  h = b.a = a;
  e = sb(h, d, true, b) && e;
  e = sb(h, d, false, b) && e;
  if (c)
    for (f = 0; f < c.length; f++)
      h = b.a = c[f], e = sb(h, d, false, b) && e;
}
g.H = function() {
  D.X.H.call(this);
  if (this.c) {
    var a = this.c, c;
    for (c in a.a) {
      for (var d = a.a[c], e = 0; e < d.length; e++)
        $a(d[e]);
      delete a.a[c];
      a.b--;
    }
  }
  this.D = null;
};
g.wa = function(a, b, c, d) {
  return this.c.add(String(a), b, false, c, d);
};
g.xa = function(a, b, c, d) {
  return this.c.add(String(a), b, true, c, d);
};
function sb(a, b, c, d) {
  b = a.c.a[String(b)];
  if (!b)
    return true;
  b = b.concat();
  for (var e = true, f = 0; f < b.length; ++f) {
    var h = b[f];
    if (h && !h.Y && h.capture == c) {
      var m = h.listener, l = h.da || h.src;
      h.Z && cb(a.c, h);
      e = false !== m.call(l, d) && e;
    }
  }
  return e && !d.defaultPrevented;
}
var tb = k.JSON.stringify;
function ub() {
  this.b = this.a = null;
}
var wb = new /** @class */
(function() {
  function class_1(a, b) {
    this.c = a;
    this.f = b;
    this.b = 0;
    this.a = null;
  }
  class_1.prototype.get = function() {
    var a;
    0 < this.b ? (this.b--, a = this.a, this.a = a.next, a.next = null) : a = this.c();
    return a;
  };
  return class_1;
}())(function() {
  return new vb();
}, function(a) {
  a.reset();
});
ub.prototype.add = function(a, b) {
  var c = wb.get();
  c.set(a, b);
  this.b ? this.b.next = c : this.a = c;
  this.b = c;
};
function xb() {
  var a = zb, b = null;
  a.a && (b = a.a, a.a = a.a.next, a.a || (a.b = null), b.next = null);
  return b;
}
function vb() {
  this.next = this.b = this.a = null;
}
vb.prototype.set = function(a, b) {
  this.a = a;
  this.b = b;
  this.next = null;
};
vb.prototype.reset = function() {
  this.next = this.b = this.a = null;
};
function Ab(a) {
  k.setTimeout(function() {
    throw a;
  }, 0);
}
function Bb(a, b) {
  Cb || Db();
  Eb || (Cb(), Eb = true);
  zb.add(a, b);
}
var Cb;
function Db() {
  var a = k.Promise.resolve(void 0);
  Cb = function() {
    a.then(Fb);
  };
}
var Eb = false;
var zb = new ub();
function Fb() {
  for (var a; a = xb(); ) {
    try {
      a.a.call(a.b);
    } catch (c) {
      Ab(c);
    }
    var b = wb;
    b.f(a);
    100 > b.b && (b.b++, a.next = b.a, b.a = a);
  }
  Eb = false;
}
function Gb(a, b) {
  D.call(this);
  this.b = a || 1;
  this.a = b || k;
  this.f = p(this.eb, this);
  this.g = q();
}
r(Gb, D);
g = Gb.prototype;
g.aa = false;
g.M = null;
g.eb = function() {
  if (this.aa) {
    var a = q() - this.g;
    0 < a && a < 0.8 * this.b ? this.M = this.a.setTimeout(this.f, this.b - a) : (this.M && (this.a.clearTimeout(this.M), this.M = null), E(this, "tick"), this.aa && (Hb(this), this.start()));
  }
};
g.start = function() {
  this.aa = true;
  this.M || (this.M = this.a.setTimeout(this.f, this.b), this.g = q());
};
function Hb(a) {
  a.aa = false;
  a.M && (a.a.clearTimeout(a.M), a.M = null);
}
g.H = function() {
  Gb.X.H.call(this);
  Hb(this);
  delete this.a;
};
function Ib(a, b, c) {
  if ("function" === typeof a)
    c && (a = p(a, c));
  else if (a && "function" == typeof a.handleEvent)
    a = p(a.handleEvent, a);
  else
    throw Error("Invalid listener argument");
  return 2147483647 < Number(b) ? -1 : k.setTimeout(a, b || 0);
}
function Jb(a) {
  a.a = Ib(function() {
    a.a = null;
    a.c && (a.c = false, Jb(a));
  }, a.h);
  var b = a.b;
  a.b = null;
  a.g.apply(null, b);
}
var Kb = (
  /** @class */
  function(_super) {
    __extends(Kb2, _super);
    function Kb2(a, b) {
      var _this = _super.call(this) || this;
      _this.g = a;
      _this.h = b;
      _this.b = null;
      _this.c = false;
      _this.a = null;
      return _this;
    }
    Kb2.prototype.f = function(a) {
      this.b = arguments;
      this.a ? this.c = true : Jb(this);
    };
    Kb2.prototype.H = function() {
      _super.prototype.H.call(this);
      this.a && (k.clearTimeout(this.a), this.a = null, this.c = false, this.b = null);
    };
    return Kb2;
  }(t)
);
function F(a) {
  t.call(this);
  this.b = a;
  this.a = {};
}
r(F, t);
var Lb = [];
function Mb(a, b, c, d) {
  Array.isArray(c) || (c && (Lb[0] = c.toString()), c = Lb);
  for (var e = 0; e < c.length; e++) {
    var f = gb(b, c[e], d || a.handleEvent, false, a.b || a);
    if (!f)
      break;
    a.a[f.key] = f;
  }
}
function Nb(a) {
  xa(a.a, function(b, c) {
    this.a.hasOwnProperty(c) && pb(b);
  }, a);
  a.a = {};
}
F.prototype.H = function() {
  F.X.H.call(this);
  Nb(this);
};
F.prototype.handleEvent = function() {
  throw Error("EventHandler.handleEvent not implemented");
};
function Ob() {
  this.a = true;
}
function Pb(a, b, c, d, e, f) {
  a.info(function() {
    if (a.a)
      if (f) {
        var h = "";
        for (var m = f.split("&"), l = 0; l < m.length; l++) {
          var v2 = m[l].split("=");
          if (1 < v2.length) {
            var C2 = v2[0];
            v2 = v2[1];
            var B2 = C2.split("_");
            h = 2 <= B2.length && "type" == B2[1] ? h + (C2 + "=" + v2 + "&") : h + (C2 + "=redacted&");
          }
        }
      } else
        h = null;
    else
      h = f;
    return "XMLHTTP REQ (" + d + ") [attempt " + e + "]: " + b + "\n" + c + "\n" + h;
  });
}
function Qb(a, b, c, d, e, f, h) {
  a.info(function() {
    return "XMLHTTP RESP (" + d + ") [ attempt " + e + "]: " + b + "\n" + c + "\n" + f + " " + h;
  });
}
function G(a, b, c, d) {
  a.info(function() {
    return "XMLHTTP TEXT (" + b + "): " + Rb(a, c) + (d ? " " + d : "");
  });
}
function Sb(a, b) {
  a.info(function() {
    return "TIMEOUT: " + b;
  });
}
Ob.prototype.info = function() {
};
function Rb(a, b) {
  if (!a.a)
    return b;
  if (!b)
    return null;
  try {
    var c = JSON.parse(b);
    if (c) {
      for (a = 0; a < c.length; a++)
        if (Array.isArray(c[a])) {
          var d = c[a];
          if (!(2 > d.length)) {
            var e = d[1];
            if (Array.isArray(e) && !(1 > e.length)) {
              var f = e[0];
              if ("noop" != f && "stop" != f && "close" != f)
                for (var h = 1; h < e.length; h++)
                  e[h] = "";
            }
          }
        }
    }
    return tb(c);
  } catch (m) {
    return b;
  }
}
var H = {};
var Tb = null;
function Ub() {
  return Tb = Tb || new D();
}
H.Ga = "serverreachability";
function Vb(a) {
  y.call(this, H.Ga, a);
}
r(Vb, y);
function I(a) {
  var b = Ub();
  E(b, new Vb(b, a));
}
H.STAT_EVENT = "statevent";
function Wb(a, b) {
  y.call(this, H.STAT_EVENT, a);
  this.stat = b;
}
r(Wb, y);
function J(a) {
  var b = Ub();
  E(b, new Wb(b, a));
}
H.Ha = "timingevent";
function Xb(a) {
  y.call(this, H.Ha, a);
}
r(Xb, y);
function K(a, b) {
  if ("function" !== typeof a)
    throw Error("Fn must not be null and must be a function");
  return k.setTimeout(function() {
    a();
  }, b);
}
var Yb = { NO_ERROR: 0, fb: 1, sb: 2, rb: 3, mb: 4, qb: 5, tb: 6, Ea: 7, TIMEOUT: 8, wb: 9 };
var Zb = { kb: "complete", Gb: "success", Fa: "error", Ea: "abort", yb: "ready", zb: "readystatechange", TIMEOUT: "timeout", ub: "incrementaldata", xb: "progress", nb: "downloadprogress", Ob: "uploadprogress" };
function $b() {
}
$b.prototype.b = null;
function ac(a) {
  return a.b || (a.b = a.c());
}
function bc() {
}
var L = { OPEN: "a", jb: "b", Fa: "c", vb: "d" };
function cc() {
  y.call(this, "d");
}
r(cc, y);
function dc() {
  y.call(this, "c");
}
r(dc, y);
var ec;
function fc() {
}
r(fc, $b);
fc.prototype.a = function() {
  return new XMLHttpRequest();
};
fc.prototype.c = function() {
  return {};
};
ec = new fc();
function M(a, b, c, d) {
  this.g = a;
  this.c = b;
  this.f = c;
  this.S = d || 1;
  this.J = new F(this);
  this.P = gc;
  a = Ia ? 125 : void 0;
  this.R = new Gb(a);
  this.B = null;
  this.b = false;
  this.j = this.l = this.i = this.G = this.u = this.T = this.o = null;
  this.s = [];
  this.a = null;
  this.D = 0;
  this.h = this.m = null;
  this.N = -1;
  this.A = false;
  this.O = 0;
  this.F = null;
  this.V = this.C = this.U = this.I = false;
}
var gc = 45e3;
var hc = {};
var ic = {};
g = M.prototype;
g.setTimeout = function(a) {
  this.P = a;
};
function jc(a, b, c) {
  a.G = 1;
  a.i = kc(N(b));
  a.j = c;
  a.I = true;
  lc(a, null);
}
function lc(a, b) {
  a.u = q();
  mc(a);
  a.l = N(a.i);
  var c = a.l, d = a.S;
  Array.isArray(d) || (d = [String(d)]);
  nc(c.b, "t", d);
  a.D = 0;
  a.a = oc(a.g, a.g.C ? b : null);
  0 < a.O && (a.F = new Kb(p(a.Da, a, a.a), a.O));
  Mb(a.J, a.a, "readystatechange", a.bb);
  b = a.B ? ya(a.B) : {};
  a.j ? (a.m || (a.m = "POST"), b["Content-Type"] = "application/x-www-form-urlencoded", a.a.ba(a.l, a.m, a.j, b)) : (a.m = "GET", a.a.ba(a.l, a.m, null, b));
  I(1);
  Pb(a.c, a.m, a.l, a.f, a.S, a.j);
}
g.bb = function(a) {
  a = a.target;
  var b = this.F;
  b && 3 == O(a) ? b.f() : this.Da(a);
};
g.Da = function(a) {
  try {
    if (a == this.a)
      a: {
        var b = O(this.a), c = this.a.va(), d = this.a.W();
        if (!(3 > b || 3 == b && !Ia && !this.a.$())) {
          this.A || 4 != b || 7 == c || (8 == c || 0 >= d ? I(3) : I(2));
          pc(this);
          var e = this.a.W();
          this.N = e;
          var f = this.a.$();
          this.b = 200 == e;
          Qb(this.c, this.m, this.l, this.f, this.S, b, e);
          if (this.b) {
            if (this.U && !this.C) {
              b: {
                if (this.a) {
                  var h, m = this.a;
                  if ((h = m.a ? m.a.getResponseHeader("X-HTTP-Initial-Response") : null) && !sa(h)) {
                    var l = h;
                    break b;
                  }
                }
                l = null;
              }
              if (l)
                G(this.c, this.f, l, "Initial handshake response via X-HTTP-Initial-Response"), this.C = true, qc(this, l);
              else {
                this.b = false;
                this.h = 3;
                J(12);
                P(this);
                rc(this);
                break a;
              }
            }
            this.I ? (sc(this, b, f), Ia && this.b && 3 == b && (Mb(this.J, this.R, "tick", this.ab), this.R.start())) : (G(this.c, this.f, f, null), qc(this, f));
            4 == b && P(this);
            this.b && !this.A && (4 == b ? tc(this.g, this) : (this.b = false, mc(this)));
          } else
            400 == e && 0 < f.indexOf("Unknown SID") ? (this.h = 3, J(12)) : (this.h = 0, J(13)), P(this), rc(this);
        }
      }
  } catch (v2) {
  } finally {
  }
};
function sc(a, b, c) {
  for (var d = true; !a.A && a.D < c.length; ) {
    var e = uc(a, c);
    if (e == ic) {
      4 == b && (a.h = 4, J(14), d = false);
      G(a.c, a.f, null, "[Incomplete Response]");
      break;
    } else if (e == hc) {
      a.h = 4;
      J(15);
      G(a.c, a.f, c, "[Invalid Chunk]");
      d = false;
      break;
    } else
      G(a.c, a.f, e, null), qc(a, e);
  }
  4 == b && 0 == c.length && (a.h = 1, J(16), d = false);
  a.b = a.b && d;
  d ? 0 < c.length && !a.V && (a.V = true, b = a.g, b.a == a && b.U && !b.F && (b.c.info("Great, no buffering proxy detected. Bytes received: " + c.length), vc(b), b.F = true, J(11))) : (G(a.c, a.f, c, "[Invalid Chunked Response]"), P(a), rc(a));
}
g.ab = function() {
  if (this.a) {
    var a = O(this.a), b = this.a.$();
    this.D < b.length && (pc(this), sc(this, a, b), this.b && 4 != a && mc(this));
  }
};
function uc(a, b) {
  var c = a.D, d = b.indexOf("\n", c);
  if (-1 == d)
    return ic;
  c = Number(b.substring(c, d));
  if (isNaN(c))
    return hc;
  d += 1;
  if (d + c > b.length)
    return ic;
  b = b.substr(d, c);
  a.D = d + c;
  return b;
}
g.cancel = function() {
  this.A = true;
  P(this);
};
function mc(a) {
  a.T = q() + a.P;
  wc(a, a.P);
}
function wc(a, b) {
  if (null != a.o)
    throw Error("WatchDog timer not null");
  a.o = K(p(a.$a, a), b);
}
function pc(a) {
  a.o && (k.clearTimeout(a.o), a.o = null);
}
g.$a = function() {
  this.o = null;
  var a = q();
  0 <= a - this.T ? (Sb(this.c, this.l), 2 != this.G && (I(3), J(17)), P(this), this.h = 2, rc(this)) : wc(this, this.T - a);
};
function rc(a) {
  0 == a.g.v || a.A || tc(a.g, a);
}
function P(a) {
  pc(a);
  var b = a.F;
  b && "function" == typeof b.ka && b.ka();
  a.F = null;
  Hb(a.R);
  Nb(a.J);
  a.a && (b = a.a, a.a = null, b.abort(), b.ka());
}
function qc(a, b) {
  try {
    var c = a.g;
    if (0 != c.v && (c.a == a || xc(c.b, a))) {
      if (c.I = a.N, !a.C && xc(c.b, a) && 3 == c.v) {
        try {
          var d = c.la.a.parse(b);
        } catch (yc2) {
          d = null;
        }
        if (Array.isArray(d) && 3 == d.length) {
          var e = d;
          if (0 == e[0])
            a: {
              if (!c.j) {
                if (c.a)
                  if (c.a.u + 3e3 < a.u)
                    zc(c), Ac(c);
                  else
                    break a;
                Bc(c);
                J(18);
              }
            }
          else
            c.pa = e[1], 0 < c.pa - c.P && 37500 > e[2] && c.G && 0 == c.o && !c.m && (c.m = K(p(c.Xa, c), 6e3));
          if (1 >= Dc(c.b) && c.fa) {
            try {
              c.fa();
            } catch (yc2) {
            }
            c.fa = void 0;
          }
        } else
          Q(c, 11);
      } else if ((a.C || c.a == a) && zc(c), !sa(b))
        for (b = d = c.la.a.parse(b), d = 0; d < b.length; d++)
          if (e = b[d], c.P = e[0], e = e[1], 2 == c.v)
            if ("c" == e[0]) {
              c.J = e[1];
              c.ha = e[2];
              var f = e[3];
              null != f && (c.ia = f, c.c.info("VER=" + c.ia));
              var h = e[4];
              null != h && (c.qa = h, c.c.info("SVER=" + c.qa));
              var m = e[5];
              if (null != m && "number" === typeof m && 0 < m) {
                var l = 1.5 * m;
                c.D = l;
                c.c.info("backChannelRequestTimeoutMs_=" + l);
              }
              l = c;
              var v2 = a.a;
              if (v2) {
                var C2 = v2.a ? v2.a.getResponseHeader("X-Client-Wire-Protocol") : null;
                if (C2) {
                  var B2 = l.b;
                  !B2.a && (u(C2, "spdy") || u(C2, "quic") || u(C2, "h2")) && (B2.f = B2.g, B2.a = /* @__PURE__ */ new Set(), B2.b && (Ec(B2, B2.b), B2.b = null));
                }
                if (l.A) {
                  var yb = v2.a ? v2.a.getResponseHeader("X-HTTP-Session-Id") : null;
                  yb && (l.oa = yb, R(l.B, l.A, yb));
                }
              }
              c.v = 3;
              c.f && c.f.ua();
              c.U && (c.N = q() - a.u, c.c.info("Handshake RTT: " + c.N + "ms"));
              l = c;
              var Aa2 = a;
              l.ma = Fc(l, l.C ? l.ha : null, l.ga);
              if (Aa2.C) {
                Gc(l.b, Aa2);
                var Ba2 = Aa2, Cc2 = l.D;
                Cc2 && Ba2.setTimeout(Cc2);
                Ba2.o && (pc(Ba2), mc(Ba2));
                l.a = Aa2;
              } else
                Hc(l);
              0 < c.g.length && Ic(c);
            } else
              "stop" != e[0] && "close" != e[0] || Q(c, 7);
          else
            3 == c.v && ("stop" == e[0] || "close" == e[0] ? "stop" == e[0] ? Q(c, 7) : Jc(c) : "noop" != e[0] && c.f && c.f.ta(e), c.o = 0);
    }
    I(4);
  } catch (yc2) {
  }
}
function Kc(a) {
  if (a.K && "function" == typeof a.K)
    return a.K();
  if ("string" === typeof a)
    return a.split("");
  if (ba(a)) {
    for (var b = [], c = a.length, d = 0; d < c; d++)
      b.push(a[d]);
    return b;
  }
  b = [];
  c = 0;
  for (d in a)
    b[c++] = a[d];
  return a = b;
}
function Lc(a, b) {
  if (a.forEach && "function" == typeof a.forEach)
    a.forEach(b, void 0);
  else if (ba(a) || "string" === typeof a)
    na(a, b, void 0);
  else {
    if (a.L && "function" == typeof a.L)
      var c = a.L();
    else if (a.K && "function" == typeof a.K)
      c = void 0;
    else if (ba(a) || "string" === typeof a) {
      c = [];
      for (var d = a.length, e = 0; e < d; e++)
        c.push(e);
    } else
      for (e in c = [], d = 0, a)
        c[d++] = e;
    d = Kc(a);
    e = d.length;
    for (var f = 0; f < e; f++)
      b.call(void 0, d[f], c && c[f], a);
  }
}
function S(a, b) {
  this.b = {};
  this.a = [];
  this.c = 0;
  var c = arguments.length;
  if (1 < c) {
    if (c % 2)
      throw Error("Uneven number of arguments");
    for (var d = 0; d < c; d += 2)
      this.set(arguments[d], arguments[d + 1]);
  } else if (a)
    if (a instanceof S)
      for (c = a.L(), d = 0; d < c.length; d++)
        this.set(c[d], a.get(c[d]));
    else
      for (d in a)
        this.set(d, a[d]);
}
g = S.prototype;
g.K = function() {
  Mc(this);
  for (var a = [], b = 0; b < this.a.length; b++)
    a.push(this.b[this.a[b]]);
  return a;
};
g.L = function() {
  Mc(this);
  return this.a.concat();
};
function Mc(a) {
  if (a.c != a.a.length) {
    for (var b = 0, c = 0; b < a.a.length; ) {
      var d = a.a[b];
      T(a.b, d) && (a.a[c++] = d);
      b++;
    }
    a.a.length = c;
  }
  if (a.c != a.a.length) {
    var e = {};
    for (c = b = 0; b < a.a.length; )
      d = a.a[b], T(e, d) || (a.a[c++] = d, e[d] = 1), b++;
    a.a.length = c;
  }
}
g.get = function(a, b) {
  return T(this.b, a) ? this.b[a] : b;
};
g.set = function(a, b) {
  T(this.b, a) || (this.c++, this.a.push(a));
  this.b[a] = b;
};
g.forEach = function(a, b) {
  for (var c = this.L(), d = 0; d < c.length; d++) {
    var e = c[d], f = this.get(e);
    a.call(b, f, e, this);
  }
};
function T(a, b) {
  return Object.prototype.hasOwnProperty.call(a, b);
}
var Nc = /^(?:([^:/?#.]+):)?(?:\/\/(?:([^\\/?#]*)@)?([^\\/?#]*?)(?::([0-9]+))?(?=[\\/?#]|$))?([^?#]+)?(?:\?([^#]*))?(?:#([\s\S]*))?$/;
function Oc(a, b) {
  if (a) {
    a = a.split("&");
    for (var c = 0; c < a.length; c++) {
      var d = a[c].indexOf("="), e = null;
      if (0 <= d) {
        var f = a[c].substring(0, d);
        e = a[c].substring(d + 1);
      } else
        f = a[c];
      b(f, e ? decodeURIComponent(e.replace(/\+/g, " ")) : "");
    }
  }
}
function U(a, b) {
  this.c = this.j = this.f = "";
  this.h = null;
  this.i = this.g = "";
  this.a = false;
  if (a instanceof U) {
    this.a = void 0 !== b ? b : a.a;
    Pc(this, a.f);
    this.j = a.j;
    Qc(this, a.c);
    Rc(this, a.h);
    this.g = a.g;
    b = a.b;
    var c = new Sc();
    c.c = b.c;
    b.a && (c.a = new S(b.a), c.b = b.b);
    Tc(this, c);
    this.i = a.i;
  } else
    a && (c = String(a).match(Nc)) ? (this.a = !!b, Pc(this, c[1] || "", true), this.j = Uc(c[2] || ""), Qc(this, c[3] || "", true), Rc(this, c[4]), this.g = Uc(c[5] || "", true), Tc(this, c[6] || "", true), this.i = Uc(c[7] || "")) : (this.a = !!b, this.b = new Sc(null, this.a));
}
U.prototype.toString = function() {
  var a = [], b = this.f;
  b && a.push(Vc(b, Wc, true), ":");
  var c = this.c;
  if (c || "file" == b)
    a.push("//"), (b = this.j) && a.push(Vc(b, Wc, true), "@"), a.push(encodeURIComponent(String(c)).replace(/%25([0-9a-fA-F]{2})/g, "%$1")), c = this.h, null != c && a.push(":", String(c));
  if (c = this.g)
    this.c && "/" != c.charAt(0) && a.push("/"), a.push(Vc(c, "/" == c.charAt(0) ? Xc : Yc, true));
  (c = this.b.toString()) && a.push("?", c);
  (c = this.i) && a.push("#", Vc(c, Zc));
  return a.join("");
};
function N(a) {
  return new U(a);
}
function Pc(a, b, c) {
  a.f = c ? Uc(b, true) : b;
  a.f && (a.f = a.f.replace(/:$/, ""));
}
function Qc(a, b, c) {
  a.c = c ? Uc(b, true) : b;
}
function Rc(a, b) {
  if (b) {
    b = Number(b);
    if (isNaN(b) || 0 > b)
      throw Error("Bad port number " + b);
    a.h = b;
  } else
    a.h = null;
}
function Tc(a, b, c) {
  b instanceof Sc ? (a.b = b, $c(a.b, a.a)) : (c || (b = Vc(b, ad)), a.b = new Sc(b, a.a));
}
function R(a, b, c) {
  a.b.set(b, c);
}
function kc(a) {
  R(a, "zx", Math.floor(2147483648 * Math.random()).toString(36) + Math.abs(Math.floor(2147483648 * Math.random()) ^ q()).toString(36));
  return a;
}
function bd(a) {
  return a instanceof U ? N(a) : new U(a, void 0);
}
function cd(a, b, c, d) {
  var e = new U(null, void 0);
  a && Pc(e, a);
  b && Qc(e, b);
  c && Rc(e, c);
  d && (e.g = d);
  return e;
}
function Uc(a, b) {
  return a ? b ? decodeURI(a.replace(/%25/g, "%2525")) : decodeURIComponent(a) : "";
}
function Vc(a, b, c) {
  return "string" === typeof a ? (a = encodeURI(a).replace(b, dd), c && (a = a.replace(/%25([0-9a-fA-F]{2})/g, "%$1")), a) : null;
}
function dd(a) {
  a = a.charCodeAt(0);
  return "%" + (a >> 4 & 15).toString(16) + (a & 15).toString(16);
}
var Wc = /[#\/\?@]/g;
var Yc = /[#\?:]/g;
var Xc = /[#\?]/g;
var ad = /[#\?@]/g;
var Zc = /#/g;
function Sc(a, b) {
  this.b = this.a = null;
  this.c = a || null;
  this.f = !!b;
}
function V(a) {
  a.a || (a.a = new S(), a.b = 0, a.c && Oc(a.c, function(b, c) {
    a.add(decodeURIComponent(b.replace(/\+/g, " ")), c);
  }));
}
g = Sc.prototype;
g.add = function(a, b) {
  V(this);
  this.c = null;
  a = W(this, a);
  var c = this.a.get(a);
  c || this.a.set(a, c = []);
  c.push(b);
  this.b += 1;
  return this;
};
function ed(a, b) {
  V(a);
  b = W(a, b);
  T(a.a.b, b) && (a.c = null, a.b -= a.a.get(b).length, a = a.a, T(a.b, b) && (delete a.b[b], a.c--, a.a.length > 2 * a.c && Mc(a)));
}
function fd(a, b) {
  V(a);
  b = W(a, b);
  return T(a.a.b, b);
}
g.forEach = function(a, b) {
  V(this);
  this.a.forEach(function(c, d) {
    na(c, function(e) {
      a.call(b, e, d, this);
    }, this);
  }, this);
};
g.L = function() {
  V(this);
  for (var a = this.a.K(), b = this.a.L(), c = [], d = 0; d < b.length; d++)
    for (var e = a[d], f = 0; f < e.length; f++)
      c.push(b[d]);
  return c;
};
g.K = function(a) {
  V(this);
  var b = [];
  if ("string" === typeof a)
    fd(this, a) && (b = qa(b, this.a.get(W(this, a))));
  else {
    a = this.a.K();
    for (var c = 0; c < a.length; c++)
      b = qa(b, a[c]);
  }
  return b;
};
g.set = function(a, b) {
  V(this);
  this.c = null;
  a = W(this, a);
  fd(this, a) && (this.b -= this.a.get(a).length);
  this.a.set(a, [b]);
  this.b += 1;
  return this;
};
g.get = function(a, b) {
  if (!a)
    return b;
  a = this.K(a);
  return 0 < a.length ? String(a[0]) : b;
};
function nc(a, b, c) {
  ed(a, b);
  0 < c.length && (a.c = null, a.a.set(W(a, b), ra(c)), a.b += c.length);
}
g.toString = function() {
  if (this.c)
    return this.c;
  if (!this.a)
    return "";
  for (var a = [], b = this.a.L(), c = 0; c < b.length; c++) {
    var d = b[c], e = encodeURIComponent(String(d));
    d = this.K(d);
    for (var f = 0; f < d.length; f++) {
      var h = e;
      "" !== d[f] && (h += "=" + encodeURIComponent(String(d[f])));
      a.push(h);
    }
  }
  return this.c = a.join("&");
};
function W(a, b) {
  b = String(b);
  a.f && (b = b.toLowerCase());
  return b;
}
function $c(a, b) {
  b && !a.f && (V(a), a.c = null, a.a.forEach(function(c, d) {
    var e = d.toLowerCase();
    d != e && (ed(this, d), nc(this, e, c));
  }, a));
  a.f = b;
}
var gd = (
  /** @class */
  function() {
    function gd2(a, b) {
      this.b = a;
      this.a = b;
    }
    return gd2;
  }()
);
function hd(a) {
  this.g = a || id;
  k.PerformanceNavigationTiming ? (a = k.performance.getEntriesByType("navigation"), a = 0 < a.length && ("hq" == a[0].nextHopProtocol || "h2" == a[0].nextHopProtocol)) : a = !!(k.ja && k.ja.za && k.ja.za() && k.ja.za().Qb);
  this.f = a ? this.g : 1;
  this.a = null;
  1 < this.f && (this.a = /* @__PURE__ */ new Set());
  this.b = null;
  this.c = [];
}
var id = 10;
function jd(a) {
  return a.b ? true : a.a ? a.a.size >= a.f : false;
}
function Dc(a) {
  return a.b ? 1 : a.a ? a.a.size : 0;
}
function xc(a, b) {
  return a.b ? a.b == b : a.a ? a.a.has(b) : false;
}
function Ec(a, b) {
  a.a ? a.a.add(b) : a.b = b;
}
function Gc(a, b) {
  a.b && a.b == b ? a.b = null : a.a && a.a.has(b) && a.a.delete(b);
}
hd.prototype.cancel = function() {
  var e_1, _a2;
  this.c = kd(this);
  if (this.b)
    this.b.cancel(), this.b = null;
  else if (this.a && 0 !== this.a.size) {
    try {
      for (var _b = __values(this.a.values()), _c2 = _b.next(); !_c2.done; _c2 = _b.next()) {
        var a = _c2.value;
        a.cancel();
      }
    } catch (e_1_1) {
      e_1 = { error: e_1_1 };
    } finally {
      try {
        if (_c2 && !_c2.done && (_a2 = _b.return))
          _a2.call(_b);
      } finally {
        if (e_1)
          throw e_1.error;
      }
    }
    this.a.clear();
  }
};
function kd(a) {
  var e_2, _a2;
  if (null != a.b)
    return a.c.concat(a.b.s);
  if (null != a.a && 0 !== a.a.size) {
    var b = a.c;
    try {
      for (var _b = __values(a.a.values()), _c2 = _b.next(); !_c2.done; _c2 = _b.next()) {
        var c = _c2.value;
        b = b.concat(c.s);
      }
    } catch (e_2_1) {
      e_2 = { error: e_2_1 };
    } finally {
      try {
        if (_c2 && !_c2.done && (_a2 = _b.return))
          _a2.call(_b);
      } finally {
        if (e_2)
          throw e_2.error;
      }
    }
    return b;
  }
  return ra(a.c);
}
function ld() {
}
ld.prototype.stringify = function(a) {
  return k.JSON.stringify(a, void 0);
};
ld.prototype.parse = function(a) {
  return k.JSON.parse(a, void 0);
};
function md() {
  this.a = new ld();
}
function nd(a, b, c) {
  var d = c || "";
  try {
    Lc(a, function(e, f) {
      var h = e;
      n(e) && (h = tb(e));
      b.push(d + f + "=" + encodeURIComponent(h));
    });
  } catch (e) {
    throw b.push(d + "type=" + encodeURIComponent("_badmap")), e;
  }
}
function od(a, b) {
  var c = new Ob();
  if (k.Image) {
    var d = new Image();
    d.onload = ia(pd, c, d, "TestLoadImage: loaded", true, b);
    d.onerror = ia(pd, c, d, "TestLoadImage: error", false, b);
    d.onabort = ia(pd, c, d, "TestLoadImage: abort", false, b);
    d.ontimeout = ia(pd, c, d, "TestLoadImage: timeout", false, b);
    k.setTimeout(function() {
      if (d.ontimeout)
        d.ontimeout();
    }, 1e4);
    d.src = a;
  } else
    b(false);
}
function pd(a, b, c, d, e) {
  try {
    b.onload = null, b.onerror = null, b.onabort = null, b.ontimeout = null, e(d);
  } catch (f) {
  }
}
var qd = k.JSON.parse;
function X(a) {
  D.call(this);
  this.headers = new S();
  this.l = a || null;
  this.b = false;
  this.u = this.a = null;
  this.C = "";
  this.h = 0;
  this.f = "";
  this.g = this.B = this.m = this.A = false;
  this.s = 0;
  this.o = null;
  this.I = rd;
  this.F = this.G = false;
}
r(X, D);
var rd = "";
var sd = /^https?$/i;
var td = ["POST", "PUT"];
g = X.prototype;
g.ba = function(a, b, c, d) {
  if (this.a)
    throw Error("[goog.net.XhrIo] Object is active with another request=" + this.C + "; newUri=" + a);
  b = b ? b.toUpperCase() : "GET";
  this.C = a;
  this.f = "";
  this.h = 0;
  this.A = false;
  this.b = true;
  this.a = this.l ? this.l.a() : ec.a();
  this.u = this.l ? ac(this.l) : ac(ec);
  this.a.onreadystatechange = p(this.Aa, this);
  try {
    this.B = true, this.a.open(b, String(a), true), this.B = false;
  } catch (f) {
    ud(this, f);
    return;
  }
  a = c || "";
  var e = new S(this.headers);
  d && Lc(d, function(f, h) {
    e.set(h, f);
  });
  d = oa(e.L());
  c = k.FormData && a instanceof k.FormData;
  !(0 <= ma(td, b)) || d || c || e.set("Content-Type", "application/x-www-form-urlencoded;charset=utf-8");
  e.forEach(function(f, h) {
    this.a.setRequestHeader(h, f);
  }, this);
  this.I && (this.a.responseType = this.I);
  "withCredentials" in this.a && this.a.withCredentials !== this.G && (this.a.withCredentials = this.G);
  try {
    vd(this), 0 < this.s && ((this.F = wd(this.a)) ? (this.a.timeout = this.s, this.a.ontimeout = p(this.ya, this)) : this.o = Ib(this.ya, this.s, this)), this.m = true, this.a.send(a), this.m = false;
  } catch (f) {
    ud(this, f);
  }
};
function wd(a) {
  return x && Qa(9) && "number" === typeof a.timeout && void 0 !== a.ontimeout;
}
function pa(a) {
  return "content-type" == a.toLowerCase();
}
g.ya = function() {
  "undefined" != typeof goog && this.a && (this.f = "Timed out after " + this.s + "ms, aborting", this.h = 8, E(this, "timeout"), this.abort(8));
};
function ud(a, b) {
  a.b = false;
  a.a && (a.g = true, a.a.abort(), a.g = false);
  a.f = b;
  a.h = 5;
  xd(a);
  yd(a);
}
function xd(a) {
  a.A || (a.A = true, E(a, "complete"), E(a, "error"));
}
g.abort = function(a) {
  this.a && this.b && (this.b = false, this.g = true, this.a.abort(), this.g = false, this.h = a || 7, E(this, "complete"), E(this, "abort"), yd(this));
};
g.H = function() {
  this.a && (this.b && (this.b = false, this.g = true, this.a.abort(), this.g = false), yd(this, true));
  X.X.H.call(this);
};
g.Aa = function() {
  this.j || (this.B || this.m || this.g ? zd(this) : this.Za());
};
g.Za = function() {
  zd(this);
};
function zd(a) {
  if (a.b && "undefined" != typeof goog && (!a.u[1] || 4 != O(a) || 2 != a.W())) {
    if (a.m && 4 == O(a))
      Ib(a.Aa, 0, a);
    else if (E(a, "readystatechange"), 4 == O(a)) {
      a.b = false;
      try {
        {
          var l = a.W();
          a:
            switch (l) {
              case 200:
              case 201:
              case 202:
              case 204:
              case 206:
              case 304:
              case 1223:
                var b = true;
                break a;
              default:
                b = false;
            }
          var c;
          if (!(c = b)) {
            var d;
            if (d = 0 === l) {
              var e = String(a.C).match(Nc)[1] || null;
              if (!e && k.self && k.self.location) {
                var f = k.self.location.protocol;
                e = f.substr(0, f.length - 1);
              }
              d = !sd.test(e ? e.toLowerCase() : "");
            }
            c = d;
          }
          var h = c;
        }
        if (h)
          E(a, "complete"), E(a, "success");
        else {
          a.h = 6;
          try {
            var m = 2 < O(a) ? a.a.statusText : "";
          } catch (l2) {
            m = "";
          }
          a.f = m + " [" + a.W() + "]";
          xd(a);
        }
      } finally {
        yd(a);
      }
    }
  }
}
function yd(a, b) {
  if (a.a) {
    vd(a);
    var c = a.a, d = a.u[0] ? aa : null;
    a.a = null;
    a.u = null;
    b || E(a, "ready");
    try {
      c.onreadystatechange = d;
    } catch (e) {
    }
  }
}
function vd(a) {
  a.a && a.F && (a.a.ontimeout = null);
  a.o && (k.clearTimeout(a.o), a.o = null);
}
function O(a) {
  return a.a ? a.a.readyState : 0;
}
g.W = function() {
  try {
    return 2 < O(this) ? this.a.status : -1;
  } catch (a) {
    return -1;
  }
};
g.$ = function() {
  try {
    return this.a ? this.a.responseText : "";
  } catch (a) {
    return "";
  }
};
g.Qa = function(a) {
  if (this.a) {
    var b = this.a.responseText;
    a && 0 == b.indexOf(a) && (b = b.substring(a.length));
    return qd(b);
  }
};
g.va = function() {
  return this.h;
};
g.Ra = function() {
  return "string" === typeof this.f ? this.f : String(this.f);
};
function Ad(a) {
  var b = "";
  xa(a, function(c, d) {
    b += d;
    b += ":";
    b += c;
    b += "\r\n";
  });
  return b;
}
function Bd(a, b, c) {
  a: {
    for (d in c) {
      var d = false;
      break a;
    }
    d = true;
  }
  d || (c = Ad(c), "string" === typeof a ? null != c && encodeURIComponent(String(c)) : R(a, b, c));
}
function Cd(a, b, c) {
  return c && c.internalChannelParams ? c.internalChannelParams[a] || b : b;
}
function Dd(a) {
  this.qa = 0;
  this.g = [];
  this.c = new Ob();
  this.ha = this.ma = this.B = this.ga = this.a = this.oa = this.A = this.V = this.i = this.O = this.l = null;
  this.Pa = this.R = 0;
  this.Ma = Cd("failFast", false, a);
  this.G = this.m = this.j = this.h = this.f = null;
  this.S = true;
  this.I = this.pa = this.P = -1;
  this.T = this.o = this.u = 0;
  this.Ia = Cd("baseRetryDelayMs", 5e3, a);
  this.Sa = Cd("retryDelaySeedMs", 1e4, a);
  this.Na = Cd("forwardChannelMaxRetries", 2, a);
  this.na = Cd("forwardChannelRequestTimeoutMs", 2e4, a);
  this.Oa = a && a.xmlHttpFactory || void 0;
  this.D = void 0;
  this.C = a && a.supportsCrossDomainXhr || false;
  this.J = "";
  this.b = new hd(a && a.concurrentRequestLimit);
  this.la = new md();
  this.ea = a && a.fastHandshake || false;
  this.Ja = a && a.b || false;
  a && a.f && (this.c.a = false);
  a && a.forceLongPolling && (this.S = false);
  this.U = !this.ea && this.S && a && a.detectBufferingProxy || false;
  this.fa = void 0;
  this.N = 0;
  this.F = false;
  this.s = null;
  (this.La = a && a.c || false) && this.c.info("Opt-in to enable Chrome Origin Trials.");
}
g = Dd.prototype;
g.ia = 8;
g.v = 1;
function Jc(a) {
  Ed(a);
  if (3 == a.v) {
    var b = a.R++, c = N(a.B);
    R(c, "SID", a.J);
    R(c, "RID", b);
    R(c, "TYPE", "terminate");
    Fd(a, c);
    b = new M(a, a.c, b, void 0);
    b.G = 2;
    b.i = kc(N(c));
    c = false;
    k.navigator && k.navigator.sendBeacon && (c = k.navigator.sendBeacon(b.i.toString(), ""));
    !c && k.Image && (new Image().src = b.i, c = true);
    c || (b.a = oc(b.g, null), b.a.ba(b.i));
    b.u = q();
    mc(b);
  }
  Gd(a);
}
function Ac(a) {
  a.a && (vc(a), a.a.cancel(), a.a = null);
}
function Ed(a) {
  Ac(a);
  a.j && (k.clearTimeout(a.j), a.j = null);
  zc(a);
  a.b.cancel();
  a.h && ("number" === typeof a.h && k.clearTimeout(a.h), a.h = null);
}
function Hd(a, b) {
  a.g.push(new gd(a.Pa++, b));
  3 == a.v && Ic(a);
}
function Ic(a) {
  jd(a.b) || a.h || (a.h = true, Bb(a.Ca, a), a.u = 0);
}
function Id(a, b) {
  if (Dc(a.b) >= a.b.f - (a.h ? 1 : 0))
    return false;
  if (a.h)
    return a.g = b.s.concat(a.g), true;
  if (1 == a.v || 2 == a.v || a.u >= (a.Ma ? 0 : a.Na))
    return false;
  a.h = K(p(a.Ca, a, b), Jd(a, a.u));
  a.u++;
  return true;
}
g.Ca = function(a) {
  if (this.h)
    if (this.h = null, 1 == this.v) {
      if (!a) {
        this.R = Math.floor(1e5 * Math.random());
        a = this.R++;
        var b = new M(this, this.c, a, void 0), c = this.l;
        this.O && (c ? (c = ya(c), Ca(c, this.O)) : c = this.O);
        null === this.i && (b.B = c);
        var d;
        if (this.ea)
          a: {
            for (var e = d = 0; e < this.g.length; e++) {
              b: {
                var f = this.g[e];
                if ("__data__" in f.a && (f = f.a.__data__, "string" === typeof f)) {
                  f = f.length;
                  break b;
                }
                f = void 0;
              }
              if (void 0 === f)
                break;
              d += f;
              if (4096 < d) {
                d = e;
                break a;
              }
              if (4096 === d || e === this.g.length - 1) {
                d = e + 1;
                break a;
              }
            }
            d = 1e3;
          }
        else
          d = 1e3;
        d = Kd(this, b, d);
        e = N(this.B);
        R(e, "RID", a);
        R(e, "CVER", 22);
        this.A && R(e, "X-HTTP-Session-Id", this.A);
        Fd(this, e);
        this.i && c && Bd(e, this.i, c);
        Ec(this.b, b);
        this.Ja && R(e, "TYPE", "init");
        this.ea ? (R(e, "$req", d), R(e, "SID", "null"), b.U = true, jc(b, e, null)) : jc(b, e, d);
        this.v = 2;
      }
    } else
      3 == this.v && (a ? Ld(this, a) : 0 == this.g.length || jd(this.b) || Ld(this));
};
function Ld(a, b) {
  var c;
  b ? c = b.f : c = a.R++;
  var d = N(a.B);
  R(d, "SID", a.J);
  R(d, "RID", c);
  R(d, "AID", a.P);
  Fd(a, d);
  a.i && a.l && Bd(d, a.i, a.l);
  c = new M(a, a.c, c, a.u + 1);
  null === a.i && (c.B = a.l);
  b && (a.g = b.s.concat(a.g));
  b = Kd(a, c, 1e3);
  c.setTimeout(Math.round(0.5 * a.na) + Math.round(0.5 * a.na * Math.random()));
  Ec(a.b, c);
  jc(c, d, b);
}
function Fd(a, b) {
  a.f && Lc({}, function(c, d) {
    R(b, d, c);
  });
}
function Kd(a, b, c) {
  c = Math.min(a.g.length, c);
  var d = a.f ? p(a.f.Ka, a.f, a) : null;
  a:
    for (var e = a.g, f = -1; ; ) {
      var h = ["count=" + c];
      -1 == f ? 0 < c ? (f = e[0].b, h.push("ofs=" + f)) : f = 0 : h.push("ofs=" + f);
      for (var m = true, l = 0; l < c; l++) {
        var v2 = e[l].b, C2 = e[l].a;
        v2 -= f;
        if (0 > v2)
          f = Math.max(0, e[l].b - 100), m = false;
        else
          try {
            nd(C2, h, "req" + v2 + "_");
          } catch (B2) {
            d && d(C2);
          }
      }
      if (m) {
        d = h.join("&");
        break a;
      }
    }
  a = a.g.splice(0, c);
  b.s = a;
  return d;
}
function Hc(a) {
  a.a || a.j || (a.T = 1, Bb(a.Ba, a), a.o = 0);
}
function Bc(a) {
  if (a.a || a.j || 3 <= a.o)
    return false;
  a.T++;
  a.j = K(p(a.Ba, a), Jd(a, a.o));
  a.o++;
  return true;
}
g.Ba = function() {
  this.j = null;
  Md(this);
  if (this.U && !(this.F || null == this.a || 0 >= this.N)) {
    var a = 2 * this.N;
    this.c.info("BP detection timer enabled: " + a);
    this.s = K(p(this.Ya, this), a);
  }
};
g.Ya = function() {
  this.s && (this.s = null, this.c.info("BP detection timeout reached."), this.c.info("Buffering proxy detected and switch to long-polling!"), this.G = false, this.F = true, J(10), Ac(this), Md(this));
};
function vc(a) {
  null != a.s && (k.clearTimeout(a.s), a.s = null);
}
function Md(a) {
  a.a = new M(a, a.c, "rpc", a.T);
  null === a.i && (a.a.B = a.l);
  a.a.O = 0;
  var b = N(a.ma);
  R(b, "RID", "rpc");
  R(b, "SID", a.J);
  R(b, "CI", a.G ? "0" : "1");
  R(b, "AID", a.P);
  Fd(a, b);
  R(b, "TYPE", "xmlhttp");
  a.i && a.l && Bd(b, a.i, a.l);
  a.D && a.a.setTimeout(a.D);
  var c = a.a;
  a = a.ha;
  c.G = 1;
  c.i = kc(N(b));
  c.j = null;
  c.I = true;
  lc(c, a);
}
g.Xa = function() {
  null != this.m && (this.m = null, Ac(this), Bc(this), J(19));
};
function zc(a) {
  null != a.m && (k.clearTimeout(a.m), a.m = null);
}
function tc(a, b) {
  var c = null;
  if (a.a == b) {
    zc(a);
    vc(a);
    a.a = null;
    var d = 2;
  } else if (xc(a.b, b))
    c = b.s, Gc(a.b, b), d = 1;
  else
    return;
  a.I = b.N;
  if (0 != a.v) {
    if (b.b)
      if (1 == d) {
        c = b.j ? b.j.length : 0;
        b = q() - b.u;
        var e = a.u;
        d = Ub();
        E(d, new Xb(d, c, b, e));
        Ic(a);
      } else
        Hc(a);
    else if (e = b.h, 3 == e || 0 == e && 0 < a.I || !(1 == d && Id(a, b) || 2 == d && Bc(a)))
      switch (c && 0 < c.length && (b = a.b, b.c = b.c.concat(c)), e) {
        case 1:
          Q(a, 5);
          break;
        case 4:
          Q(a, 10);
          break;
        case 3:
          Q(a, 6);
          break;
        default:
          Q(a, 2);
      }
  }
}
function Jd(a, b) {
  var c = a.Ia + Math.floor(Math.random() * a.Sa);
  a.f || (c *= 2);
  return c * b;
}
function Q(a, b) {
  a.c.info("Error code " + b);
  if (2 == b) {
    var c = null;
    a.f && (c = null);
    var d = p(a.cb, a);
    c || (c = new U("//www.google.com/images/cleardot.gif"), k.location && "http" == k.location.protocol || Pc(c, "https"), kc(c));
    od(c.toString(), d);
  } else
    J(2);
  a.v = 0;
  a.f && a.f.sa(b);
  Gd(a);
  Ed(a);
}
g.cb = function(a) {
  a ? (this.c.info("Successfully pinged google.com"), J(2)) : (this.c.info("Failed to ping google.com"), J(1));
};
function Gd(a) {
  a.v = 0;
  a.I = -1;
  if (a.f) {
    if (0 != kd(a.b).length || 0 != a.g.length)
      a.b.c.length = 0, ra(a.g), a.g.length = 0;
    a.f.ra();
  }
}
function Fc(a, b, c) {
  var d = bd(c);
  if ("" != d.c)
    b && Qc(d, b + "." + d.c), Rc(d, d.h);
  else {
    var e = k.location;
    d = cd(e.protocol, b ? b + "." + e.hostname : e.hostname, +e.port, c);
  }
  a.V && xa(a.V, function(f, h) {
    R(d, h, f);
  });
  b = a.A;
  c = a.oa;
  b && c && R(d, b, c);
  R(d, "VER", a.ia);
  Fd(a, d);
  return d;
}
function oc(a, b) {
  if (b && !a.C)
    throw Error("Can't create secondary domain capable XhrIo object.");
  b = new X(a.Oa);
  b.G = a.C;
  return b;
}
function Nd() {
}
g = Nd.prototype;
g.ua = function() {
};
g.ta = function() {
};
g.sa = function() {
};
g.ra = function() {
};
g.Ka = function() {
};
function Od() {
  if (x && !(10 <= Number(Ta)))
    throw Error("Environmental error: no available transport.");
}
Od.prototype.a = function(a, b) {
  return new Y(a, b);
};
function Y(a, b) {
  D.call(this);
  this.a = new Dd(b);
  this.g = a;
  this.b = b && b.messageUrlParams || null;
  a = b && b.messageHeaders || null;
  b && b.clientProtocolHeaderRequired && (a ? a["X-Client-Protocol"] = "webchannel" : a = { "X-Client-Protocol": "webchannel" });
  this.a.l = a;
  a = b && b.initMessageHeaders || null;
  b && b.messageContentType && (a ? a["X-WebChannel-Content-Type"] = b.messageContentType : a = { "X-WebChannel-Content-Type": b.messageContentType });
  b && b.a && (a ? a["X-WebChannel-Client-Profile"] = b.a : a = { "X-WebChannel-Client-Profile": b.a });
  this.a.O = a;
  (a = b && b.httpHeadersOverwriteParam) && !sa(a) && (this.a.i = a);
  this.o = b && b.supportsCrossDomainXhr || false;
  this.m = b && b.sendRawJson || false;
  (b = b && b.httpSessionIdParam) && !sa(b) && (this.a.A = b, a = this.b, null !== a && b in a && (a = this.b, b in a && delete a[b]));
  this.f = new Z(this);
}
r(Y, D);
Y.prototype.h = function() {
  this.a.f = this.f;
  this.o && (this.a.C = true);
  var a = this.a, b = this.g, c = this.b || void 0;
  J(0);
  a.ga = b;
  a.V = c || {};
  a.G = a.S;
  a.B = Fc(a, null, a.ga);
  Ic(a);
};
Y.prototype.close = function() {
  Jc(this.a);
};
Y.prototype.l = function(a) {
  if ("string" === typeof a) {
    var b = {};
    b.__data__ = a;
    Hd(this.a, b);
  } else
    this.m ? (b = {}, b.__data__ = tb(a), Hd(this.a, b)) : Hd(this.a, a);
};
Y.prototype.H = function() {
  this.a.f = null;
  delete this.f;
  Jc(this.a);
  delete this.a;
  Y.X.H.call(this);
};
function Pd(a) {
  cc.call(this);
  var b = a.__sm__;
  if (b) {
    a: {
      for (var c in b) {
        a = c;
        break a;
      }
      a = void 0;
    }
    (this.c = a) ? (a = this.c, this.data = null !== b && a in b ? b[a] : void 0) : this.data = b;
  } else
    this.data = a;
}
r(Pd, cc);
function Qd() {
  dc.call(this);
  this.status = 1;
}
r(Qd, dc);
function Z(a) {
  this.a = a;
}
r(Z, Nd);
Z.prototype.ua = function() {
  E(this.a, "a");
};
Z.prototype.ta = function(a) {
  E(this.a, new Pd(a));
};
Z.prototype.sa = function(a) {
  E(this.a, new Qd(a));
};
Z.prototype.ra = function() {
  E(this.a, "b");
};
function Rd(a) {
  this.f = a;
}
r(Rd, $b);
Rd.prototype.a = function() {
  return new Sd(this.f);
};
Rd.prototype.c = function(a) {
  return function() {
    return a;
  };
}({});
function Sd(a) {
  D.call(this);
  this.u = a;
  this.h = void 0;
  this.readyState = Td;
  this.status = 0;
  this.responseType = this.responseText = this.statusText = "";
  this.onreadystatechange = null;
  this.l = new Headers();
  this.b = null;
  this.s = "GET";
  this.o = "";
  this.a = false;
  this.m = this.f = this.g = null;
}
r(Sd, D);
var Td = 0;
g = Sd.prototype;
g.open = function(a, b) {
  if (this.readyState != Td)
    throw this.abort(), Error("Error reopening a connection");
  this.s = a;
  this.o = b;
  this.readyState = 1;
  Ud(this);
};
g.send = function(a) {
  if (1 != this.readyState)
    throw this.abort(), Error("need to call open() first. ");
  this.a = true;
  var b = { headers: this.l, method: this.s, credentials: this.h, cache: void 0 };
  a && (b.body = a);
  this.u.fetch(new Request(this.o, b)).then(this.Wa.bind(this), this.ca.bind(this));
};
g.abort = function() {
  this.responseText = "";
  this.l = new Headers();
  this.status = 0;
  this.f && this.f.cancel("Request was aborted.");
  1 <= this.readyState && this.a && 4 != this.readyState && (this.a = false, Vd(this));
  this.readyState = Td;
};
g.Wa = function(a) {
  this.a && (this.g = a, this.b || (this.status = this.g.status, this.statusText = this.g.statusText, this.b = a.headers, this.readyState = 2, Ud(this)), this.a && (this.readyState = 3, Ud(this), this.a && ("arraybuffer" === this.responseType ? a.arrayBuffer().then(this.Ua.bind(this), this.ca.bind(this)) : "undefined" !== typeof k.ReadableStream && "body" in a ? (this.responseText = "", this.f = a.body.getReader(), this.m = new TextDecoder(), Wd(this)) : a.text().then(this.Va.bind(this), this.ca.bind(this)))));
};
function Wd(a) {
  a.f.read().then(a.Ta.bind(a)).catch(a.ca.bind(a));
}
g.Ta = function(a) {
  if (this.a) {
    var b = this.m.decode(a.value ? a.value : new Uint8Array(0), { stream: !a.done });
    b && (this.responseText += b);
    a.done ? Vd(this) : Ud(this);
    3 == this.readyState && Wd(this);
  }
};
g.Va = function(a) {
  this.a && (this.responseText = a, Vd(this));
};
g.Ua = function() {
  this.a && Vd(this);
};
g.ca = function() {
  this.a && Vd(this);
};
function Vd(a) {
  a.readyState = 4;
  a.g = null;
  a.f = null;
  a.m = null;
  Ud(a);
}
g.setRequestHeader = function(a, b) {
  this.l.append(a, b);
};
g.getResponseHeader = function(a) {
  return this.b ? this.b.get(a.toLowerCase()) || "" : "";
};
g.getAllResponseHeaders = function() {
  if (!this.b)
    return "";
  var a = [], b = this.b.entries();
  for (var c = b.next(); !c.done; )
    c = c.value, a.push(c[0] + ": " + c[1]), c = b.next();
  return a.join("\r\n");
};
function Ud(a) {
  a.onreadystatechange && a.onreadystatechange.call(a);
}
Object.defineProperty(Sd.prototype, "withCredentials", { get: function() {
  return "include" === this.h;
}, set: function(a) {
  this.h = a ? "include" : "same-origin";
} });
Od.prototype.createWebChannel = Od.prototype.a;
Y.prototype.send = Y.prototype.l;
Y.prototype.open = Y.prototype.h;
Y.prototype.close = Y.prototype.close;
Yb.NO_ERROR = 0;
Yb.TIMEOUT = 8;
Yb.HTTP_ERROR = 6;
Zb.COMPLETE = "complete";
bc.EventType = L;
L.OPEN = "a";
L.CLOSE = "b";
L.ERROR = "c";
L.MESSAGE = "d";
D.prototype.listen = D.prototype.wa;
X.prototype.listenOnce = X.prototype.xa;
X.prototype.getLastError = X.prototype.Ra;
X.prototype.getLastErrorCode = X.prototype.va;
X.prototype.getStatus = X.prototype.W;
X.prototype.getResponseJson = X.prototype.Qa;
X.prototype.getResponseText = X.prototype.$;
X.prototype.send = X.prototype.ba;
var createWebChannelTransport = function() {
  return new Od();
};
var getStatEventTarget = function() {
  return Ub();
};
var ErrorCode = Yb;
var EventType = Zb;
var Event = H;
var Stat = { lb: 0, ob: 1, pb: 2, Ib: 3, Nb: 4, Kb: 5, Lb: 6, Jb: 7, Hb: 8, Mb: 9, PROXY: 10, NOPROXY: 11, Fb: 12, Bb: 13, Cb: 14, Ab: 15, Db: 16, Eb: 17, hb: 18, gb: 19, ib: 20 };
var FetchXmlHttpFactory = Rd;
var WebChannel = bc;
var XhrIo = X;

// node_modules/@firebase/firestore/dist/exp/index.browser.esm2017.js
var v = "8.6.8";
var V2 = class {
  constructor(t2, e) {
    this.previousValue = t2, e && (e.sequenceNumberHandler = (t3) => this.t(t3), this.i = (t3) => e.writeSequenceNumber(t3));
  }
  t(t2) {
    return this.previousValue = Math.max(t2, this.previousValue), this.previousValue;
  }
  next() {
    const t2 = ++this.previousValue;
    return this.i && this.i(t2), t2;
  }
};
V2.o = -1;
var S2 = {
  // Causes are copied from:
  // https://github.com/grpc/grpc/blob/bceec94ea4fc5f0085d81235d8e1c06798dc341a/include/grpc%2B%2B/impl/codegen/status_code_enum.h
  /** Not an error; returned on success. */
  OK: "ok",
  /** The operation was cancelled (typically by the caller). */
  CANCELLED: "cancelled",
  /** Unknown error or an error from a different error domain. */
  UNKNOWN: "unknown",
  /**
   * Client specified an invalid argument. Note that this differs from
   * FAILED_PRECONDITION. INVALID_ARGUMENT indicates arguments that are
   * problematic regardless of the state of the system (e.g., a malformed file
   * name).
   */
  INVALID_ARGUMENT: "invalid-argument",
  /**
   * Deadline expired before operation could complete. For operations that
   * change the state of the system, this error may be returned even if the
   * operation has completed successfully. For example, a successful response
   * from a server could have been delayed long enough for the deadline to
   * expire.
   */
  DEADLINE_EXCEEDED: "deadline-exceeded",
  /** Some requested entity (e.g., file or directory) was not found. */
  NOT_FOUND: "not-found",
  /**
   * Some entity that we attempted to create (e.g., file or directory) already
   * exists.
   */
  ALREADY_EXISTS: "already-exists",
  /**
   * The caller does not have permission to execute the specified operation.
   * PERMISSION_DENIED must not be used for rejections caused by exhausting
   * some resource (use RESOURCE_EXHAUSTED instead for those errors).
   * PERMISSION_DENIED must not be used if the caller can not be identified
   * (use UNAUTHENTICATED instead for those errors).
   */
  PERMISSION_DENIED: "permission-denied",
  /**
   * The request does not have valid authentication credentials for the
   * operation.
   */
  UNAUTHENTICATED: "unauthenticated",
  /**
   * Some resource has been exhausted, perhaps a per-user quota, or perhaps the
   * entire file system is out of space.
   */
  RESOURCE_EXHAUSTED: "resource-exhausted",
  /**
   * Operation was rejected because the system is not in a state required for
   * the operation's execution. For example, directory to be deleted may be
   * non-empty, an rmdir operation is applied to a non-directory, etc.
   *
   * A litmus test that may help a service implementor in deciding
   * between FAILED_PRECONDITION, ABORTED, and UNAVAILABLE:
   *  (a) Use UNAVAILABLE if the client can retry just the failing call.
   *  (b) Use ABORTED if the client should retry at a higher-level
   *      (e.g., restarting a read-modify-write sequence).
   *  (c) Use FAILED_PRECONDITION if the client should not retry until
   *      the system state has been explicitly fixed. E.g., if an "rmdir"
   *      fails because the directory is non-empty, FAILED_PRECONDITION
   *      should be returned since the client should not retry unless
   *      they have first fixed up the directory by deleting files from it.
   *  (d) Use FAILED_PRECONDITION if the client performs conditional
   *      REST Get/Update/Delete on a resource and the resource on the
   *      server does not match the condition. E.g., conflicting
   *      read-modify-write on the same resource.
   */
  FAILED_PRECONDITION: "failed-precondition",
  /**
   * The operation was aborted, typically due to a concurrency issue like
   * sequencer check failures, transaction aborts, etc.
   *
   * See litmus test above for deciding between FAILED_PRECONDITION, ABORTED,
   * and UNAVAILABLE.
   */
  ABORTED: "aborted",
  /**
   * Operation was attempted past the valid range. E.g., seeking or reading
   * past end of file.
   *
   * Unlike INVALID_ARGUMENT, this error indicates a problem that may be fixed
   * if the system state changes. For example, a 32-bit file system will
   * generate INVALID_ARGUMENT if asked to read at an offset that is not in the
   * range [0,2^32-1], but it will generate OUT_OF_RANGE if asked to read from
   * an offset past the current file size.
   *
   * There is a fair bit of overlap between FAILED_PRECONDITION and
   * OUT_OF_RANGE. We recommend using OUT_OF_RANGE (the more specific error)
   * when it applies so that callers who are iterating through a space can
   * easily look for an OUT_OF_RANGE error to detect when they are done.
   */
  OUT_OF_RANGE: "out-of-range",
  /** Operation is not implemented or not supported/enabled in this service. */
  UNIMPLEMENTED: "unimplemented",
  /**
   * Internal errors. Means some invariants expected by underlying System has
   * been broken. If you see one of these errors, Something is very broken.
   */
  INTERNAL: "internal",
  /**
   * The service is currently unavailable. This is a most likely a transient
   * condition and may be corrected by retrying with a backoff.
   *
   * See litmus test above for deciding between FAILED_PRECONDITION, ABORTED,
   * and UNAVAILABLE.
   */
  UNAVAILABLE: "unavailable",
  /** Unrecoverable data loss or corruption. */
  DATA_LOSS: "data-loss"
};
var D2 = class extends Error {
  /** @hideconstructor */
  constructor(t2, e) {
    super(e), this.code = t2, this.message = e, /** The custom name for all FirestoreErrors. */
    this.name = "FirebaseError", // HACK: We write a toString property directly because Error is not a real
    // class and so inheritance does not work correctly. We could alternatively
    // do the same "back-door inheritance" trick that FirebaseError does.
    this.toString = () => `${this.name}: [code=${this.code}]: ${this.message}`;
  }
};
var C = new Logger("@firebase/firestore");
function N2() {
  return C.logLevel;
}
function x2(t2) {
  C.setLogLevel(t2);
}
function k2(t2, ...e) {
  if (C.logLevel <= LogLevel.DEBUG) {
    const n2 = e.map(F2);
    C.debug(`Firestore (${v}): ${t2}`, ...n2);
  }
}
function $(t2, ...e) {
  if (C.logLevel <= LogLevel.ERROR) {
    const n2 = e.map(F2);
    C.error(`Firestore (${v}): ${t2}`, ...n2);
  }
}
function O2(t2, ...e) {
  if (C.logLevel <= LogLevel.WARN) {
    const n2 = e.map(F2);
    C.warn(`Firestore (${v}): ${t2}`, ...n2);
  }
}
function F2(t2) {
  if ("string" == typeof t2)
    return t2;
  try {
    return e = t2, JSON.stringify(e);
  } catch (e2) {
    return t2;
  }
  var e;
}
function M2(t2 = "Unexpected state") {
  const e = `FIRESTORE (${v}) INTERNAL ASSERTION FAILED: ` + t2;
  throw $(e), new Error(e);
}
function L2(t2, e) {
  t2 || M2();
}
function B(t2, e) {
  return t2;
}
function U2(t2) {
  const e = (
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    "undefined" != typeof self && (self.crypto || self.msCrypto)
  ), n2 = new Uint8Array(t2);
  if (e && "function" == typeof e.getRandomValues)
    e.getRandomValues(n2);
  else
    for (let e2 = 0; e2 < t2; e2++)
      n2[e2] = Math.floor(256 * Math.random());
  return n2;
}
var q2 = class {
  static u() {
    const t2 = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789", e = Math.floor(256 / t2.length) * t2.length;
    let n2 = "";
    for (; n2.length < 20; ) {
      const s = U2(40);
      for (let i = 0; i < s.length; ++i)
        n2.length < 20 && s[i] < e && (n2 += t2.charAt(s[i] % t2.length));
    }
    return n2;
  }
};
function K2(t2, e) {
  return t2 < e ? -1 : t2 > e ? 1 : 0;
}
function Q2(t2, e, n2) {
  return t2.length === e.length && t2.every((t3, s) => n2(t3, e[s]));
}
function j(t2) {
  return t2 + "\0";
}
var W2 = class {
  /**
   * Creates a new timestamp.
   *
   * @param seconds - The number of seconds of UTC time since Unix epoch
   *     1970-01-01T00:00:00Z. Must be from 0001-01-01T00:00:00Z to
   *     9999-12-31T23:59:59Z inclusive.
   * @param nanoseconds - The non-negative fractions of a second at nanosecond
   *     resolution. Negative second values with fractions must still have
   *     non-negative nanoseconds values that count forward in time. Must be
   *     from 0 to 999,999,999 inclusive.
   */
  constructor(t2, e) {
    if (this.seconds = t2, this.nanoseconds = e, e < 0)
      throw new D2(S2.INVALID_ARGUMENT, "Timestamp nanoseconds out of range: " + e);
    if (e >= 1e9)
      throw new D2(S2.INVALID_ARGUMENT, "Timestamp nanoseconds out of range: " + e);
    if (t2 < -62135596800)
      throw new D2(S2.INVALID_ARGUMENT, "Timestamp seconds out of range: " + t2);
    if (t2 >= 253402300800)
      throw new D2(S2.INVALID_ARGUMENT, "Timestamp seconds out of range: " + t2);
  }
  /**
   * Creates a new timestamp with the current date, with millisecond precision.
   *
   * @returns a new timestamp representing the current date.
   */
  static now() {
    return W2.fromMillis(Date.now());
  }
  /**
   * Creates a new timestamp from the given date.
   *
   * @param date - The date to initialize the `Timestamp` from.
   * @returns A new `Timestamp` representing the same point in time as the given
   *     date.
   */
  static fromDate(t2) {
    return W2.fromMillis(t2.getTime());
  }
  /**
   * Creates a new timestamp from the given number of milliseconds.
   *
   * @param milliseconds - Number of milliseconds since Unix epoch
   *     1970-01-01T00:00:00Z.
   * @returns A new `Timestamp` representing the same point in time as the given
   *     number of milliseconds.
   */
  static fromMillis(t2) {
    const e = Math.floor(t2 / 1e3), n2 = Math.floor(1e6 * (t2 - 1e3 * e));
    return new W2(e, n2);
  }
  /**
   * Converts a `Timestamp` to a JavaScript `Date` object. This conversion
   * causes a loss of precision since `Date` objects only support millisecond
   * precision.
   *
   * @returns JavaScript `Date` object representing the same point in time as
   *     this `Timestamp`, with millisecond precision.
   */
  toDate() {
    return new Date(this.toMillis());
  }
  /**
   * Converts a `Timestamp` to a numeric timestamp (in milliseconds since
   * epoch). This operation causes a loss of precision.
   *
   * @returns The point in time corresponding to this timestamp, represented as
   *     the number of milliseconds since Unix epoch 1970-01-01T00:00:00Z.
   */
  toMillis() {
    return 1e3 * this.seconds + this.nanoseconds / 1e6;
  }
  _compareTo(t2) {
    return this.seconds === t2.seconds ? K2(this.nanoseconds, t2.nanoseconds) : K2(this.seconds, t2.seconds);
  }
  /**
   * Returns true if this `Timestamp` is equal to the provided one.
   *
   * @param other - The `Timestamp` to compare against.
   * @returns true if this `Timestamp` is equal to the provided one.
   */
  isEqual(t2) {
    return t2.seconds === this.seconds && t2.nanoseconds === this.nanoseconds;
  }
  /** Returns a textual representation of this Timestamp. */
  toString() {
    return "Timestamp(seconds=" + this.seconds + ", nanoseconds=" + this.nanoseconds + ")";
  }
  /** Returns a JSON-serializable representation of this Timestamp. */
  toJSON() {
    return {
      seconds: this.seconds,
      nanoseconds: this.nanoseconds
    };
  }
  /**
   * Converts this object to a primitive string, which allows Timestamp objects
   * to be compared using the `>`, `<=`, `>=` and `>` operators.
   */
  valueOf() {
    const t2 = this.seconds - -62135596800;
    return String(t2).padStart(12, "0") + "." + String(this.nanoseconds).padStart(9, "0");
  }
};
var G2 = class {
  constructor(t2) {
    this.timestamp = t2;
  }
  static fromTimestamp(t2) {
    return new G2(t2);
  }
  static min() {
    return new G2(new W2(0, 0));
  }
  compareTo(t2) {
    return this.timestamp._compareTo(t2.timestamp);
  }
  isEqual(t2) {
    return this.timestamp.isEqual(t2.timestamp);
  }
  /** Returns a number representation of the version for use in spec tests. */
  toMicroseconds() {
    return 1e6 * this.timestamp.seconds + this.timestamp.nanoseconds / 1e3;
  }
  toString() {
    return "SnapshotVersion(" + this.timestamp.toString() + ")";
  }
  toTimestamp() {
    return this.timestamp;
  }
};
function z2(t2) {
  let e = 0;
  for (const n2 in t2)
    Object.prototype.hasOwnProperty.call(t2, n2) && e++;
  return e;
}
function H2(t2, e) {
  for (const n2 in t2)
    Object.prototype.hasOwnProperty.call(t2, n2) && e(n2, t2[n2]);
}
function J2(t2) {
  for (const e in t2)
    if (Object.prototype.hasOwnProperty.call(t2, e))
      return false;
  return true;
}
var Y2 = class {
  constructor(t2, e, n2) {
    void 0 === e ? e = 0 : e > t2.length && M2(), void 0 === n2 ? n2 = t2.length - e : n2 > t2.length - e && M2(), this.segments = t2, this.offset = e, this.len = n2;
  }
  get length() {
    return this.len;
  }
  isEqual(t2) {
    return 0 === Y2.comparator(this, t2);
  }
  child(t2) {
    const e = this.segments.slice(this.offset, this.limit());
    return t2 instanceof Y2 ? t2.forEach((t3) => {
      e.push(t3);
    }) : e.push(t2), this.construct(e);
  }
  /** The index of one past the last segment of the path. */
  limit() {
    return this.offset + this.length;
  }
  popFirst(t2) {
    return t2 = void 0 === t2 ? 1 : t2, this.construct(this.segments, this.offset + t2, this.length - t2);
  }
  popLast() {
    return this.construct(this.segments, this.offset, this.length - 1);
  }
  firstSegment() {
    return this.segments[this.offset];
  }
  lastSegment() {
    return this.get(this.length - 1);
  }
  get(t2) {
    return this.segments[this.offset + t2];
  }
  isEmpty() {
    return 0 === this.length;
  }
  isPrefixOf(t2) {
    if (t2.length < this.length)
      return false;
    for (let e = 0; e < this.length; e++)
      if (this.get(e) !== t2.get(e))
        return false;
    return true;
  }
  isImmediateParentOf(t2) {
    if (this.length + 1 !== t2.length)
      return false;
    for (let e = 0; e < this.length; e++)
      if (this.get(e) !== t2.get(e))
        return false;
    return true;
  }
  forEach(t2) {
    for (let e = this.offset, n2 = this.limit(); e < n2; e++)
      t2(this.segments[e]);
  }
  toArray() {
    return this.segments.slice(this.offset, this.limit());
  }
  static comparator(t2, e) {
    const n2 = Math.min(t2.length, e.length);
    for (let s = 0; s < n2; s++) {
      const n3 = t2.get(s), i = e.get(s);
      if (n3 < i)
        return -1;
      if (n3 > i)
        return 1;
    }
    return t2.length < e.length ? -1 : t2.length > e.length ? 1 : 0;
  }
};
var X2 = class extends Y2 {
  construct(t2, e, n2) {
    return new X2(t2, e, n2);
  }
  canonicalString() {
    return this.toArray().join("/");
  }
  toString() {
    return this.canonicalString();
  }
  /**
   * Creates a resource path from the given slash-delimited string. If multiple
   * arguments are provided, all components are combined. Leading and trailing
   * slashes from all components are ignored.
   */
  static fromString(...t2) {
    const e = [];
    for (const n2 of t2) {
      if (n2.indexOf("//") >= 0)
        throw new D2(S2.INVALID_ARGUMENT, `Invalid segment (${n2}). Paths must not contain // in them.`);
      e.push(...n2.split("/").filter((t3) => t3.length > 0));
    }
    return new X2(e);
  }
  static emptyPath() {
    return new X2([]);
  }
};
var Z2 = /^[_a-zA-Z][_a-zA-Z0-9]*$/;
var tt = class extends Y2 {
  construct(t2, e, n2) {
    return new tt(t2, e, n2);
  }
  /**
   * Returns true if the string could be used as a segment in a field path
   * without escaping.
   */
  static isValidIdentifier(t2) {
    return Z2.test(t2);
  }
  canonicalString() {
    return this.toArray().map((t2) => (t2 = t2.replace(/\\/g, "\\\\").replace(/`/g, "\\`"), tt.isValidIdentifier(t2) || (t2 = "`" + t2 + "`"), t2)).join(".");
  }
  toString() {
    return this.canonicalString();
  }
  /**
   * Returns true if this field references the key of a document.
   */
  isKeyField() {
    return 1 === this.length && "__name__" === this.get(0);
  }
  /**
   * The field designating the key of a document.
   */
  static keyField() {
    return new tt(["__name__"]);
  }
  /**
   * Parses a field string from the given server-formatted string.
   *
   * - Splitting the empty string is not allowed (for now at least).
   * - Empty segments within the string (e.g. if there are two consecutive
   *   separators) are not allowed.
   *
   * TODO(b/37244157): we should make this more strict. Right now, it allows
   * non-identifier path components, even if they aren't escaped.
   */
  static fromServerFormat(t2) {
    const e = [];
    let n2 = "", s = 0;
    const i = () => {
      if (0 === n2.length)
        throw new D2(S2.INVALID_ARGUMENT, `Invalid field path (${t2}). Paths must not be empty, begin with '.', end with '.', or contain '..'`);
      e.push(n2), n2 = "";
    };
    let r2 = false;
    for (; s < t2.length; ) {
      const e2 = t2[s];
      if ("\\" === e2) {
        if (s + 1 === t2.length)
          throw new D2(S2.INVALID_ARGUMENT, "Path has trailing escape character: " + t2);
        const e3 = t2[s + 1];
        if ("\\" !== e3 && "." !== e3 && "`" !== e3)
          throw new D2(S2.INVALID_ARGUMENT, "Path has invalid escape sequence: " + t2);
        n2 += e3, s += 2;
      } else
        "`" === e2 ? (r2 = !r2, s++) : "." !== e2 || r2 ? (n2 += e2, s++) : (i(), s++);
    }
    if (i(), r2)
      throw new D2(S2.INVALID_ARGUMENT, "Unterminated ` in path: " + t2);
    return new tt(e);
  }
  static emptyPath() {
    return new tt([]);
  }
};
var et = class {
  constructor(t2) {
    this.fields = t2, // TODO(dimond): validation of FieldMask
    // Sort the field mask to support `FieldMask.isEqual()` and assert below.
    t2.sort(tt.comparator);
  }
  /**
   * Verifies that `fieldPath` is included by at least one field in this field
   * mask.
   *
   * This is an O(n) operation, where `n` is the size of the field mask.
   */
  covers(t2) {
    for (const e of this.fields)
      if (e.isPrefixOf(t2))
        return true;
    return false;
  }
  isEqual(t2) {
    return Q2(this.fields, t2.fields, (t3, e) => t3.isEqual(e));
  }
};
var nt = class {
  constructor(t2) {
    this.binaryString = t2;
  }
  static fromBase64String(t2) {
    const e = atob(t2);
    return new nt(e);
  }
  static fromUint8Array(t2) {
    const e = (
      /**
      * Helper function to convert an Uint8array to a binary string.
      */
      function(t3) {
        let e2 = "";
        for (let n2 = 0; n2 < t3.length; ++n2)
          e2 += String.fromCharCode(t3[n2]);
        return e2;
      }(t2)
    );
    return new nt(e);
  }
  toBase64() {
    return t2 = this.binaryString, btoa(t2);
    var t2;
  }
  toUint8Array() {
    return function(t2) {
      const e = new Uint8Array(t2.length);
      for (let n2 = 0; n2 < t2.length; n2++)
        e[n2] = t2.charCodeAt(n2);
      return e;
    }(this.binaryString);
  }
  approximateByteSize() {
    return 2 * this.binaryString.length;
  }
  compareTo(t2) {
    return K2(this.binaryString, t2.binaryString);
  }
  isEqual(t2) {
    return this.binaryString === t2.binaryString;
  }
};
nt.EMPTY_BYTE_STRING = new nt("");
var st = new RegExp(/^\d{4}-\d\d-\d\dT\d\d:\d\d:\d\d(?:\.(\d+))?Z$/);
function it(t2) {
  if (L2(!!t2), "string" == typeof t2) {
    let e = 0;
    const n2 = st.exec(t2);
    if (L2(!!n2), n2[1]) {
      let t3 = n2[1];
      t3 = (t3 + "000000000").substr(0, 9), e = Number(t3);
    }
    const s = new Date(t2);
    return {
      seconds: Math.floor(s.getTime() / 1e3),
      nanos: e
    };
  }
  return {
    seconds: rt(t2.seconds),
    nanos: rt(t2.nanos)
  };
}
function rt(t2) {
  return "number" == typeof t2 ? t2 : "string" == typeof t2 ? Number(t2) : 0;
}
function ot(t2) {
  return "string" == typeof t2 ? nt.fromBase64String(t2) : nt.fromUint8Array(t2);
}
function ct(t2) {
  var e, n2;
  return "server_timestamp" === (null === (n2 = ((null === (e = null == t2 ? void 0 : t2.mapValue) || void 0 === e ? void 0 : e.fields) || {}).__type__) || void 0 === n2 ? void 0 : n2.stringValue);
}
function ut(t2) {
  const e = t2.mapValue.fields.__previous_value__;
  return ct(e) ? ut(e) : e;
}
function at(t2) {
  const e = it(t2.mapValue.fields.__local_write_time__.timestampValue);
  return new W2(e.seconds, e.nanos);
}
function ht(t2) {
  return null == t2;
}
function lt(t2) {
  return 0 === t2 && 1 / t2 == -1 / 0;
}
function ft(t2) {
  return "number" == typeof t2 && Number.isInteger(t2) && !lt(t2) && t2 <= Number.MAX_SAFE_INTEGER && t2 >= Number.MIN_SAFE_INTEGER;
}
var dt = class {
  constructor(t2) {
    this.path = t2;
  }
  static fromPath(t2) {
    return new dt(X2.fromString(t2));
  }
  static fromName(t2) {
    return new dt(X2.fromString(t2).popFirst(5));
  }
  /** Returns true if the document is in the specified collectionId. */
  hasCollectionId(t2) {
    return this.path.length >= 2 && this.path.get(this.path.length - 2) === t2;
  }
  isEqual(t2) {
    return null !== t2 && 0 === X2.comparator(this.path, t2.path);
  }
  toString() {
    return this.path.toString();
  }
  static comparator(t2, e) {
    return X2.comparator(t2.path, e.path);
  }
  static isDocumentKey(t2) {
    return t2.length % 2 == 0;
  }
  /**
   * Creates and returns a new document key with the given segments.
   *
   * @param segments - The segments of the path to the document
   * @returns A new instance of DocumentKey
   */
  static fromSegments(t2) {
    return new dt(new X2(t2.slice()));
  }
};
function wt(t2) {
  return "nullValue" in t2 ? 0 : "booleanValue" in t2 ? 1 : "integerValue" in t2 || "doubleValue" in t2 ? 2 : "timestampValue" in t2 ? 3 : "stringValue" in t2 ? 5 : "bytesValue" in t2 ? 6 : "referenceValue" in t2 ? 7 : "geoPointValue" in t2 ? 8 : "arrayValue" in t2 ? 9 : "mapValue" in t2 ? ct(t2) ? 4 : 10 : M2();
}
function _t(t2, e) {
  const n2 = wt(t2);
  if (n2 !== wt(e))
    return false;
  switch (n2) {
    case 0:
      return true;
    case 1:
      return t2.booleanValue === e.booleanValue;
    case 4:
      return at(t2).isEqual(at(e));
    case 3:
      return function(t3, e2) {
        if ("string" == typeof t3.timestampValue && "string" == typeof e2.timestampValue && t3.timestampValue.length === e2.timestampValue.length)
          return t3.timestampValue === e2.timestampValue;
        const n3 = it(t3.timestampValue), s = it(e2.timestampValue);
        return n3.seconds === s.seconds && n3.nanos === s.nanos;
      }(t2, e);
    case 5:
      return t2.stringValue === e.stringValue;
    case 6:
      return function(t3, e2) {
        return ot(t3.bytesValue).isEqual(ot(e2.bytesValue));
      }(t2, e);
    case 7:
      return t2.referenceValue === e.referenceValue;
    case 8:
      return function(t3, e2) {
        return rt(t3.geoPointValue.latitude) === rt(e2.geoPointValue.latitude) && rt(t3.geoPointValue.longitude) === rt(e2.geoPointValue.longitude);
      }(t2, e);
    case 2:
      return function(t3, e2) {
        if ("integerValue" in t3 && "integerValue" in e2)
          return rt(t3.integerValue) === rt(e2.integerValue);
        if ("doubleValue" in t3 && "doubleValue" in e2) {
          const n3 = rt(t3.doubleValue), s = rt(e2.doubleValue);
          return n3 === s ? lt(n3) === lt(s) : isNaN(n3) && isNaN(s);
        }
        return false;
      }(t2, e);
    case 9:
      return Q2(t2.arrayValue.values || [], e.arrayValue.values || [], _t);
    case 10:
      return function(t3, e2) {
        const n3 = t3.mapValue.fields || {}, s = e2.mapValue.fields || {};
        if (z2(n3) !== z2(s))
          return false;
        for (const t4 in n3)
          if (n3.hasOwnProperty(t4) && (void 0 === s[t4] || !_t(n3[t4], s[t4])))
            return false;
        return true;
      }(t2, e);
    default:
      return M2();
  }
}
function mt(t2, e) {
  return void 0 !== (t2.values || []).find((t3) => _t(t3, e));
}
function gt(t2, e) {
  const n2 = wt(t2), s = wt(e);
  if (n2 !== s)
    return K2(n2, s);
  switch (n2) {
    case 0:
      return 0;
    case 1:
      return K2(t2.booleanValue, e.booleanValue);
    case 2:
      return function(t3, e2) {
        const n3 = rt(t3.integerValue || t3.doubleValue), s2 = rt(e2.integerValue || e2.doubleValue);
        return n3 < s2 ? -1 : n3 > s2 ? 1 : n3 === s2 ? 0 : (
          // one or both are NaN.
          isNaN(n3) ? isNaN(s2) ? 0 : -1 : 1
        );
      }(t2, e);
    case 3:
      return yt(t2.timestampValue, e.timestampValue);
    case 4:
      return yt(at(t2), at(e));
    case 5:
      return K2(t2.stringValue, e.stringValue);
    case 6:
      return function(t3, e2) {
        const n3 = ot(t3), s2 = ot(e2);
        return n3.compareTo(s2);
      }(t2.bytesValue, e.bytesValue);
    case 7:
      return function(t3, e2) {
        const n3 = t3.split("/"), s2 = e2.split("/");
        for (let t4 = 0; t4 < n3.length && t4 < s2.length; t4++) {
          const e3 = K2(n3[t4], s2[t4]);
          if (0 !== e3)
            return e3;
        }
        return K2(n3.length, s2.length);
      }(t2.referenceValue, e.referenceValue);
    case 8:
      return function(t3, e2) {
        const n3 = K2(rt(t3.latitude), rt(e2.latitude));
        if (0 !== n3)
          return n3;
        return K2(rt(t3.longitude), rt(e2.longitude));
      }(t2.geoPointValue, e.geoPointValue);
    case 9:
      return function(t3, e2) {
        const n3 = t3.values || [], s2 = e2.values || [];
        for (let t4 = 0; t4 < n3.length && t4 < s2.length; ++t4) {
          const e3 = gt(n3[t4], s2[t4]);
          if (e3)
            return e3;
        }
        return K2(n3.length, s2.length);
      }(t2.arrayValue, e.arrayValue);
    case 10:
      return function(t3, e2) {
        const n3 = t3.fields || {}, s2 = Object.keys(n3), i = e2.fields || {}, r2 = Object.keys(i);
        s2.sort(), r2.sort();
        for (let t4 = 0; t4 < s2.length && t4 < r2.length; ++t4) {
          const e3 = K2(s2[t4], r2[t4]);
          if (0 !== e3)
            return e3;
          const o = gt(n3[s2[t4]], i[r2[t4]]);
          if (0 !== o)
            return o;
        }
        return K2(s2.length, r2.length);
      }(t2.mapValue, e.mapValue);
    default:
      throw M2();
  }
}
function yt(t2, e) {
  if ("string" == typeof t2 && "string" == typeof e && t2.length === e.length)
    return K2(t2, e);
  const n2 = it(t2), s = it(e), i = K2(n2.seconds, s.seconds);
  return 0 !== i ? i : K2(n2.nanos, s.nanos);
}
function pt(t2) {
  return Et(t2);
}
function Et(t2) {
  return "nullValue" in t2 ? "null" : "booleanValue" in t2 ? "" + t2.booleanValue : "integerValue" in t2 ? "" + t2.integerValue : "doubleValue" in t2 ? "" + t2.doubleValue : "timestampValue" in t2 ? function(t3) {
    const e2 = it(t3);
    return `time(${e2.seconds},${e2.nanos})`;
  }(t2.timestampValue) : "stringValue" in t2 ? t2.stringValue : "bytesValue" in t2 ? ot(t2.bytesValue).toBase64() : "referenceValue" in t2 ? (n2 = t2.referenceValue, dt.fromName(n2).toString()) : "geoPointValue" in t2 ? `geo(${(e = t2.geoPointValue).latitude},${e.longitude})` : "arrayValue" in t2 ? function(t3) {
    let e2 = "[", n3 = true;
    for (const s of t3.values || [])
      n3 ? n3 = false : e2 += ",", e2 += Et(s);
    return e2 + "]";
  }(t2.arrayValue) : "mapValue" in t2 ? function(t3) {
    const e2 = Object.keys(t3.fields || {}).sort();
    let n3 = "{", s = true;
    for (const i of e2)
      s ? s = false : n3 += ",", n3 += `${i}:${Et(t3.fields[i])}`;
    return n3 + "}";
  }(t2.mapValue) : M2();
  var e, n2;
}
function Tt(t2, e) {
  return {
    referenceValue: `projects/${t2.projectId}/databases/${t2.database}/documents/${e.path.canonicalString()}`
  };
}
function It(t2) {
  return !!t2 && "integerValue" in t2;
}
function At(t2) {
  return !!t2 && "arrayValue" in t2;
}
function Rt(t2) {
  return !!t2 && "nullValue" in t2;
}
function Pt(t2) {
  return !!t2 && "doubleValue" in t2 && isNaN(Number(t2.doubleValue));
}
function bt(t2) {
  return !!t2 && "mapValue" in t2;
}
function vt(t2) {
  if (t2.geoPointValue)
    return {
      geoPointValue: Object.assign({}, t2.geoPointValue)
    };
  if (t2.timestampValue)
    return {
      timestampValue: Object.assign({}, it(t2.timestampValue))
    };
  if (t2.mapValue) {
    const e = {
      mapValue: {
        fields: {}
      }
    };
    return H2(t2.mapValue.fields, (t3, n2) => e.mapValue.fields[t3] = vt(n2)), e;
  }
  if (t2.arrayValue) {
    const e = {
      arrayValue: {
        values: []
      }
    };
    for (let n2 = 0; n2 < (t2.arrayValue.values || []).length; ++n2)
      e.arrayValue.values[n2] = vt(t2.arrayValue.values[n2]);
    return e;
  }
  return Object.assign({}, t2);
}
var Vt = class {
  constructor(t2) {
    this.value = t2;
  }
  static empty() {
    return new Vt({
      mapValue: {}
    });
  }
  /**
   * Returns the value at the given path or null.
   *
   * @param path - the path to search
   * @returns The value at the path or null if the path is not set.
   */
  field(t2) {
    if (t2.isEmpty())
      return this.value;
    {
      let e = this.value;
      for (let n2 = 0; n2 < t2.length - 1; ++n2)
        if (e = (e.mapValue.fields || {})[t2.get(n2)], !bt(e))
          return null;
      return e = (e.mapValue.fields || {})[t2.lastSegment()], e || null;
    }
  }
  /**
   * Sets the field to the provided value.
   *
   * @param path - The field path to set.
   * @param value - The value to set.
   */
  set(t2, e) {
    this.getFieldsMap(t2.popLast())[t2.lastSegment()] = vt(e);
  }
  /**
   * Sets the provided fields to the provided values.
   *
   * @param data - A map of fields to values (or null for deletes).
   */
  setAll(t2) {
    let e = tt.emptyPath(), n2 = {}, s = [];
    t2.forEach((t3, i2) => {
      if (!e.isImmediateParentOf(i2)) {
        const t4 = this.getFieldsMap(e);
        this.applyChanges(t4, n2, s), n2 = {}, s = [], e = i2.popLast();
      }
      t3 ? n2[i2.lastSegment()] = vt(t3) : s.push(i2.lastSegment());
    });
    const i = this.getFieldsMap(e);
    this.applyChanges(i, n2, s);
  }
  /**
   * Removes the field at the specified path. If there is no field at the
   * specified path, nothing is changed.
   *
   * @param path - The field path to remove.
   */
  delete(t2) {
    const e = this.field(t2.popLast());
    bt(e) && e.mapValue.fields && delete e.mapValue.fields[t2.lastSegment()];
  }
  isEqual(t2) {
    return _t(this.value, t2.value);
  }
  /**
   * Returns the map that contains the leaf element of `path`. If the parent
   * entry does not yet exist, or if it is not a map, a new map will be created.
   */
  getFieldsMap(t2) {
    let e = this.value;
    e.mapValue.fields || (e.mapValue = {
      fields: {}
    });
    for (let n2 = 0; n2 < t2.length; ++n2) {
      let s = e.mapValue.fields[t2.get(n2)];
      bt(s) && s.mapValue.fields || (s = {
        mapValue: {
          fields: {}
        }
      }, e.mapValue.fields[t2.get(n2)] = s), e = s;
    }
    return e.mapValue.fields;
  }
  /**
   * Modifies `fieldsMap` by adding, replacing or deleting the specified
   * entries.
   */
  applyChanges(t2, e, n2) {
    H2(e, (e2, n3) => t2[e2] = n3);
    for (const e2 of n2)
      delete t2[e2];
  }
  clone() {
    return new Vt(vt(this.value));
  }
};
function St(t2) {
  const e = [];
  return H2(t2.fields, (t3, n2) => {
    const s = new tt([t3]);
    if (bt(n2)) {
      const t4 = St(n2.mapValue).fields;
      if (0 === t4.length)
        e.push(s);
      else
        for (const n3 of t4)
          e.push(s.child(n3));
    } else
      e.push(s);
  }), new et(e);
}
var Dt = class {
  constructor(t2, e, n2, s, i) {
    this.key = t2, this.documentType = e, this.version = n2, this.data = s, this.documentState = i;
  }
  /**
   * Creates a document with no known version or data, but which can serve as
   * base document for mutations.
   */
  static newInvalidDocument(t2) {
    return new Dt(
      t2,
      0,
      G2.min(),
      Vt.empty(),
      0
      /* SYNCED */
    );
  }
  /**
   * Creates a new document that is known to exist with the given data at the
   * given version.
   */
  static newFoundDocument(t2, e, n2) {
    return new Dt(
      t2,
      1,
      e,
      n2,
      0
      /* SYNCED */
    );
  }
  /** Creates a new document that is known to not exist at the given version. */
  static newNoDocument(t2, e) {
    return new Dt(
      t2,
      2,
      e,
      Vt.empty(),
      0
      /* SYNCED */
    );
  }
  /**
   * Creates a new document that is known to exist at the given version but
   * whose data is not known (e.g. a document that was updated without a known
   * base document).
   */
  static newUnknownDocument(t2, e) {
    return new Dt(
      t2,
      3,
      e,
      Vt.empty(),
      2
      /* HAS_COMMITTED_MUTATIONS */
    );
  }
  /**
   * Changes the document type to indicate that it exists and that its version
   * and data are known.
   */
  convertToFoundDocument(t2, e) {
    return this.version = t2, this.documentType = 1, this.data = e, this.documentState = 0, this;
  }
  /**
   * Changes the document type to indicate that it doesn't exist at the given
   * version.
   */
  convertToNoDocument(t2) {
    return this.version = t2, this.documentType = 2, this.data = Vt.empty(), this.documentState = 0, this;
  }
  /**
   * Changes the document type to indicate that it exists at a given version but
   * that its data is not known (e.g. a document that was updated without a known
   * base document).
   */
  convertToUnknownDocument(t2) {
    return this.version = t2, this.documentType = 3, this.data = Vt.empty(), this.documentState = 2, this;
  }
  setHasCommittedMutations() {
    return this.documentState = 2, this;
  }
  setHasLocalMutations() {
    return this.documentState = 1, this;
  }
  get hasLocalMutations() {
    return 1 === this.documentState;
  }
  get hasCommittedMutations() {
    return 2 === this.documentState;
  }
  get hasPendingWrites() {
    return this.hasLocalMutations || this.hasCommittedMutations;
  }
  isValidDocument() {
    return 0 !== this.documentType;
  }
  isFoundDocument() {
    return 1 === this.documentType;
  }
  isNoDocument() {
    return 2 === this.documentType;
  }
  isUnknownDocument() {
    return 3 === this.documentType;
  }
  isEqual(t2) {
    return t2 instanceof Dt && this.key.isEqual(t2.key) && this.version.isEqual(t2.version) && this.documentType === t2.documentType && this.documentState === t2.documentState && this.data.isEqual(t2.data);
  }
  clone() {
    return new Dt(this.key, this.documentType, this.version, this.data.clone(), this.documentState);
  }
  toString() {
    return `Document(${this.key}, ${this.version}, ${JSON.stringify(this.data.value)}, {documentType: ${this.documentType}}), {documentState: ${this.documentState}})`;
  }
};
var Ct = class {
  constructor(t2, e = null, n2 = [], s = [], i = null, r2 = null, o = null) {
    this.path = t2, this.collectionGroup = e, this.orderBy = n2, this.filters = s, this.limit = i, this.startAt = r2, this.endAt = o, this.h = null;
  }
};
function Nt(t2, e = null, n2 = [], s = [], i = null, r2 = null, o = null) {
  return new Ct(t2, e, n2, s, i, r2, o);
}
function xt(t2) {
  const e = B(t2);
  if (null === e.h) {
    let t3 = e.path.canonicalString();
    null !== e.collectionGroup && (t3 += "|cg:" + e.collectionGroup), t3 += "|f:", t3 += e.filters.map((t4) => Mt(t4)).join(","), t3 += "|ob:", t3 += e.orderBy.map((t4) => function(t5) {
      return t5.field.canonicalString() + t5.dir;
    }(t4)).join(","), ht(e.limit) || (t3 += "|l:", t3 += e.limit), e.startAt && (t3 += "|lb:", t3 += zt(e.startAt)), e.endAt && (t3 += "|ub:", t3 += zt(e.endAt)), e.h = t3;
  }
  return e.h;
}
function kt(t2) {
  let e = t2.path.canonicalString();
  return null !== t2.collectionGroup && (e += " collectionGroup=" + t2.collectionGroup), t2.filters.length > 0 && (e += `, filters: [${t2.filters.map((t3) => {
    return `${(e2 = t3).field.canonicalString()} ${e2.op} ${pt(e2.value)}`;
    var e2;
  }).join(", ")}]`), ht(t2.limit) || (e += ", limit: " + t2.limit), t2.orderBy.length > 0 && (e += `, orderBy: [${t2.orderBy.map((t3) => function(t4) {
    return `${t4.field.canonicalString()} (${t4.dir})`;
  }(t3)).join(", ")}]`), t2.startAt && (e += ", startAt: " + zt(t2.startAt)), t2.endAt && (e += ", endAt: " + zt(t2.endAt)), `Target(${e})`;
}
function $t(t2, e) {
  if (t2.limit !== e.limit)
    return false;
  if (t2.orderBy.length !== e.orderBy.length)
    return false;
  for (let n3 = 0; n3 < t2.orderBy.length; n3++)
    if (!Jt(t2.orderBy[n3], e.orderBy[n3]))
      return false;
  if (t2.filters.length !== e.filters.length)
    return false;
  for (let i = 0; i < t2.filters.length; i++)
    if (n2 = t2.filters[i], s = e.filters[i], n2.op !== s.op || !n2.field.isEqual(s.field) || !_t(n2.value, s.value))
      return false;
  var n2, s;
  return t2.collectionGroup === e.collectionGroup && (!!t2.path.isEqual(e.path) && (!!Xt(t2.startAt, e.startAt) && Xt(t2.endAt, e.endAt)));
}
function Ot(t2) {
  return dt.isDocumentKey(t2.path) && null === t2.collectionGroup && 0 === t2.filters.length;
}
var Ft = class extends class {
} {
  constructor(t2, e, n2) {
    super(), this.field = t2, this.op = e, this.value = n2;
  }
  /**
   * Creates a filter based on the provided arguments.
   */
  static create(t2, e, n2) {
    return t2.isKeyField() ? "in" === e || "not-in" === e ? this.l(t2, e, n2) : new Lt(t2, e, n2) : "array-contains" === e ? new Kt(t2, n2) : "in" === e ? new Qt(t2, n2) : "not-in" === e ? new jt(t2, n2) : "array-contains-any" === e ? new Wt(t2, n2) : new Ft(t2, e, n2);
  }
  static l(t2, e, n2) {
    return "in" === e ? new Bt(t2, n2) : new Ut(t2, n2);
  }
  matches(t2) {
    const e = t2.data.field(this.field);
    return "!=" === this.op ? null !== e && this.m(gt(e, this.value)) : null !== e && wt(this.value) === wt(e) && this.m(gt(e, this.value));
  }
  m(t2) {
    switch (this.op) {
      case "<":
        return t2 < 0;
      case "<=":
        return t2 <= 0;
      case "==":
        return 0 === t2;
      case "!=":
        return 0 !== t2;
      case ">":
        return t2 > 0;
      case ">=":
        return t2 >= 0;
      default:
        return M2();
    }
  }
  g() {
    return [
      "<",
      "<=",
      ">",
      ">=",
      "!=",
      "not-in"
      /* NOT_IN */
    ].indexOf(this.op) >= 0;
  }
};
function Mt(t2) {
  return t2.field.canonicalString() + t2.op.toString() + pt(t2.value);
}
var Lt = class extends Ft {
  constructor(t2, e, n2) {
    super(t2, e, n2), this.key = dt.fromName(n2.referenceValue);
  }
  matches(t2) {
    const e = dt.comparator(t2.key, this.key);
    return this.m(e);
  }
};
var Bt = class extends Ft {
  constructor(t2, e) {
    super(t2, "in", e), this.keys = qt("in", e);
  }
  matches(t2) {
    return this.keys.some((e) => e.isEqual(t2.key));
  }
};
var Ut = class extends Ft {
  constructor(t2, e) {
    super(t2, "not-in", e), this.keys = qt("not-in", e);
  }
  matches(t2) {
    return !this.keys.some((e) => e.isEqual(t2.key));
  }
};
function qt(t2, e) {
  var n2;
  return ((null === (n2 = e.arrayValue) || void 0 === n2 ? void 0 : n2.values) || []).map((t3) => dt.fromName(t3.referenceValue));
}
var Kt = class extends Ft {
  constructor(t2, e) {
    super(t2, "array-contains", e);
  }
  matches(t2) {
    const e = t2.data.field(this.field);
    return At(e) && mt(e.arrayValue, this.value);
  }
};
var Qt = class extends Ft {
  constructor(t2, e) {
    super(t2, "in", e);
  }
  matches(t2) {
    const e = t2.data.field(this.field);
    return null !== e && mt(this.value.arrayValue, e);
  }
};
var jt = class extends Ft {
  constructor(t2, e) {
    super(t2, "not-in", e);
  }
  matches(t2) {
    if (mt(this.value.arrayValue, {
      nullValue: "NULL_VALUE"
    }))
      return false;
    const e = t2.data.field(this.field);
    return null !== e && !mt(this.value.arrayValue, e);
  }
};
var Wt = class extends Ft {
  constructor(t2, e) {
    super(t2, "array-contains-any", e);
  }
  matches(t2) {
    const e = t2.data.field(this.field);
    return !(!At(e) || !e.arrayValue.values) && e.arrayValue.values.some((t3) => mt(this.value.arrayValue, t3));
  }
};
var Gt = class {
  constructor(t2, e) {
    this.position = t2, this.before = e;
  }
};
function zt(t2) {
  return `${t2.before ? "b" : "a"}:${t2.position.map((t3) => pt(t3)).join(",")}`;
}
var Ht = class {
  constructor(t2, e = "asc") {
    this.field = t2, this.dir = e;
  }
};
function Jt(t2, e) {
  return t2.dir === e.dir && t2.field.isEqual(e.field);
}
function Yt(t2, e, n2) {
  let s = 0;
  for (let i = 0; i < t2.position.length; i++) {
    const r2 = e[i], o = t2.position[i];
    if (r2.field.isKeyField())
      s = dt.comparator(dt.fromName(o.referenceValue), n2.key);
    else {
      s = gt(o, n2.data.field(r2.field));
    }
    if ("desc" === r2.dir && (s *= -1), 0 !== s)
      break;
  }
  return t2.before ? s <= 0 : s < 0;
}
function Xt(t2, e) {
  if (null === t2)
    return null === e;
  if (null === e)
    return false;
  if (t2.before !== e.before || t2.position.length !== e.position.length)
    return false;
  for (let n2 = 0; n2 < t2.position.length; n2++) {
    if (!_t(t2.position[n2], e.position[n2]))
      return false;
  }
  return true;
}
var Zt = class {
  /**
   * Initializes a Query with a path and optional additional query constraints.
   * Path must currently be empty if this is a collection group query.
   */
  constructor(t2, e = null, n2 = [], s = [], i = null, r2 = "F", o = null, c = null) {
    this.path = t2, this.collectionGroup = e, this.explicitOrderBy = n2, this.filters = s, this.limit = i, this.limitType = r2, this.startAt = o, this.endAt = c, this.p = null, // The corresponding `Target` of this `Query` instance.
    this.T = null, this.startAt, this.endAt;
  }
};
function te(t2, e, n2, s, i, r2, o, c) {
  return new Zt(t2, e, n2, s, i, r2, o, c);
}
function ee(t2) {
  return new Zt(t2);
}
function ne(t2) {
  return !ht(t2.limit) && "F" === t2.limitType;
}
function se(t2) {
  return !ht(t2.limit) && "L" === t2.limitType;
}
function ie(t2) {
  return t2.explicitOrderBy.length > 0 ? t2.explicitOrderBy[0].field : null;
}
function re(t2) {
  for (const e of t2.filters)
    if (e.g())
      return e.field;
  return null;
}
function oe(t2) {
  return null !== t2.collectionGroup;
}
function ce(t2) {
  const e = B(t2);
  if (null === e.p) {
    e.p = [];
    const t3 = re(e), n2 = ie(e);
    if (null !== t3 && null === n2)
      t3.isKeyField() || e.p.push(new Ht(t3)), e.p.push(new Ht(
        tt.keyField(),
        "asc"
        /* ASCENDING */
      ));
    else {
      let t4 = false;
      for (const n3 of e.explicitOrderBy)
        e.p.push(n3), n3.field.isKeyField() && (t4 = true);
      if (!t4) {
        const t5 = e.explicitOrderBy.length > 0 ? e.explicitOrderBy[e.explicitOrderBy.length - 1].dir : "asc";
        e.p.push(new Ht(tt.keyField(), t5));
      }
    }
  }
  return e.p;
}
function ue(t2) {
  const e = B(t2);
  if (!e.T)
    if ("F" === e.limitType)
      e.T = Nt(e.path, e.collectionGroup, ce(e), e.filters, e.limit, e.startAt, e.endAt);
    else {
      const t3 = [];
      for (const n3 of ce(e)) {
        const e2 = "desc" === n3.dir ? "asc" : "desc";
        t3.push(new Ht(n3.field, e2));
      }
      const n2 = e.endAt ? new Gt(e.endAt.position, !e.endAt.before) : null, s = e.startAt ? new Gt(e.startAt.position, !e.startAt.before) : null;
      e.T = Nt(e.path, e.collectionGroup, t3, e.filters, e.limit, n2, s);
    }
  return e.T;
}
function ae(t2, e, n2) {
  return new Zt(t2.path, t2.collectionGroup, t2.explicitOrderBy.slice(), t2.filters.slice(), e, n2, t2.startAt, t2.endAt);
}
function he(t2, e) {
  return $t(ue(t2), ue(e)) && t2.limitType === e.limitType;
}
function le(t2) {
  return `${xt(ue(t2))}|lt:${t2.limitType}`;
}
function fe(t2) {
  return `Query(target=${kt(ue(t2))}; limitType=${t2.limitType})`;
}
function de(t2, e) {
  return e.isFoundDocument() && function(t3, e2) {
    const n2 = e2.key.path;
    return null !== t3.collectionGroup ? e2.key.hasCollectionId(t3.collectionGroup) && t3.path.isPrefixOf(n2) : dt.isDocumentKey(t3.path) ? t3.path.isEqual(n2) : t3.path.isImmediateParentOf(n2);
  }(t2, e) && function(t3, e2) {
    for (const n2 of t3.explicitOrderBy)
      if (!n2.field.isKeyField() && null === e2.data.field(n2.field))
        return false;
    return true;
  }(t2, e) && function(t3, e2) {
    for (const n2 of t3.filters)
      if (!n2.matches(e2))
        return false;
    return true;
  }(t2, e) && function(t3, e2) {
    if (t3.startAt && !Yt(t3.startAt, ce(t3), e2))
      return false;
    if (t3.endAt && Yt(t3.endAt, ce(t3), e2))
      return false;
    return true;
  }(t2, e);
}
function we(t2) {
  return (e, n2) => {
    let s = false;
    for (const i of ce(t2)) {
      const t3 = _e(i, e, n2);
      if (0 !== t3)
        return t3;
      s = s || i.field.isKeyField();
    }
    return 0;
  };
}
function _e(t2, e, n2) {
  const s = t2.field.isKeyField() ? dt.comparator(e.key, n2.key) : function(t3, e2, n3) {
    const s2 = e2.data.field(t3), i = n3.data.field(t3);
    return null !== s2 && null !== i ? gt(s2, i) : M2();
  }(t2.field, e, n2);
  switch (t2.dir) {
    case "asc":
      return s;
    case "desc":
      return -1 * s;
    default:
      return M2();
  }
}
function me(t2, e) {
  if (t2.I) {
    if (isNaN(e))
      return {
        doubleValue: "NaN"
      };
    if (e === 1 / 0)
      return {
        doubleValue: "Infinity"
      };
    if (e === -1 / 0)
      return {
        doubleValue: "-Infinity"
      };
  }
  return {
    doubleValue: lt(e) ? "-0" : e
  };
}
function ge(t2) {
  return {
    integerValue: "" + t2
  };
}
function ye(t2, e) {
  return ft(e) ? ge(e) : me(t2, e);
}
var pe = class {
  constructor() {
    this._ = void 0;
  }
};
function Ee(t2, e, n2) {
  return t2 instanceof Ae ? function(t3, e2) {
    const n3 = {
      fields: {
        __type__: {
          stringValue: "server_timestamp"
        },
        __local_write_time__: {
          timestampValue: {
            seconds: t3.seconds,
            nanos: t3.nanoseconds
          }
        }
      }
    };
    return e2 && (n3.fields.__previous_value__ = e2), {
      mapValue: n3
    };
  }(n2, e) : t2 instanceof Re ? Pe(t2, e) : t2 instanceof be ? ve(t2, e) : function(t3, e2) {
    const n3 = Ie(t3, e2), s = Se(n3) + Se(t3.A);
    return It(n3) && It(t3.A) ? ge(s) : me(t3.R, s);
  }(t2, e);
}
function Te(t2, e, n2) {
  return t2 instanceof Re ? Pe(t2, e) : t2 instanceof be ? ve(t2, e) : n2;
}
function Ie(t2, e) {
  return t2 instanceof Ve ? It(n2 = e) || function(t3) {
    return !!t3 && "doubleValue" in t3;
  }(n2) ? e : {
    integerValue: 0
  } : null;
  var n2;
}
var Ae = class extends pe {
};
var Re = class extends pe {
  constructor(t2) {
    super(), this.elements = t2;
  }
};
function Pe(t2, e) {
  const n2 = De(e);
  for (const e2 of t2.elements)
    n2.some((t3) => _t(t3, e2)) || n2.push(e2);
  return {
    arrayValue: {
      values: n2
    }
  };
}
var be = class extends pe {
  constructor(t2) {
    super(), this.elements = t2;
  }
};
function ve(t2, e) {
  let n2 = De(e);
  for (const e2 of t2.elements)
    n2 = n2.filter((t3) => !_t(t3, e2));
  return {
    arrayValue: {
      values: n2
    }
  };
}
var Ve = class extends pe {
  constructor(t2, e) {
    super(), this.R = t2, this.A = e;
  }
};
function Se(t2) {
  return rt(t2.integerValue || t2.doubleValue);
}
function De(t2) {
  return At(t2) && t2.arrayValue.values ? t2.arrayValue.values.slice() : [];
}
var Ce = class {
  constructor(t2, e) {
    this.field = t2, this.transform = e;
  }
};
function Ne(t2, e) {
  return t2.field.isEqual(e.field) && function(t3, e2) {
    return t3 instanceof Re && e2 instanceof Re || t3 instanceof be && e2 instanceof be ? Q2(t3.elements, e2.elements, _t) : t3 instanceof Ve && e2 instanceof Ve ? _t(t3.A, e2.A) : t3 instanceof Ae && e2 instanceof Ae;
  }(t2.transform, e.transform);
}
var xe = class {
  constructor(t2, e) {
    this.version = t2, this.transformResults = e;
  }
};
var ke = class {
  constructor(t2, e) {
    this.updateTime = t2, this.exists = e;
  }
  /** Creates a new empty Precondition. */
  static none() {
    return new ke();
  }
  /** Creates a new Precondition with an exists flag. */
  static exists(t2) {
    return new ke(void 0, t2);
  }
  /** Creates a new Precondition based on a version a document exists at. */
  static updateTime(t2) {
    return new ke(t2);
  }
  /** Returns whether this Precondition is empty. */
  get isNone() {
    return void 0 === this.updateTime && void 0 === this.exists;
  }
  isEqual(t2) {
    return this.exists === t2.exists && (this.updateTime ? !!t2.updateTime && this.updateTime.isEqual(t2.updateTime) : !t2.updateTime);
  }
};
function $e(t2, e) {
  return void 0 !== t2.updateTime ? e.isFoundDocument() && e.version.isEqual(t2.updateTime) : void 0 === t2.exists || t2.exists === e.isFoundDocument();
}
var Oe = class {
};
function Fe(t2, e, n2) {
  t2 instanceof qe ? function(t3, e2, n3) {
    const s = t3.value.clone(), i = je(t3.fieldTransforms, e2, n3.transformResults);
    s.setAll(i), e2.convertToFoundDocument(n3.version, s).setHasCommittedMutations();
  }(t2, e, n2) : t2 instanceof Ke ? function(t3, e2, n3) {
    if (!$e(t3.precondition, e2))
      return void e2.convertToUnknownDocument(n3.version);
    const s = je(t3.fieldTransforms, e2, n3.transformResults), i = e2.data;
    i.setAll(Qe(t3)), i.setAll(s), e2.convertToFoundDocument(n3.version, i).setHasCommittedMutations();
  }(t2, e, n2) : function(t3, e2, n3) {
    e2.convertToNoDocument(n3.version).setHasCommittedMutations();
  }(0, e, n2);
}
function Me(t2, e, n2) {
  t2 instanceof qe ? function(t3, e2, n3) {
    if (!$e(t3.precondition, e2))
      return;
    const s = t3.value.clone(), i = We(t3.fieldTransforms, n3, e2);
    s.setAll(i), e2.convertToFoundDocument(Ue(e2), s).setHasLocalMutations();
  }(t2, e, n2) : t2 instanceof Ke ? function(t3, e2, n3) {
    if (!$e(t3.precondition, e2))
      return;
    const s = We(t3.fieldTransforms, n3, e2), i = e2.data;
    i.setAll(Qe(t3)), i.setAll(s), e2.convertToFoundDocument(Ue(e2), i).setHasLocalMutations();
  }(t2, e, n2) : function(t3, e2) {
    $e(t3.precondition, e2) && // We don't call `setHasLocalMutations()` since we want to be backwards
    // compatible with the existing SDK behavior.
    e2.convertToNoDocument(G2.min());
  }(t2, e);
}
function Le(t2, e) {
  let n2 = null;
  for (const s of t2.fieldTransforms) {
    const t3 = e.data.field(s.field), i = Ie(s.transform, t3 || null);
    null != i && (null == n2 && (n2 = Vt.empty()), n2.set(s.field, i));
  }
  return n2 || null;
}
function Be(t2, e) {
  return t2.type === e.type && (!!t2.key.isEqual(e.key) && (!!t2.precondition.isEqual(e.precondition) && (!!function(t3, e2) {
    return void 0 === t3 && void 0 === e2 || !(!t3 || !e2) && Q2(t3, e2, (t4, e3) => Ne(t4, e3));
  }(t2.fieldTransforms, e.fieldTransforms) && (0 === t2.type ? t2.value.isEqual(e.value) : 1 !== t2.type || t2.data.isEqual(e.data) && t2.fieldMask.isEqual(e.fieldMask)))));
}
function Ue(t2) {
  return t2.isFoundDocument() ? t2.version : G2.min();
}
var qe = class extends Oe {
  constructor(t2, e, n2, s = []) {
    super(), this.key = t2, this.value = e, this.precondition = n2, this.fieldTransforms = s, this.type = 0;
  }
};
var Ke = class extends Oe {
  constructor(t2, e, n2, s, i = []) {
    super(), this.key = t2, this.data = e, this.fieldMask = n2, this.precondition = s, this.fieldTransforms = i, this.type = 1;
  }
};
function Qe(t2) {
  const e = /* @__PURE__ */ new Map();
  return t2.fieldMask.fields.forEach((n2) => {
    if (!n2.isEmpty()) {
      const s = t2.data.field(n2);
      e.set(n2, s);
    }
  }), e;
}
function je(t2, e, n2) {
  const s = /* @__PURE__ */ new Map();
  L2(t2.length === n2.length);
  for (let i = 0; i < n2.length; i++) {
    const r2 = t2[i], o = r2.transform, c = e.data.field(r2.field);
    s.set(r2.field, Te(o, c, n2[i]));
  }
  return s;
}
function We(t2, e, n2) {
  const s = /* @__PURE__ */ new Map();
  for (const i of t2) {
    const t3 = i.transform, r2 = n2.data.field(i.field);
    s.set(i.field, Ee(t3, r2, e));
  }
  return s;
}
var Ge = class extends Oe {
  constructor(t2, e) {
    super(), this.key = t2, this.precondition = e, this.type = 2, this.fieldTransforms = [];
  }
};
var ze = class extends Oe {
  constructor(t2, e) {
    super(), this.key = t2, this.precondition = e, this.type = 3, this.fieldTransforms = [];
  }
};
var He = class {
  // TODO(b/33078163): just use simplest form of existence filter for now
  constructor(t2) {
    this.count = t2;
  }
};
var Je;
var Ye;
function Xe(t2) {
  switch (t2) {
    case S2.OK:
      return M2();
    case S2.CANCELLED:
    case S2.UNKNOWN:
    case S2.DEADLINE_EXCEEDED:
    case S2.RESOURCE_EXHAUSTED:
    case S2.INTERNAL:
    case S2.UNAVAILABLE:
    case S2.UNAUTHENTICATED:
      return false;
    case S2.INVALID_ARGUMENT:
    case S2.NOT_FOUND:
    case S2.ALREADY_EXISTS:
    case S2.PERMISSION_DENIED:
    case S2.FAILED_PRECONDITION:
    case S2.ABORTED:
    case S2.OUT_OF_RANGE:
    case S2.UNIMPLEMENTED:
    case S2.DATA_LOSS:
      return true;
    default:
      return M2();
  }
}
function Ze(t2) {
  if (void 0 === t2)
    return $("GRPC error has no .code"), S2.UNKNOWN;
  switch (t2) {
    case Je.OK:
      return S2.OK;
    case Je.CANCELLED:
      return S2.CANCELLED;
    case Je.UNKNOWN:
      return S2.UNKNOWN;
    case Je.DEADLINE_EXCEEDED:
      return S2.DEADLINE_EXCEEDED;
    case Je.RESOURCE_EXHAUSTED:
      return S2.RESOURCE_EXHAUSTED;
    case Je.INTERNAL:
      return S2.INTERNAL;
    case Je.UNAVAILABLE:
      return S2.UNAVAILABLE;
    case Je.UNAUTHENTICATED:
      return S2.UNAUTHENTICATED;
    case Je.INVALID_ARGUMENT:
      return S2.INVALID_ARGUMENT;
    case Je.NOT_FOUND:
      return S2.NOT_FOUND;
    case Je.ALREADY_EXISTS:
      return S2.ALREADY_EXISTS;
    case Je.PERMISSION_DENIED:
      return S2.PERMISSION_DENIED;
    case Je.FAILED_PRECONDITION:
      return S2.FAILED_PRECONDITION;
    case Je.ABORTED:
      return S2.ABORTED;
    case Je.OUT_OF_RANGE:
      return S2.OUT_OF_RANGE;
    case Je.UNIMPLEMENTED:
      return S2.UNIMPLEMENTED;
    case Je.DATA_LOSS:
      return S2.DATA_LOSS;
    default:
      return M2();
  }
}
(Ye = Je || (Je = {}))[Ye.OK = 0] = "OK", Ye[Ye.CANCELLED = 1] = "CANCELLED", Ye[Ye.UNKNOWN = 2] = "UNKNOWN", Ye[Ye.INVALID_ARGUMENT = 3] = "INVALID_ARGUMENT", Ye[Ye.DEADLINE_EXCEEDED = 4] = "DEADLINE_EXCEEDED", Ye[Ye.NOT_FOUND = 5] = "NOT_FOUND", Ye[Ye.ALREADY_EXISTS = 6] = "ALREADY_EXISTS", Ye[Ye.PERMISSION_DENIED = 7] = "PERMISSION_DENIED", Ye[Ye.UNAUTHENTICATED = 16] = "UNAUTHENTICATED", Ye[Ye.RESOURCE_EXHAUSTED = 8] = "RESOURCE_EXHAUSTED", Ye[Ye.FAILED_PRECONDITION = 9] = "FAILED_PRECONDITION", Ye[Ye.ABORTED = 10] = "ABORTED", Ye[Ye.OUT_OF_RANGE = 11] = "OUT_OF_RANGE", Ye[Ye.UNIMPLEMENTED = 12] = "UNIMPLEMENTED", Ye[Ye.INTERNAL = 13] = "INTERNAL", Ye[Ye.UNAVAILABLE = 14] = "UNAVAILABLE", Ye[Ye.DATA_LOSS = 15] = "DATA_LOSS";
var tn = class {
  constructor(t2, e) {
    this.comparator = t2, this.root = e || nn.EMPTY;
  }
  // Returns a copy of the map, with the specified key/value added or replaced.
  insert(t2, e) {
    return new tn(this.comparator, this.root.insert(t2, e, this.comparator).copy(null, null, nn.BLACK, null, null));
  }
  // Returns a copy of the map, with the specified key removed.
  remove(t2) {
    return new tn(this.comparator, this.root.remove(t2, this.comparator).copy(null, null, nn.BLACK, null, null));
  }
  // Returns the value of the node with the given key, or null.
  get(t2) {
    let e = this.root;
    for (; !e.isEmpty(); ) {
      const n2 = this.comparator(t2, e.key);
      if (0 === n2)
        return e.value;
      n2 < 0 ? e = e.left : n2 > 0 && (e = e.right);
    }
    return null;
  }
  // Returns the index of the element in this sorted map, or -1 if it doesn't
  // exist.
  indexOf(t2) {
    let e = 0, n2 = this.root;
    for (; !n2.isEmpty(); ) {
      const s = this.comparator(t2, n2.key);
      if (0 === s)
        return e + n2.left.size;
      s < 0 ? n2 = n2.left : (
        // Count all nodes left of the node plus the node itself
        (e += n2.left.size + 1, n2 = n2.right)
      );
    }
    return -1;
  }
  isEmpty() {
    return this.root.isEmpty();
  }
  // Returns the total number of nodes in the map.
  get size() {
    return this.root.size;
  }
  // Returns the minimum key in the map.
  minKey() {
    return this.root.minKey();
  }
  // Returns the maximum key in the map.
  maxKey() {
    return this.root.maxKey();
  }
  // Traverses the map in key order and calls the specified action function
  // for each key/value pair. If action returns true, traversal is aborted.
  // Returns the first truthy value returned by action, or the last falsey
  // value returned by action.
  inorderTraversal(t2) {
    return this.root.inorderTraversal(t2);
  }
  forEach(t2) {
    this.inorderTraversal((e, n2) => (t2(e, n2), false));
  }
  toString() {
    const t2 = [];
    return this.inorderTraversal((e, n2) => (t2.push(`${e}:${n2}`), false)), `{${t2.join(", ")}}`;
  }
  // Traverses the map in reverse key order and calls the specified action
  // function for each key/value pair. If action returns true, traversal is
  // aborted.
  // Returns the first truthy value returned by action, or the last falsey
  // value returned by action.
  reverseTraversal(t2) {
    return this.root.reverseTraversal(t2);
  }
  // Returns an iterator over the SortedMap.
  getIterator() {
    return new en(this.root, null, this.comparator, false);
  }
  getIteratorFrom(t2) {
    return new en(this.root, t2, this.comparator, false);
  }
  getReverseIterator() {
    return new en(this.root, null, this.comparator, true);
  }
  getReverseIteratorFrom(t2) {
    return new en(this.root, t2, this.comparator, true);
  }
};
var en = class {
  constructor(t2, e, n2, s) {
    this.isReverse = s, this.nodeStack = [];
    let i = 1;
    for (; !t2.isEmpty(); )
      if (i = e ? n2(t2.key, e) : 1, // flip the comparison if we're going in reverse
      s && (i *= -1), i < 0)
        t2 = this.isReverse ? t2.left : t2.right;
      else {
        if (0 === i) {
          this.nodeStack.push(t2);
          break;
        }
        this.nodeStack.push(t2), t2 = this.isReverse ? t2.right : t2.left;
      }
  }
  getNext() {
    let t2 = this.nodeStack.pop();
    const e = {
      key: t2.key,
      value: t2.value
    };
    if (this.isReverse)
      for (t2 = t2.left; !t2.isEmpty(); )
        this.nodeStack.push(t2), t2 = t2.right;
    else
      for (t2 = t2.right; !t2.isEmpty(); )
        this.nodeStack.push(t2), t2 = t2.left;
    return e;
  }
  hasNext() {
    return this.nodeStack.length > 0;
  }
  peek() {
    if (0 === this.nodeStack.length)
      return null;
    const t2 = this.nodeStack[this.nodeStack.length - 1];
    return {
      key: t2.key,
      value: t2.value
    };
  }
};
var nn = class {
  constructor(t2, e, n2, s, i) {
    this.key = t2, this.value = e, this.color = null != n2 ? n2 : nn.RED, this.left = null != s ? s : nn.EMPTY, this.right = null != i ? i : nn.EMPTY, this.size = this.left.size + 1 + this.right.size;
  }
  // Returns a copy of the current node, optionally replacing pieces of it.
  copy(t2, e, n2, s, i) {
    return new nn(null != t2 ? t2 : this.key, null != e ? e : this.value, null != n2 ? n2 : this.color, null != s ? s : this.left, null != i ? i : this.right);
  }
  isEmpty() {
    return false;
  }
  // Traverses the tree in key order and calls the specified action function
  // for each node. If action returns true, traversal is aborted.
  // Returns the first truthy value returned by action, or the last falsey
  // value returned by action.
  inorderTraversal(t2) {
    return this.left.inorderTraversal(t2) || t2(this.key, this.value) || this.right.inorderTraversal(t2);
  }
  // Traverses the tree in reverse key order and calls the specified action
  // function for each node. If action returns true, traversal is aborted.
  // Returns the first truthy value returned by action, or the last falsey
  // value returned by action.
  reverseTraversal(t2) {
    return this.right.reverseTraversal(t2) || t2(this.key, this.value) || this.left.reverseTraversal(t2);
  }
  // Returns the minimum node in the tree.
  min() {
    return this.left.isEmpty() ? this : this.left.min();
  }
  // Returns the maximum key in the tree.
  minKey() {
    return this.min().key;
  }
  // Returns the maximum key in the tree.
  maxKey() {
    return this.right.isEmpty() ? this.key : this.right.maxKey();
  }
  // Returns new tree, with the key/value added.
  insert(t2, e, n2) {
    let s = this;
    const i = n2(t2, s.key);
    return s = i < 0 ? s.copy(null, null, null, s.left.insert(t2, e, n2), null) : 0 === i ? s.copy(null, e, null, null, null) : s.copy(null, null, null, null, s.right.insert(t2, e, n2)), s.fixUp();
  }
  removeMin() {
    if (this.left.isEmpty())
      return nn.EMPTY;
    let t2 = this;
    return t2.left.isRed() || t2.left.left.isRed() || (t2 = t2.moveRedLeft()), t2 = t2.copy(null, null, null, t2.left.removeMin(), null), t2.fixUp();
  }
  // Returns new tree, with the specified item removed.
  remove(t2, e) {
    let n2, s = this;
    if (e(t2, s.key) < 0)
      s.left.isEmpty() || s.left.isRed() || s.left.left.isRed() || (s = s.moveRedLeft()), s = s.copy(null, null, null, s.left.remove(t2, e), null);
    else {
      if (s.left.isRed() && (s = s.rotateRight()), s.right.isEmpty() || s.right.isRed() || s.right.left.isRed() || (s = s.moveRedRight()), 0 === e(t2, s.key)) {
        if (s.right.isEmpty())
          return nn.EMPTY;
        n2 = s.right.min(), s = s.copy(n2.key, n2.value, null, null, s.right.removeMin());
      }
      s = s.copy(null, null, null, null, s.right.remove(t2, e));
    }
    return s.fixUp();
  }
  isRed() {
    return this.color;
  }
  // Returns new tree after performing any needed rotations.
  fixUp() {
    let t2 = this;
    return t2.right.isRed() && !t2.left.isRed() && (t2 = t2.rotateLeft()), t2.left.isRed() && t2.left.left.isRed() && (t2 = t2.rotateRight()), t2.left.isRed() && t2.right.isRed() && (t2 = t2.colorFlip()), t2;
  }
  moveRedLeft() {
    let t2 = this.colorFlip();
    return t2.right.left.isRed() && (t2 = t2.copy(null, null, null, null, t2.right.rotateRight()), t2 = t2.rotateLeft(), t2 = t2.colorFlip()), t2;
  }
  moveRedRight() {
    let t2 = this.colorFlip();
    return t2.left.left.isRed() && (t2 = t2.rotateRight(), t2 = t2.colorFlip()), t2;
  }
  rotateLeft() {
    const t2 = this.copy(null, null, nn.RED, null, this.right.left);
    return this.right.copy(null, null, this.color, t2, null);
  }
  rotateRight() {
    const t2 = this.copy(null, null, nn.RED, this.left.right, null);
    return this.left.copy(null, null, this.color, null, t2);
  }
  colorFlip() {
    const t2 = this.left.copy(null, null, !this.left.color, null, null), e = this.right.copy(null, null, !this.right.color, null, null);
    return this.copy(null, null, !this.color, t2, e);
  }
  // For testing.
  checkMaxDepth() {
    const t2 = this.check();
    return Math.pow(2, t2) <= this.size + 1;
  }
  // In a balanced RB tree, the black-depth (number of black nodes) from root to
  // leaves is equal on both sides.  This function verifies that or asserts.
  check() {
    if (this.isRed() && this.left.isRed())
      throw M2();
    if (this.right.isRed())
      throw M2();
    const t2 = this.left.check();
    if (t2 !== this.right.check())
      throw M2();
    return t2 + (this.isRed() ? 0 : 1);
  }
};
nn.EMPTY = null, nn.RED = true, nn.BLACK = false;
nn.EMPTY = new // Represents an empty node (a leaf node in the Red-Black Tree).
class {
  constructor() {
    this.size = 0;
  }
  get key() {
    throw M2();
  }
  get value() {
    throw M2();
  }
  get color() {
    throw M2();
  }
  get left() {
    throw M2();
  }
  get right() {
    throw M2();
  }
  // Returns a copy of the current node.
  copy(t2, e, n2, s, i) {
    return this;
  }
  // Returns a copy of the tree, with the specified key/value added.
  insert(t2, e, n2) {
    return new nn(t2, e);
  }
  // Returns a copy of the tree, with the specified key removed.
  remove(t2, e) {
    return this;
  }
  isEmpty() {
    return true;
  }
  inorderTraversal(t2) {
    return false;
  }
  reverseTraversal(t2) {
    return false;
  }
  minKey() {
    return null;
  }
  maxKey() {
    return null;
  }
  isRed() {
    return false;
  }
  // For testing.
  checkMaxDepth() {
    return true;
  }
  check() {
    return 0;
  }
}();
var sn = class {
  constructor(t2) {
    this.comparator = t2, this.data = new tn(this.comparator);
  }
  has(t2) {
    return null !== this.data.get(t2);
  }
  first() {
    return this.data.minKey();
  }
  last() {
    return this.data.maxKey();
  }
  get size() {
    return this.data.size;
  }
  indexOf(t2) {
    return this.data.indexOf(t2);
  }
  /** Iterates elements in order defined by "comparator" */
  forEach(t2) {
    this.data.inorderTraversal((e, n2) => (t2(e), false));
  }
  /** Iterates over `elem`s such that: range[0] &lt;= elem &lt; range[1]. */
  forEachInRange(t2, e) {
    const n2 = this.data.getIteratorFrom(t2[0]);
    for (; n2.hasNext(); ) {
      const s = n2.getNext();
      if (this.comparator(s.key, t2[1]) >= 0)
        return;
      e(s.key);
    }
  }
  /**
   * Iterates over `elem`s such that: start &lt;= elem until false is returned.
   */
  forEachWhile(t2, e) {
    let n2;
    for (n2 = void 0 !== e ? this.data.getIteratorFrom(e) : this.data.getIterator(); n2.hasNext(); ) {
      if (!t2(n2.getNext().key))
        return;
    }
  }
  /** Finds the least element greater than or equal to `elem`. */
  firstAfterOrEqual(t2) {
    const e = this.data.getIteratorFrom(t2);
    return e.hasNext() ? e.getNext().key : null;
  }
  getIterator() {
    return new rn(this.data.getIterator());
  }
  getIteratorFrom(t2) {
    return new rn(this.data.getIteratorFrom(t2));
  }
  /** Inserts or updates an element */
  add(t2) {
    return this.copy(this.data.remove(t2).insert(t2, true));
  }
  /** Deletes an element */
  delete(t2) {
    return this.has(t2) ? this.copy(this.data.remove(t2)) : this;
  }
  isEmpty() {
    return this.data.isEmpty();
  }
  unionWith(t2) {
    let e = this;
    return e.size < t2.size && (e = t2, t2 = this), t2.forEach((t3) => {
      e = e.add(t3);
    }), e;
  }
  isEqual(t2) {
    if (!(t2 instanceof sn))
      return false;
    if (this.size !== t2.size)
      return false;
    const e = this.data.getIterator(), n2 = t2.data.getIterator();
    for (; e.hasNext(); ) {
      const t3 = e.getNext().key, s = n2.getNext().key;
      if (0 !== this.comparator(t3, s))
        return false;
    }
    return true;
  }
  toArray() {
    const t2 = [];
    return this.forEach((e) => {
      t2.push(e);
    }), t2;
  }
  toString() {
    const t2 = [];
    return this.forEach((e) => t2.push(e)), "SortedSet(" + t2.toString() + ")";
  }
  copy(t2) {
    const e = new sn(this.comparator);
    return e.data = t2, e;
  }
};
var rn = class {
  constructor(t2) {
    this.iter = t2;
  }
  getNext() {
    return this.iter.getNext().key;
  }
  hasNext() {
    return this.iter.hasNext();
  }
};
var on = new tn(dt.comparator);
function cn() {
  return on;
}
var un = new tn(dt.comparator);
function an() {
  return un;
}
var hn = new tn(dt.comparator);
function ln() {
  return hn;
}
var fn = new sn(dt.comparator);
function dn(...t2) {
  let e = fn;
  for (const n2 of t2)
    e = e.add(n2);
  return e;
}
var wn = new sn(K2);
function _n() {
  return wn;
}
var mn = class {
  constructor(t2, e, n2, s, i) {
    this.snapshotVersion = t2, this.targetChanges = e, this.targetMismatches = n2, this.documentUpdates = s, this.resolvedLimboDocuments = i;
  }
  /**
   * HACK: Views require RemoteEvents in order to determine whether the view is
   * CURRENT, but secondary tabs don't receive remote events. So this method is
   * used to create a synthesized RemoteEvent that can be used to apply a
   * CURRENT status change to a View, for queries executed in a different tab.
   */
  // PORTING NOTE: Multi-tab only
  static createSynthesizedRemoteEventForCurrentChange(t2, e) {
    const n2 = /* @__PURE__ */ new Map();
    return n2.set(t2, gn.createSynthesizedTargetChangeForCurrentChange(t2, e)), new mn(G2.min(), n2, _n(), cn(), dn());
  }
};
var gn = class {
  constructor(t2, e, n2, s, i) {
    this.resumeToken = t2, this.current = e, this.addedDocuments = n2, this.modifiedDocuments = s, this.removedDocuments = i;
  }
  /**
   * This method is used to create a synthesized TargetChanges that can be used to
   * apply a CURRENT status change to a View (for queries executed in a different
   * tab) or for new queries (to raise snapshots with correct CURRENT status).
   */
  static createSynthesizedTargetChangeForCurrentChange(t2, e) {
    return new gn(nt.EMPTY_BYTE_STRING, e, dn(), dn(), dn());
  }
};
var yn = class {
  constructor(t2, e, n2, s) {
    this.P = t2, this.removedTargetIds = e, this.key = n2, this.v = s;
  }
};
var pn = class {
  constructor(t2, e) {
    this.targetId = t2, this.V = e;
  }
};
var En = class {
  constructor(t2, e, n2 = nt.EMPTY_BYTE_STRING, s = null) {
    this.state = t2, this.targetIds = e, this.resumeToken = n2, this.cause = s;
  }
};
var Tn = class {
  constructor() {
    this.S = 0, /**
     * Keeps track of the document changes since the last raised snapshot.
     *
     * These changes are continuously updated as we receive document updates and
     * always reflect the current set of changes against the last issued snapshot.
     */
    this.D = Rn(), /** See public getters for explanations of these fields. */
    this.C = nt.EMPTY_BYTE_STRING, this.N = false, /**
     * Whether this target state should be included in the next snapshot. We
     * initialize to true so that newly-added targets are included in the next
     * RemoteEvent.
     */
    this.k = true;
  }
  /**
   * Whether this target has been marked 'current'.
   *
   * 'Current' has special meaning in the RPC protocol: It implies that the
   * Watch backend has sent us all changes up to the point at which the target
   * was added and that the target is consistent with the rest of the watch
   * stream.
   */
  get current() {
    return this.N;
  }
  /** The last resume token sent to us for this target. */
  get resumeToken() {
    return this.C;
  }
  /** Whether this target has pending target adds or target removes. */
  get $() {
    return 0 !== this.S;
  }
  /** Whether we have modified any state that should trigger a snapshot. */
  get O() {
    return this.k;
  }
  /**
   * Applies the resume token to the TargetChange, but only when it has a new
   * value. Empty resumeTokens are discarded.
   */
  F(t2) {
    t2.approximateByteSize() > 0 && (this.k = true, this.C = t2);
  }
  /**
   * Creates a target change from the current set of changes.
   *
   * To reset the document changes after raising this snapshot, call
   * `clearPendingChanges()`.
   */
  M() {
    let t2 = dn(), e = dn(), n2 = dn();
    return this.D.forEach((s, i) => {
      switch (i) {
        case 0:
          t2 = t2.add(s);
          break;
        case 2:
          e = e.add(s);
          break;
        case 1:
          n2 = n2.add(s);
          break;
        default:
          M2();
      }
    }), new gn(this.C, this.N, t2, e, n2);
  }
  /**
   * Resets the document changes and sets `hasPendingChanges` to false.
   */
  L() {
    this.k = false, this.D = Rn();
  }
  B(t2, e) {
    this.k = true, this.D = this.D.insert(t2, e);
  }
  U(t2) {
    this.k = true, this.D = this.D.remove(t2);
  }
  q() {
    this.S += 1;
  }
  K() {
    this.S -= 1;
  }
  j() {
    this.k = true, this.N = true;
  }
};
var In = class {
  constructor(t2) {
    this.W = t2, /** The internal state of all tracked targets. */
    this.G = /* @__PURE__ */ new Map(), /** Keeps track of the documents to update since the last raised snapshot. */
    this.H = cn(), /** A mapping of document keys to their set of target IDs. */
    this.J = An(), /**
     * A list of targets with existence filter mismatches. These targets are
     * known to be inconsistent and their listens needs to be re-established by
     * RemoteStore.
     */
    this.Y = new sn(K2);
  }
  /**
   * Processes and adds the DocumentWatchChange to the current set of changes.
   */
  X(t2) {
    for (const e of t2.P)
      t2.v && t2.v.isFoundDocument() ? this.Z(e, t2.v) : this.tt(e, t2.key, t2.v);
    for (const e of t2.removedTargetIds)
      this.tt(e, t2.key, t2.v);
  }
  /** Processes and adds the WatchTargetChange to the current set of changes. */
  et(t2) {
    this.forEachTarget(t2, (e) => {
      const n2 = this.nt(e);
      switch (t2.state) {
        case 0:
          this.st(e) && n2.F(t2.resumeToken);
          break;
        case 1:
          n2.K(), n2.$ || // We have a freshly added target, so we need to reset any state
          // that we had previously. This can happen e.g. when remove and add
          // back a target for existence filter mismatches.
          n2.L(), n2.F(t2.resumeToken);
          break;
        case 2:
          n2.K(), n2.$ || this.removeTarget(e);
          break;
        case 3:
          this.st(e) && (n2.j(), n2.F(t2.resumeToken));
          break;
        case 4:
          this.st(e) && // Reset the target and synthesizes removes for all existing
          // documents. The backend will re-add any documents that still
          // match the target before it sends the next global snapshot.
          (this.it(e), n2.F(t2.resumeToken));
          break;
        default:
          M2();
      }
    });
  }
  /**
   * Iterates over all targetIds that the watch change applies to: either the
   * targetIds explicitly listed in the change or the targetIds of all currently
   * active targets.
   */
  forEachTarget(t2, e) {
    t2.targetIds.length > 0 ? t2.targetIds.forEach(e) : this.G.forEach((t3, n2) => {
      this.st(n2) && e(n2);
    });
  }
  /**
   * Handles existence filters and synthesizes deletes for filter mismatches.
   * Targets that are invalidated by filter mismatches are added to
   * `pendingTargetResets`.
   */
  rt(t2) {
    const e = t2.targetId, n2 = t2.V.count, s = this.ot(e);
    if (s) {
      const t3 = s.target;
      if (Ot(t3))
        if (0 === n2) {
          const n3 = new dt(t3.path);
          this.tt(e, n3, Dt.newNoDocument(n3, G2.min()));
        } else
          L2(1 === n2);
      else {
        this.ct(e) !== n2 && // Existence filter mismatch: We reset the mapping and raise a new
        // snapshot with `isFromCache:true`.
        (this.it(e), this.Y = this.Y.add(e));
      }
    }
  }
  /**
   * Converts the currently accumulated state into a remote event at the
   * provided snapshot version. Resets the accumulated changes before returning.
   */
  ut(t2) {
    const e = /* @__PURE__ */ new Map();
    this.G.forEach((n3, s2) => {
      const i = this.ot(s2);
      if (i) {
        if (n3.current && Ot(i.target)) {
          const e2 = new dt(i.target.path);
          null !== this.H.get(e2) || this.at(s2, e2) || this.tt(s2, e2, Dt.newNoDocument(e2, t2));
        }
        n3.O && (e.set(s2, n3.M()), n3.L());
      }
    });
    let n2 = dn();
    this.J.forEach((t3, e2) => {
      let s2 = true;
      e2.forEachWhile((t4) => {
        const e3 = this.ot(t4);
        return !e3 || 2 === e3.purpose || (s2 = false, false);
      }), s2 && (n2 = n2.add(t3));
    });
    const s = new mn(t2, e, this.Y, this.H, n2);
    return this.H = cn(), this.J = An(), this.Y = new sn(K2), s;
  }
  /**
   * Adds the provided document to the internal list of document updates and
   * its document key to the given target's mapping.
   */
  // Visible for testing.
  Z(t2, e) {
    if (!this.st(t2))
      return;
    const n2 = this.at(t2, e.key) ? 2 : 0;
    this.nt(t2).B(e.key, n2), this.H = this.H.insert(e.key, e), this.J = this.J.insert(e.key, this.ht(e.key).add(t2));
  }
  /**
   * Removes the provided document from the target mapping. If the
   * document no longer matches the target, but the document's state is still
   * known (e.g. we know that the document was deleted or we received the change
   * that caused the filter mismatch), the new document can be provided
   * to update the remote document cache.
   */
  // Visible for testing.
  tt(t2, e, n2) {
    if (!this.st(t2))
      return;
    const s = this.nt(t2);
    this.at(t2, e) ? s.B(
      e,
      1
      /* Removed */
    ) : (
      // The document may have entered and left the target before we raised a
      // snapshot, so we can just ignore the change.
      s.U(e)
    ), this.J = this.J.insert(e, this.ht(e).delete(t2)), n2 && (this.H = this.H.insert(e, n2));
  }
  removeTarget(t2) {
    this.G.delete(t2);
  }
  /**
   * Returns the current count of documents in the target. This includes both
   * the number of documents that the LocalStore considers to be part of the
   * target as well as any accumulated changes.
   */
  ct(t2) {
    const e = this.nt(t2).M();
    return this.W.getRemoteKeysForTarget(t2).size + e.addedDocuments.size - e.removedDocuments.size;
  }
  /**
   * Increment the number of acks needed from watch before we can consider the
   * server to be 'in-sync' with the client's active targets.
   */
  q(t2) {
    this.nt(t2).q();
  }
  nt(t2) {
    let e = this.G.get(t2);
    return e || (e = new Tn(), this.G.set(t2, e)), e;
  }
  ht(t2) {
    let e = this.J.get(t2);
    return e || (e = new sn(K2), this.J = this.J.insert(t2, e)), e;
  }
  /**
   * Verifies that the user is still interested in this target (by calling
   * `getTargetDataForTarget()`) and that we are not waiting for pending ADDs
   * from watch.
   */
  st(t2) {
    const e = null !== this.ot(t2);
    return e || k2("WatchChangeAggregator", "Detected inactive target", t2), e;
  }
  /**
   * Returns the TargetData for an active target (i.e. a target that the user
   * is still interested in that has no outstanding target change requests).
   */
  ot(t2) {
    const e = this.G.get(t2);
    return e && e.$ ? null : this.W.lt(t2);
  }
  /**
   * Resets the state of a Watch target to its initial state (e.g. sets
   * 'current' to false, clears the resume token and removes its target mapping
   * from all documents).
   */
  it(t2) {
    this.G.set(t2, new Tn());
    this.W.getRemoteKeysForTarget(t2).forEach((e) => {
      this.tt(
        t2,
        e,
        /*updatedDocument=*/
        null
      );
    });
  }
  /**
   * Returns whether the LocalStore considers the document to be part of the
   * specified target.
   */
  at(t2, e) {
    return this.W.getRemoteKeysForTarget(t2).has(e);
  }
};
function An() {
  return new tn(dt.comparator);
}
function Rn() {
  return new tn(dt.comparator);
}
var Pn = (() => {
  const t2 = {
    asc: "ASCENDING",
    desc: "DESCENDING"
  };
  return t2;
})();
var bn = (() => {
  const t2 = {
    "<": "LESS_THAN",
    "<=": "LESS_THAN_OR_EQUAL",
    ">": "GREATER_THAN",
    ">=": "GREATER_THAN_OR_EQUAL",
    "==": "EQUAL",
    "!=": "NOT_EQUAL",
    "array-contains": "ARRAY_CONTAINS",
    in: "IN",
    "not-in": "NOT_IN",
    "array-contains-any": "ARRAY_CONTAINS_ANY"
  };
  return t2;
})();
var vn = class {
  constructor(t2, e) {
    this.databaseId = t2, this.I = e;
  }
};
function Vn(t2, e) {
  if (t2.I) {
    return `${new Date(1e3 * e.seconds).toISOString().replace(/\.\d*/, "").replace("Z", "")}.${("000000000" + e.nanoseconds).slice(-9)}Z`;
  }
  return {
    seconds: "" + e.seconds,
    nanos: e.nanoseconds
  };
}
function Sn(t2, e) {
  return t2.I ? e.toBase64() : e.toUint8Array();
}
function Dn(t2, e) {
  return Vn(t2, e.toTimestamp());
}
function Cn(t2) {
  return L2(!!t2), G2.fromTimestamp(function(t3) {
    const e = it(t3);
    return new W2(e.seconds, e.nanos);
  }(t2));
}
function Nn(t2, e) {
  return function(t3) {
    return new X2(["projects", t3.projectId, "databases", t3.database]);
  }(t2).child("documents").child(e).canonicalString();
}
function xn(t2) {
  const e = X2.fromString(t2);
  return L2(cs(e)), e;
}
function kn(t2, e) {
  return Nn(t2.databaseId, e.path);
}
function $n(t2, e) {
  const n2 = xn(e);
  if (n2.get(1) !== t2.databaseId.projectId)
    throw new D2(S2.INVALID_ARGUMENT, "Tried to deserialize key from different project: " + n2.get(1) + " vs " + t2.databaseId.projectId);
  if (n2.get(3) !== t2.databaseId.database)
    throw new D2(S2.INVALID_ARGUMENT, "Tried to deserialize key from different database: " + n2.get(3) + " vs " + t2.databaseId.database);
  return new dt(Ln(n2));
}
function On(t2, e) {
  return Nn(t2.databaseId, e);
}
function Fn(t2) {
  const e = xn(t2);
  return 4 === e.length ? X2.emptyPath() : Ln(e);
}
function Mn(t2) {
  return new X2(["projects", t2.databaseId.projectId, "databases", t2.databaseId.database]).canonicalString();
}
function Ln(t2) {
  return L2(t2.length > 4 && "documents" === t2.get(4)), t2.popFirst(5);
}
function Bn(t2, e, n2) {
  return {
    name: kn(t2, e),
    fields: n2.value.mapValue.fields
  };
}
function Un(t2, e, n2) {
  const s = $n(t2, e.name), i = Cn(e.updateTime), r2 = new Vt({
    mapValue: {
      fields: e.fields
    }
  }), o = Dt.newFoundDocument(s, i, r2);
  return n2 && o.setHasCommittedMutations(), n2 ? o.setHasCommittedMutations() : o;
}
function qn(t2, e) {
  return "found" in e ? function(t3, e2) {
    L2(!!e2.found), e2.found.name, e2.found.updateTime;
    const n2 = $n(t3, e2.found.name), s = Cn(e2.found.updateTime), i = new Vt({
      mapValue: {
        fields: e2.found.fields
      }
    });
    return Dt.newFoundDocument(n2, s, i);
  }(t2, e) : "missing" in e ? function(t3, e2) {
    L2(!!e2.missing), L2(!!e2.readTime);
    const n2 = $n(t3, e2.missing), s = Cn(e2.readTime);
    return Dt.newNoDocument(n2, s);
  }(t2, e) : M2();
}
function Kn(t2, e) {
  let n2;
  if ("targetChange" in e) {
    e.targetChange;
    const s = function(t3) {
      return "NO_CHANGE" === t3 ? 0 : "ADD" === t3 ? 1 : "REMOVE" === t3 ? 2 : "CURRENT" === t3 ? 3 : "RESET" === t3 ? 4 : M2();
    }(e.targetChange.targetChangeType || "NO_CHANGE"), i = e.targetChange.targetIds || [], r2 = function(t3, e2) {
      return t3.I ? (L2(void 0 === e2 || "string" == typeof e2), nt.fromBase64String(e2 || "")) : (L2(void 0 === e2 || e2 instanceof Uint8Array), nt.fromUint8Array(e2 || new Uint8Array()));
    }(t2, e.targetChange.resumeToken), o = e.targetChange.cause, c = o && function(t3) {
      const e2 = void 0 === t3.code ? S2.UNKNOWN : Ze(t3.code);
      return new D2(e2, t3.message || "");
    }(o);
    n2 = new En(s, i, r2, c || null);
  } else if ("documentChange" in e) {
    e.documentChange;
    const s = e.documentChange;
    s.document, s.document.name, s.document.updateTime;
    const i = $n(t2, s.document.name), r2 = Cn(s.document.updateTime), o = new Vt({
      mapValue: {
        fields: s.document.fields
      }
    }), c = Dt.newFoundDocument(i, r2, o), u2 = s.targetIds || [], a = s.removedTargetIds || [];
    n2 = new yn(u2, a, c.key, c);
  } else if ("documentDelete" in e) {
    e.documentDelete;
    const s = e.documentDelete;
    s.document;
    const i = $n(t2, s.document), r2 = s.readTime ? Cn(s.readTime) : G2.min(), o = Dt.newNoDocument(i, r2), c = s.removedTargetIds || [];
    n2 = new yn([], c, o.key, o);
  } else if ("documentRemove" in e) {
    e.documentRemove;
    const s = e.documentRemove;
    s.document;
    const i = $n(t2, s.document), r2 = s.removedTargetIds || [];
    n2 = new yn([], r2, i, null);
  } else {
    if (!("filter" in e))
      return M2();
    {
      e.filter;
      const t3 = e.filter;
      t3.targetId;
      const s = t3.count || 0, i = new He(s), r2 = t3.targetId;
      n2 = new pn(r2, i);
    }
  }
  return n2;
}
function Qn(t2, e) {
  let n2;
  if (e instanceof qe)
    n2 = {
      update: Bn(t2, e.key, e.value)
    };
  else if (e instanceof Ge)
    n2 = {
      delete: kn(t2, e.key)
    };
  else if (e instanceof Ke)
    n2 = {
      update: Bn(t2, e.key, e.data),
      updateMask: os(e.fieldMask)
    };
  else {
    if (!(e instanceof ze))
      return M2();
    n2 = {
      verify: kn(t2, e.key)
    };
  }
  return e.fieldTransforms.length > 0 && (n2.updateTransforms = e.fieldTransforms.map((t3) => function(t4, e2) {
    const n3 = e2.transform;
    if (n3 instanceof Ae)
      return {
        fieldPath: e2.field.canonicalString(),
        setToServerValue: "REQUEST_TIME"
      };
    if (n3 instanceof Re)
      return {
        fieldPath: e2.field.canonicalString(),
        appendMissingElements: {
          values: n3.elements
        }
      };
    if (n3 instanceof be)
      return {
        fieldPath: e2.field.canonicalString(),
        removeAllFromArray: {
          values: n3.elements
        }
      };
    if (n3 instanceof Ve)
      return {
        fieldPath: e2.field.canonicalString(),
        increment: n3.A
      };
    throw M2();
  }(0, t3))), e.precondition.isNone || (n2.currentDocument = function(t3, e2) {
    return void 0 !== e2.updateTime ? {
      updateTime: Dn(t3, e2.updateTime)
    } : void 0 !== e2.exists ? {
      exists: e2.exists
    } : M2();
  }(t2, e.precondition)), n2;
}
function jn(t2, e) {
  const n2 = e.currentDocument ? function(t3) {
    return void 0 !== t3.updateTime ? ke.updateTime(Cn(t3.updateTime)) : void 0 !== t3.exists ? ke.exists(t3.exists) : ke.none();
  }(e.currentDocument) : ke.none(), s = e.updateTransforms ? e.updateTransforms.map((e2) => function(t3, e3) {
    let n3 = null;
    if ("setToServerValue" in e3)
      L2("REQUEST_TIME" === e3.setToServerValue), n3 = new Ae();
    else if ("appendMissingElements" in e3) {
      const t4 = e3.appendMissingElements.values || [];
      n3 = new Re(t4);
    } else if ("removeAllFromArray" in e3) {
      const t4 = e3.removeAllFromArray.values || [];
      n3 = new be(t4);
    } else
      "increment" in e3 ? n3 = new Ve(t3, e3.increment) : M2();
    const s2 = tt.fromServerFormat(e3.fieldPath);
    return new Ce(s2, n3);
  }(t2, e2)) : [];
  if (e.update) {
    e.update.name;
    const i = $n(t2, e.update.name), r2 = new Vt({
      mapValue: {
        fields: e.update.fields
      }
    });
    if (e.updateMask) {
      const t3 = function(t4) {
        const e2 = t4.fieldPaths || [];
        return new et(e2.map((t5) => tt.fromServerFormat(t5)));
      }(e.updateMask);
      return new Ke(i, r2, t3, n2, s);
    }
    return new qe(i, r2, n2, s);
  }
  if (e.delete) {
    const s2 = $n(t2, e.delete);
    return new Ge(s2, n2);
  }
  if (e.verify) {
    const s2 = $n(t2, e.verify);
    return new ze(s2, n2);
  }
  return M2();
}
function Wn(t2, e) {
  return t2 && t2.length > 0 ? (L2(void 0 !== e), t2.map((t3) => function(t4, e2) {
    let n2 = t4.updateTime ? Cn(t4.updateTime) : Cn(e2);
    return n2.isEqual(G2.min()) && // The Firestore Emulator currently returns an update time of 0 for
    // deletes of non-existing documents (rather than null). This breaks the
    // test "get deleted doc while offline with source=cache" as NoDocuments
    // with version 0 are filtered by IndexedDb's RemoteDocumentCache.
    // TODO(#2149): Remove this when Emulator is fixed
    (n2 = Cn(e2)), new xe(n2, t4.transformResults || []);
  }(t3, e))) : [];
}
function Gn(t2, e) {
  return {
    documents: [On(t2, e.path)]
  };
}
function zn(t2, e) {
  const n2 = {
    structuredQuery: {}
  }, s = e.path;
  null !== e.collectionGroup ? (n2.parent = On(t2, s), n2.structuredQuery.from = [{
    collectionId: e.collectionGroup,
    allDescendants: true
  }]) : (n2.parent = On(t2, s.popLast()), n2.structuredQuery.from = [{
    collectionId: s.lastSegment()
  }]);
  const i = function(t3) {
    if (0 === t3.length)
      return;
    const e2 = t3.map((t4) => (
      // visible for testing
      function(t5) {
        if ("==" === t5.op) {
          if (Pt(t5.value))
            return {
              unaryFilter: {
                field: ns(t5.field),
                op: "IS_NAN"
              }
            };
          if (Rt(t5.value))
            return {
              unaryFilter: {
                field: ns(t5.field),
                op: "IS_NULL"
              }
            };
        } else if ("!=" === t5.op) {
          if (Pt(t5.value))
            return {
              unaryFilter: {
                field: ns(t5.field),
                op: "IS_NOT_NAN"
              }
            };
          if (Rt(t5.value))
            return {
              unaryFilter: {
                field: ns(t5.field),
                op: "IS_NOT_NULL"
              }
            };
        }
        return {
          fieldFilter: {
            field: ns(t5.field),
            op: es(t5.op),
            value: t5.value
          }
        };
      }(t4)
    ));
    if (1 === e2.length)
      return e2[0];
    return {
      compositeFilter: {
        op: "AND",
        filters: e2
      }
    };
  }(e.filters);
  i && (n2.structuredQuery.where = i);
  const r2 = function(t3) {
    if (0 === t3.length)
      return;
    return t3.map((t4) => (
      // visible for testing
      function(t5) {
        return {
          field: ns(t5.field),
          direction: ts(t5.dir)
        };
      }(t4)
    ));
  }(e.orderBy);
  r2 && (n2.structuredQuery.orderBy = r2);
  const o = function(t3, e2) {
    return t3.I || ht(e2) ? e2 : {
      value: e2
    };
  }(t2, e.limit);
  return null !== o && (n2.structuredQuery.limit = o), e.startAt && (n2.structuredQuery.startAt = Xn(e.startAt)), e.endAt && (n2.structuredQuery.endAt = Xn(e.endAt)), n2;
}
function Hn(t2) {
  let e = Fn(t2.parent);
  const n2 = t2.structuredQuery, s = n2.from ? n2.from.length : 0;
  let i = null;
  if (s > 0) {
    L2(1 === s);
    const t3 = n2.from[0];
    t3.allDescendants ? i = t3.collectionId : e = e.child(t3.collectionId);
  }
  let r2 = [];
  n2.where && (r2 = Yn(n2.where));
  let o = [];
  n2.orderBy && (o = n2.orderBy.map((t3) => function(t4) {
    return new Ht(
      ss(t4.field),
      // visible for testing
      function(t5) {
        switch (t5) {
          case "ASCENDING":
            return "asc";
          case "DESCENDING":
            return "desc";
          default:
            return;
        }
      }(t4.direction)
    );
  }(t3)));
  let c = null;
  n2.limit && (c = function(t3) {
    let e2;
    return e2 = "object" == typeof t3 ? t3.value : t3, ht(e2) ? null : e2;
  }(n2.limit));
  let u2 = null;
  n2.startAt && (u2 = Zn(n2.startAt));
  let a = null;
  return n2.endAt && (a = Zn(n2.endAt)), te(e, i, o, r2, c, "F", u2, a);
}
function Jn(t2, e) {
  const n2 = function(t3, e2) {
    switch (e2) {
      case 0:
        return null;
      case 1:
        return "existence-filter-mismatch";
      case 2:
        return "limbo-document";
      default:
        return M2();
    }
  }(0, e.purpose);
  return null == n2 ? null : {
    "goog-listen-tags": n2
  };
}
function Yn(t2) {
  return t2 ? void 0 !== t2.unaryFilter ? [rs(t2)] : void 0 !== t2.fieldFilter ? [is(t2)] : void 0 !== t2.compositeFilter ? t2.compositeFilter.filters.map((t3) => Yn(t3)).reduce((t3, e) => t3.concat(e)) : M2() : [];
}
function Xn(t2) {
  return {
    before: t2.before,
    values: t2.position
  };
}
function Zn(t2) {
  const e = !!t2.before, n2 = t2.values || [];
  return new Gt(n2, e);
}
function ts(t2) {
  return Pn[t2];
}
function es(t2) {
  return bn[t2];
}
function ns(t2) {
  return {
    fieldPath: t2.canonicalString()
  };
}
function ss(t2) {
  return tt.fromServerFormat(t2.fieldPath);
}
function is(t2) {
  return Ft.create(ss(t2.fieldFilter.field), function(t3) {
    switch (t3) {
      case "EQUAL":
        return "==";
      case "NOT_EQUAL":
        return "!=";
      case "GREATER_THAN":
        return ">";
      case "GREATER_THAN_OR_EQUAL":
        return ">=";
      case "LESS_THAN":
        return "<";
      case "LESS_THAN_OR_EQUAL":
        return "<=";
      case "ARRAY_CONTAINS":
        return "array-contains";
      case "IN":
        return "in";
      case "NOT_IN":
        return "not-in";
      case "ARRAY_CONTAINS_ANY":
        return "array-contains-any";
      case "OPERATOR_UNSPECIFIED":
      default:
        return M2();
    }
  }(t2.fieldFilter.op), t2.fieldFilter.value);
}
function rs(t2) {
  switch (t2.unaryFilter.op) {
    case "IS_NAN":
      const e = ss(t2.unaryFilter.field);
      return Ft.create(e, "==", {
        doubleValue: NaN
      });
    case "IS_NULL":
      const n2 = ss(t2.unaryFilter.field);
      return Ft.create(n2, "==", {
        nullValue: "NULL_VALUE"
      });
    case "IS_NOT_NAN":
      const s = ss(t2.unaryFilter.field);
      return Ft.create(s, "!=", {
        doubleValue: NaN
      });
    case "IS_NOT_NULL":
      const i = ss(t2.unaryFilter.field);
      return Ft.create(i, "!=", {
        nullValue: "NULL_VALUE"
      });
    case "OPERATOR_UNSPECIFIED":
    default:
      return M2();
  }
}
function os(t2) {
  const e = [];
  return t2.fields.forEach((t3) => e.push(t3.canonicalString())), {
    fieldPaths: e
  };
}
function cs(t2) {
  return t2.length >= 4 && "projects" === t2.get(0) && "databases" === t2.get(2);
}
function us(t2) {
  let e = "";
  for (let n2 = 0; n2 < t2.length; n2++)
    e.length > 0 && (e = hs(e)), e = as(t2.get(n2), e);
  return hs(e);
}
function as(t2, e) {
  let n2 = e;
  const s = t2.length;
  for (let e2 = 0; e2 < s; e2++) {
    const s2 = t2.charAt(e2);
    switch (s2) {
      case "\0":
        n2 += "";
        break;
      case "":
        n2 += "";
        break;
      default:
        n2 += s2;
    }
  }
  return n2;
}
function hs(t2) {
  return t2 + "";
}
function ls(t2) {
  const e = t2.length;
  if (L2(e >= 2), 2 === e)
    return L2("" === t2.charAt(0) && "" === t2.charAt(1)), X2.emptyPath();
  const n2 = e - 2, s = [];
  let i = "";
  for (let r2 = 0; r2 < e; ) {
    const e2 = t2.indexOf("", r2);
    (e2 < 0 || e2 > n2) && M2();
    switch (t2.charAt(e2 + 1)) {
      case "":
        const n3 = t2.substring(r2, e2);
        let o;
        0 === i.length ? (
          // Avoid copying for the common case of a segment that excludes \0
          // and \001
          o = n3
        ) : (i += n3, o = i, i = ""), s.push(o);
        break;
      case "":
        i += t2.substring(r2, e2), i += "\0";
        break;
      case "":
        i += t2.substring(r2, e2 + 1);
        break;
      default:
        M2();
    }
    r2 = e2 + 2;
  }
  return new X2(s);
}
var fs = class {
  constructor(t2, e) {
    this.seconds = t2, this.nanoseconds = e;
  }
};
var ds = class {
  constructor(t2, e, n2) {
    this.ownerId = t2, this.allowTabSynchronization = e, this.leaseTimestampMs = n2;
  }
};
ds.store = "owner", /**
 * The key string used for the single object that exists in the
 * DbPrimaryClient store.
 */
ds.key = "owner";
var ws = class {
  constructor(t2, e, n2) {
    this.userId = t2, this.lastAcknowledgedBatchId = e, this.lastStreamToken = n2;
  }
};
ws.store = "mutationQueues", /** Keys are automatically assigned via the userId property. */
ws.keyPath = "userId";
var _s = class {
  constructor(t2, e, n2, s, i) {
    this.userId = t2, this.batchId = e, this.localWriteTimeMs = n2, this.baseMutations = s, this.mutations = i;
  }
};
_s.store = "mutations", /** Keys are automatically assigned via the userId, batchId properties. */
_s.keyPath = "batchId", /** The index name for lookup of mutations by user. */
_s.userMutationsIndex = "userMutationsIndex", /** The user mutations index is keyed by [userId, batchId] pairs. */
_s.userMutationsKeyPath = ["userId", "batchId"];
var ms = class {
  constructor() {
  }
  /**
   * Creates a [userId] key for use in the DbDocumentMutations index to iterate
   * over all of a user's document mutations.
   */
  static prefixForUser(t2) {
    return [t2];
  }
  /**
   * Creates a [userId, encodedPath] key for use in the DbDocumentMutations
   * index to iterate over all at document mutations for a given path or lower.
   */
  static prefixForPath(t2, e) {
    return [t2, us(e)];
  }
  /**
   * Creates a full index key of [userId, encodedPath, batchId] for inserting
   * and deleting into the DbDocumentMutations index.
   */
  static key(t2, e, n2) {
    return [t2, us(e), n2];
  }
};
ms.store = "documentMutations", /**
 * Because we store all the useful information for this store in the key,
 * there is no useful information to store as the value. The raw (unencoded)
 * path cannot be stored because IndexedDb doesn't store prototype
 * information.
 */
ms.PLACEHOLDER = new ms();
var gs = class {
  constructor(t2, e) {
    this.path = t2, this.readTime = e;
  }
};
var ys = class {
  constructor(t2, e) {
    this.path = t2, this.version = e;
  }
};
var ps = class {
  // TODO: We are currently storing full document keys almost three times
  // (once as part of the primary key, once - partly - as `parentPath` and once
  // inside the encoded documents). During our next migration, we should
  // rewrite the primary key as parentPath + document ID which would allow us
  // to drop one value.
  constructor(t2, e, n2, s, i, r2) {
    this.unknownDocument = t2, this.noDocument = e, this.document = n2, this.hasCommittedMutations = s, this.readTime = i, this.parentPath = r2;
  }
};
ps.store = "remoteDocuments", /**
 * An index that provides access to all entries sorted by read time (which
 * corresponds to the last modification time of each row).
 *
 * This index is used to provide a changelog for Multi-Tab.
 */
ps.readTimeIndex = "readTimeIndex", ps.readTimeIndexPath = "readTime", /**
 * An index that provides access to documents in a collection sorted by read
 * time.
 *
 * This index is used to allow the RemoteDocumentCache to fetch newly changed
 * documents in a collection.
 */
ps.collectionReadTimeIndex = "collectionReadTimeIndex", ps.collectionReadTimeIndexPath = ["parentPath", "readTime"];
var Es = class {
  /**
   * @param byteSize - Approximately the total size in bytes of all the
   * documents in the document cache.
   */
  constructor(t2) {
    this.byteSize = t2;
  }
};
Es.store = "remoteDocumentGlobal", Es.key = "remoteDocumentGlobalKey";
var Ts = class {
  constructor(t2, e, n2, s, i, r2, o) {
    this.targetId = t2, this.canonicalId = e, this.readTime = n2, this.resumeToken = s, this.lastListenSequenceNumber = i, this.lastLimboFreeSnapshotVersion = r2, this.query = o;
  }
};
Ts.store = "targets", /** Keys are automatically assigned via the targetId property. */
Ts.keyPath = "targetId", /** The name of the queryTargets index. */
Ts.queryTargetsIndexName = "queryTargetsIndex", /**
 * The index of all canonicalIds to the targets that they match. This is not
 * a unique mapping because canonicalId does not promise a unique name for all
 * possible queries, so we append the targetId to make the mapping unique.
 */
Ts.queryTargetsKeyPath = ["canonicalId", "targetId"];
var Is = class {
  constructor(t2, e, n2) {
    this.targetId = t2, this.path = e, this.sequenceNumber = n2;
  }
};
Is.store = "targetDocuments", /** Keys are automatically assigned via the targetId, path properties. */
Is.keyPath = ["targetId", "path"], /** The index name for the reverse index. */
Is.documentTargetsIndex = "documentTargetsIndex", /** We also need to create the reverse index for these properties. */
Is.documentTargetsKeyPath = ["path", "targetId"];
var As = class {
  constructor(t2, e, n2, s) {
    this.highestTargetId = t2, this.highestListenSequenceNumber = e, this.lastRemoteSnapshotVersion = n2, this.targetCount = s;
  }
};
As.key = "targetGlobalKey", As.store = "targetGlobal";
var Rs = class {
  constructor(t2, e) {
    this.collectionId = t2, this.parent = e;
  }
};
Rs.store = "collectionParents", /** Keys are automatically assigned via the collectionId, parent properties. */
Rs.keyPath = ["collectionId", "parent"];
var Ps = class {
  constructor(t2, e, n2, s) {
    this.clientId = t2, this.updateTimeMs = e, this.networkEnabled = n2, this.inForeground = s;
  }
};
Ps.store = "clientMetadata", /** Keys are automatically assigned via the clientId properties. */
Ps.keyPath = "clientId";
var bs = class {
  constructor(t2, e, n2) {
    this.bundleId = t2, this.createTime = e, this.version = n2;
  }
};
bs.store = "bundles", bs.keyPath = "bundleId";
var vs = class {
  constructor(t2, e, n2) {
    this.name = t2, this.readTime = e, this.bundledQuery = n2;
  }
};
vs.store = "namedQueries", vs.keyPath = "name";
var Vs = [...[...[...[...[ws.store, _s.store, ms.store, ps.store, Ts.store, ds.store, As.store, Is.store], Ps.store], Es.store], Rs.store], bs.store, vs.store];
var Ss = "The current tab is not in the required state to perform this operation. It might be necessary to refresh the browser tab.";
var Ds = class {
  constructor() {
    this.onCommittedListeners = [];
  }
  addOnCommittedListener(t2) {
    this.onCommittedListeners.push(t2);
  }
  raiseOnCommittedEvent() {
    this.onCommittedListeners.forEach((t2) => t2());
  }
};
var Cs = class {
  constructor() {
    this.promise = new Promise((t2, e) => {
      this.resolve = t2, this.reject = e;
    });
  }
};
var Ns = class {
  constructor(t2) {
    this.nextCallback = null, this.catchCallback = null, // When the operation resolves, we'll set result or error and mark isDone.
    this.result = void 0, this.error = void 0, this.isDone = false, // Set to true when .then() or .catch() are called and prevents additional
    // chaining.
    this.callbackAttached = false, t2((t3) => {
      this.isDone = true, this.result = t3, this.nextCallback && // value should be defined unless T is Void, but we can't express
      // that in the type system.
      this.nextCallback(t3);
    }, (t3) => {
      this.isDone = true, this.error = t3, this.catchCallback && this.catchCallback(t3);
    });
  }
  catch(t2) {
    return this.next(void 0, t2);
  }
  next(t2, e) {
    return this.callbackAttached && M2(), this.callbackAttached = true, this.isDone ? this.error ? this.wrapFailure(e, this.error) : this.wrapSuccess(t2, this.result) : new Ns((n2, s) => {
      this.nextCallback = (e2) => {
        this.wrapSuccess(t2, e2).next(n2, s);
      }, this.catchCallback = (t3) => {
        this.wrapFailure(e, t3).next(n2, s);
      };
    });
  }
  toPromise() {
    return new Promise((t2, e) => {
      this.next(t2, e);
    });
  }
  wrapUserFunction(t2) {
    try {
      const e = t2();
      return e instanceof Ns ? e : Ns.resolve(e);
    } catch (t3) {
      return Ns.reject(t3);
    }
  }
  wrapSuccess(t2, e) {
    return t2 ? this.wrapUserFunction(() => t2(e)) : Ns.resolve(e);
  }
  wrapFailure(t2, e) {
    return t2 ? this.wrapUserFunction(() => t2(e)) : Ns.reject(e);
  }
  static resolve(t2) {
    return new Ns((e, n2) => {
      e(t2);
    });
  }
  static reject(t2) {
    return new Ns((e, n2) => {
      n2(t2);
    });
  }
  static waitFor(t2) {
    return new Ns((e, n2) => {
      let s = 0, i = 0, r2 = false;
      t2.forEach((t3) => {
        ++s, t3.next(() => {
          ++i, r2 && i === s && e();
        }, (t4) => n2(t4));
      }), r2 = true, i === s && e();
    });
  }
  /**
   * Given an array of predicate functions that asynchronously evaluate to a
   * boolean, implements a short-circuiting `or` between the results. Predicates
   * will be evaluated until one of them returns `true`, then stop. The final
   * result will be whether any of them returned `true`.
   */
  static or(t2) {
    let e = Ns.resolve(false);
    for (const n2 of t2)
      e = e.next((t3) => t3 ? Ns.resolve(t3) : n2());
    return e;
  }
  static forEach(t2, e) {
    const n2 = [];
    return t2.forEach((t3, s) => {
      n2.push(e.call(this, t3, s));
    }), this.waitFor(n2);
  }
};
var xs = class {
  constructor(t2, e) {
    this.action = t2, this.transaction = e, this.aborted = false, /**
     * A promise that resolves with the result of the IndexedDb transaction.
     */
    this.ft = new Cs(), this.transaction.oncomplete = () => {
      this.ft.resolve();
    }, this.transaction.onabort = () => {
      e.error ? this.ft.reject(new Os(t2, e.error)) : this.ft.resolve();
    }, this.transaction.onerror = (e2) => {
      const n2 = Us(e2.target.error);
      this.ft.reject(new Os(t2, n2));
    };
  }
  static open(t2, e, n2, s) {
    try {
      return new xs(e, t2.transaction(s, n2));
    } catch (t3) {
      throw new Os(e, t3);
    }
  }
  get dt() {
    return this.ft.promise;
  }
  abort(t2) {
    t2 && this.ft.reject(t2), this.aborted || (k2("SimpleDb", "Aborting transaction:", t2 ? t2.message : "Client-initiated abort"), this.aborted = true, this.transaction.abort());
  }
  /**
   * Returns a SimpleDbStore<KeyType, ValueType> for the specified store. All
   * operations performed on the SimpleDbStore happen within the context of this
   * transaction and it cannot be used anymore once the transaction is
   * completed.
   *
   * Note that we can't actually enforce that the KeyType and ValueType are
   * correct, but they allow type safety through the rest of the consuming code.
   */
  store(t2) {
    const e = this.transaction.objectStore(t2);
    return new Ms(e);
  }
};
var ks = class {
  /*
   * Creates a new SimpleDb wrapper for IndexedDb database `name`.
   *
   * Note that `version` must not be a downgrade. IndexedDB does not support
   * downgrading the schema version. We currently do not support any way to do
   * versioning outside of IndexedDB's versioning mechanism, as only
   * version-upgrade transactions are allowed to do things like create
   * objectstores.
   */
  constructor(t2, e, n2) {
    this.name = t2, this.version = e, this.wt = n2;
    12.2 === ks._t(getUA()) && $("Firestore persistence suffers from a bug in iOS 12.2 Safari that may cause your app to stop working. See https://stackoverflow.com/q/56496296/110915 for details and a potential workaround.");
  }
  /** Deletes the specified database. */
  static delete(t2) {
    return k2("SimpleDb", "Removing database:", t2), Ls(window.indexedDB.deleteDatabase(t2)).toPromise();
  }
  /** Returns true if IndexedDB is available in the current environment. */
  static gt() {
    if ("undefined" == typeof indexedDB)
      return false;
    if (ks.yt())
      return true;
    const t2 = getUA(), e = ks._t(t2), n2 = 0 < e && e < 10, s = ks.Et(t2), i = 0 < s && s < 4.5;
    return !(t2.indexOf("MSIE ") > 0 || t2.indexOf("Trident/") > 0 || t2.indexOf("Edge/") > 0 || n2 || i);
  }
  /**
   * Returns true if the backing IndexedDB store is the Node IndexedDBShim
   * (see https://github.com/axemclion/IndexedDBShim).
   */
  static yt() {
    var t2;
    return "undefined" != typeof process && "YES" === (null === (t2 = process.env) || void 0 === t2 ? void 0 : t2.Tt);
  }
  /** Helper to get a typed SimpleDbStore from a transaction. */
  static It(t2, e) {
    return t2.store(e);
  }
  // visible for testing
  /** Parse User Agent to determine iOS version. Returns -1 if not found. */
  static _t(t2) {
    const e = t2.match(/i(?:phone|pad|pod) os ([\d_]+)/i), n2 = e ? e[1].split("_").slice(0, 2).join(".") : "-1";
    return Number(n2);
  }
  // visible for testing
  /** Parse User Agent to determine Android version. Returns -1 if not found. */
  static Et(t2) {
    const e = t2.match(/Android ([\d.]+)/i), n2 = e ? e[1].split(".").slice(0, 2).join(".") : "-1";
    return Number(n2);
  }
  /**
   * Opens the specified database, creating or upgrading it if necessary.
   */
  async At(t2) {
    return this.db || (k2("SimpleDb", "Opening database:", this.name), this.db = await new Promise((e, n2) => {
      const s = indexedDB.open(this.name, this.version);
      s.onsuccess = (t3) => {
        const n3 = t3.target.result;
        e(n3);
      }, s.onblocked = () => {
        n2(new Os(t2, "Cannot upgrade IndexedDB schema while another tab is open. Close all tabs that access Firestore and reload this page to proceed."));
      }, s.onerror = (e2) => {
        const s2 = e2.target.error;
        "VersionError" === s2.name ? n2(new D2(S2.FAILED_PRECONDITION, "A newer version of the Firestore SDK was previously used and so the persisted data is not compatible with the version of the SDK you are now using. The SDK will operate with persistence disabled. If you need persistence, please re-upgrade to a newer version of the SDK or else clear the persisted IndexedDB data for your app to start fresh.")) : n2(new Os(t2, s2));
      }, s.onupgradeneeded = (t3) => {
        k2("SimpleDb", 'Database "' + this.name + '" requires upgrade from version:', t3.oldVersion);
        const e2 = t3.target.result;
        this.wt.Rt(e2, s.transaction, t3.oldVersion, this.version).next(() => {
          k2("SimpleDb", "Database upgrade to version " + this.version + " complete");
        });
      };
    })), this.Pt && (this.db.onversionchange = (t3) => this.Pt(t3)), this.db;
  }
  bt(t2) {
    this.Pt = t2, this.db && (this.db.onversionchange = (e) => t2(e));
  }
  async runTransaction(t2, e, n2, s) {
    const i = "readonly" === e;
    let r2 = 0;
    for (; ; ) {
      ++r2;
      try {
        this.db = await this.At(t2);
        const e2 = xs.open(this.db, t2, i ? "readonly" : "readwrite", n2), r3 = s(e2).catch((t3) => (
          // Abort the transaction if there was an error.
          (e2.abort(t3), Ns.reject(t3))
        )).toPromise();
        return r3.catch(() => {
        }), // Wait for the transaction to complete (i.e. IndexedDb's onsuccess event to
        // fire), but still return the original transactionFnResult back to the
        // caller.
        await e2.dt, r3;
      } catch (t3) {
        const e2 = "FirebaseError" !== t3.name && r2 < 3;
        if (k2("SimpleDb", "Transaction failed with error:", t3.message, "Retrying:", e2), this.close(), !e2)
          return Promise.reject(t3);
      }
    }
  }
  close() {
    this.db && this.db.close(), this.db = void 0;
  }
};
var $s = class {
  constructor(t2) {
    this.vt = t2, this.Vt = false, this.St = null;
  }
  get isDone() {
    return this.Vt;
  }
  get Dt() {
    return this.St;
  }
  set cursor(t2) {
    this.vt = t2;
  }
  /**
   * This function can be called to stop iteration at any point.
   */
  done() {
    this.Vt = true;
  }
  /**
   * This function can be called to skip to that next key, which could be
   * an index or a primary key.
   */
  Ct(t2) {
    this.St = t2;
  }
  /**
   * Delete the current cursor value from the object store.
   *
   * NOTE: You CANNOT do this with a keysOnly query.
   */
  delete() {
    return Ls(this.vt.delete());
  }
};
var Os = class extends D2 {
  constructor(t2, e) {
    super(S2.UNAVAILABLE, `IndexedDB transaction '${t2}' failed: ${e}`), this.name = "IndexedDbTransactionError";
  }
};
function Fs(t2) {
  return "IndexedDbTransactionError" === t2.name;
}
var Ms = class {
  constructor(t2) {
    this.store = t2;
  }
  put(t2, e) {
    let n2;
    return void 0 !== e ? (k2("SimpleDb", "PUT", this.store.name, t2, e), n2 = this.store.put(e, t2)) : (k2("SimpleDb", "PUT", this.store.name, "<auto-key>", t2), n2 = this.store.put(t2)), Ls(n2);
  }
  /**
   * Adds a new value into an Object Store and returns the new key. Similar to
   * IndexedDb's `add()`, this method will fail on primary key collisions.
   *
   * @param value - The object to write.
   * @returns The key of the value to add.
   */
  add(t2) {
    k2("SimpleDb", "ADD", this.store.name, t2, t2);
    return Ls(this.store.add(t2));
  }
  /**
   * Gets the object with the specified key from the specified store, or null
   * if no object exists with the specified key.
   *
   * @key The key of the object to get.
   * @returns The object with the specified key or null if no object exists.
   */
  get(t2) {
    return Ls(this.store.get(t2)).next((e) => (
      // Normalize nonexistence to null.
      (void 0 === e && (e = null), k2("SimpleDb", "GET", this.store.name, t2, e), e)
    ));
  }
  delete(t2) {
    k2("SimpleDb", "DELETE", this.store.name, t2);
    return Ls(this.store.delete(t2));
  }
  /**
   * If we ever need more of the count variants, we can add overloads. For now,
   * all we need is to count everything in a store.
   *
   * Returns the number of rows in the store.
   */
  count() {
    k2("SimpleDb", "COUNT", this.store.name);
    return Ls(this.store.count());
  }
  Nt(t2, e) {
    const n2 = this.cursor(this.options(t2, e)), s = [];
    return this.xt(n2, (t3, e2) => {
      s.push(e2);
    }).next(() => s);
  }
  kt(t2, e) {
    k2("SimpleDb", "DELETE ALL", this.store.name);
    const n2 = this.options(t2, e);
    n2.$t = false;
    const s = this.cursor(n2);
    return this.xt(s, (t3, e2, n3) => n3.delete());
  }
  Ot(t2, e) {
    let n2;
    e ? n2 = t2 : (n2 = {}, e = t2);
    const s = this.cursor(n2);
    return this.xt(s, e);
  }
  /**
   * Iterates over a store, but waits for the given callback to complete for
   * each entry before iterating the next entry. This allows the callback to do
   * asynchronous work to determine if this iteration should continue.
   *
   * The provided callback should return `true` to continue iteration, and
   * `false` otherwise.
   */
  Ft(t2) {
    const e = this.cursor({});
    return new Ns((n2, s) => {
      e.onerror = (t3) => {
        const e2 = Us(t3.target.error);
        s(e2);
      }, e.onsuccess = (e2) => {
        const s2 = e2.target.result;
        s2 ? t2(s2.primaryKey, s2.value).next((t3) => {
          t3 ? s2.continue() : n2();
        }) : n2();
      };
    });
  }
  xt(t2, e) {
    const n2 = [];
    return new Ns((s, i) => {
      t2.onerror = (t3) => {
        i(t3.target.error);
      }, t2.onsuccess = (t3) => {
        const i2 = t3.target.result;
        if (!i2)
          return void s();
        const r2 = new $s(i2), o = e(i2.primaryKey, i2.value, r2);
        if (o instanceof Ns) {
          const t4 = o.catch((t5) => (r2.done(), Ns.reject(t5)));
          n2.push(t4);
        }
        r2.isDone ? s() : null === r2.Dt ? i2.continue() : i2.continue(r2.Dt);
      };
    }).next(() => Ns.waitFor(n2));
  }
  options(t2, e) {
    let n2;
    return void 0 !== t2 && ("string" == typeof t2 ? n2 = t2 : e = t2), {
      index: n2,
      range: e
    };
  }
  cursor(t2) {
    let e = "next";
    if (t2.reverse && (e = "prev"), t2.index) {
      const n2 = this.store.index(t2.index);
      return t2.$t ? n2.openKeyCursor(t2.range, e) : n2.openCursor(t2.range, e);
    }
    return this.store.openCursor(t2.range, e);
  }
};
function Ls(t2) {
  return new Ns((e, n2) => {
    t2.onsuccess = (t3) => {
      const n3 = t3.target.result;
      e(n3);
    }, t2.onerror = (t3) => {
      const e2 = Us(t3.target.error);
      n2(e2);
    };
  });
}
var Bs = false;
function Us(t2) {
  const e = ks._t(getUA());
  if (e >= 12.2 && e < 13) {
    const e2 = "An internal error was encountered in the Indexed Database server";
    if (t2.message.indexOf(e2) >= 0) {
      const t3 = new D2("internal", `IOS_INDEXEDDB_BUG1: IndexedDb has thrown '${e2}'. This is likely due to an unavoidable bug in iOS. See https://stackoverflow.com/q/56496296/110915 for details and a potential workaround.`);
      return Bs || (Bs = true, // Throw a global exception outside of this promise chain, for the user to
      // potentially catch.
      setTimeout(() => {
        throw t3;
      }, 0)), t3;
    }
  }
  return t2;
}
var qs = class extends Ds {
  constructor(t2, e) {
    super(), this.Mt = t2, this.currentSequenceNumber = e;
  }
};
function Ks(t2, e) {
  const n2 = B(t2);
  return ks.It(n2.Mt, e);
}
var Qs = class {
  /**
   * @param batchId - The unique ID of this mutation batch.
   * @param localWriteTime - The original write time of this mutation.
   * @param baseMutations - Mutations that are used to populate the base
   * values when this mutation is applied locally. This can be used to locally
   * overwrite values that are persisted in the remote document cache. Base
   * mutations are never sent to the backend.
   * @param mutations - The user-provided mutations in this mutation batch.
   * User-provided mutations are applied both locally and remotely on the
   * backend.
   */
  constructor(t2, e, n2, s) {
    this.batchId = t2, this.localWriteTime = e, this.baseMutations = n2, this.mutations = s;
  }
  /**
   * Applies all the mutations in this MutationBatch to the specified document
   * to compute the state of the remote document
   *
   * @param document - The document to apply mutations to.
   * @param batchResult - The result of applying the MutationBatch to the
   * backend.
   */
  applyToRemoteDocument(t2, e) {
    const n2 = e.mutationResults;
    for (let e2 = 0; e2 < this.mutations.length; e2++) {
      const s = this.mutations[e2];
      if (s.key.isEqual(t2.key)) {
        Fe(s, t2, n2[e2]);
      }
    }
  }
  /**
   * Computes the local view of a document given all the mutations in this
   * batch.
   *
   * @param document - The document to apply mutations to.
   */
  applyToLocalView(t2) {
    for (const e of this.baseMutations)
      e.key.isEqual(t2.key) && Me(e, t2, this.localWriteTime);
    for (const e of this.mutations)
      e.key.isEqual(t2.key) && Me(e, t2, this.localWriteTime);
  }
  /**
   * Computes the local view for all provided documents given the mutations in
   * this batch.
   */
  applyToLocalDocumentSet(t2) {
    this.mutations.forEach((e) => {
      const n2 = t2.get(e.key), s = n2;
      this.applyToLocalView(s), n2.isValidDocument() || s.convertToNoDocument(G2.min());
    });
  }
  keys() {
    return this.mutations.reduce((t2, e) => t2.add(e.key), dn());
  }
  isEqual(t2) {
    return this.batchId === t2.batchId && Q2(this.mutations, t2.mutations, (t3, e) => Be(t3, e)) && Q2(this.baseMutations, t2.baseMutations, (t3, e) => Be(t3, e));
  }
};
var js = class {
  constructor(t2, e, n2, s) {
    this.batch = t2, this.commitVersion = e, this.mutationResults = n2, this.docVersions = s;
  }
  /**
   * Creates a new MutationBatchResult for the given batch and results. There
   * must be one result for each mutation in the batch. This static factory
   * caches a document=&gt;version mapping (docVersions).
   */
  static from(t2, e, n2) {
    L2(t2.mutations.length === n2.length);
    let s = ln();
    const i = t2.mutations;
    for (let t3 = 0; t3 < i.length; t3++)
      s = s.insert(i[t3].key, n2[t3].version);
    return new js(t2, e, n2, s);
  }
};
var Ws = class {
  constructor(t2, e, n2, s, i = G2.min(), r2 = G2.min(), o = nt.EMPTY_BYTE_STRING) {
    this.target = t2, this.targetId = e, this.purpose = n2, this.sequenceNumber = s, this.snapshotVersion = i, this.lastLimboFreeSnapshotVersion = r2, this.resumeToken = o;
  }
  /** Creates a new target data instance with an updated sequence number. */
  withSequenceNumber(t2) {
    return new Ws(this.target, this.targetId, this.purpose, t2, this.snapshotVersion, this.lastLimboFreeSnapshotVersion, this.resumeToken);
  }
  /**
   * Creates a new target data instance with an updated resume token and
   * snapshot version.
   */
  withResumeToken(t2, e) {
    return new Ws(this.target, this.targetId, this.purpose, this.sequenceNumber, e, this.lastLimboFreeSnapshotVersion, t2);
  }
  /**
   * Creates a new target data instance with an updated last limbo free
   * snapshot version number.
   */
  withLastLimboFreeSnapshotVersion(t2) {
    return new Ws(this.target, this.targetId, this.purpose, this.sequenceNumber, this.snapshotVersion, t2, this.resumeToken);
  }
};
var Gs = class {
  constructor(t2) {
    this.Lt = t2;
  }
};
function zs(t2, e) {
  if (e.document)
    return Un(t2.Lt, e.document, !!e.hasCommittedMutations);
  if (e.noDocument) {
    const t3 = dt.fromSegments(e.noDocument.path), n2 = Zs(e.noDocument.readTime), s = Dt.newNoDocument(t3, n2);
    return e.hasCommittedMutations ? s.setHasCommittedMutations() : s;
  }
  if (e.unknownDocument) {
    const t3 = dt.fromSegments(e.unknownDocument.path), n2 = Zs(e.unknownDocument.version);
    return Dt.newUnknownDocument(t3, n2);
  }
  return M2();
}
function Hs(t2, e, n2) {
  const s = Js(n2), i = e.key.path.popLast().toArray();
  if (e.isFoundDocument()) {
    const n3 = function(t3, e2) {
      return {
        name: kn(t3, e2.key),
        fields: e2.data.value.mapValue.fields,
        updateTime: Vn(t3, e2.version.toTimestamp())
      };
    }(t2.Lt, e), r2 = e.hasCommittedMutations;
    return new ps(
      /* unknownDocument= */
      null,
      /* noDocument= */
      null,
      n3,
      r2,
      s,
      i
    );
  }
  if (e.isNoDocument()) {
    const t3 = e.key.path.toArray(), n3 = Xs(e.version), r2 = e.hasCommittedMutations;
    return new ps(
      /* unknownDocument= */
      null,
      new gs(t3, n3),
      /* document= */
      null,
      r2,
      s,
      i
    );
  }
  if (e.isUnknownDocument()) {
    const t3 = e.key.path.toArray(), n3 = Xs(e.version);
    return new ps(
      new ys(t3, n3),
      /* noDocument= */
      null,
      /* document= */
      null,
      /* hasCommittedMutations= */
      true,
      s,
      i
    );
  }
  return M2();
}
function Js(t2) {
  const e = t2.toTimestamp();
  return [e.seconds, e.nanoseconds];
}
function Ys(t2) {
  const e = new W2(t2[0], t2[1]);
  return G2.fromTimestamp(e);
}
function Xs(t2) {
  const e = t2.toTimestamp();
  return new fs(e.seconds, e.nanoseconds);
}
function Zs(t2) {
  const e = new W2(t2.seconds, t2.nanoseconds);
  return G2.fromTimestamp(e);
}
function ti(t2, e) {
  const n2 = (e.baseMutations || []).map((e2) => jn(t2.Lt, e2));
  for (let t3 = 0; t3 < e.mutations.length - 1; ++t3) {
    const n3 = e.mutations[t3];
    if (t3 + 1 < e.mutations.length && void 0 !== e.mutations[t3 + 1].transform) {
      const s2 = e.mutations[t3 + 1];
      n3.updateTransforms = s2.transform.fieldTransforms, e.mutations.splice(t3 + 1, 1), ++t3;
    }
  }
  const s = e.mutations.map((e2) => jn(t2.Lt, e2)), i = W2.fromMillis(e.localWriteTimeMs);
  return new Qs(e.batchId, i, n2, s);
}
function ei(t2) {
  const e = Zs(t2.readTime), n2 = void 0 !== t2.lastLimboFreeSnapshotVersion ? Zs(t2.lastLimboFreeSnapshotVersion) : G2.min();
  let s;
  var i;
  return void 0 !== t2.query.documents ? (L2(1 === (i = t2.query).documents.length), s = ue(ee(Fn(i.documents[0])))) : s = function(t3) {
    return ue(Hn(t3));
  }(t2.query), new Ws(s, t2.targetId, 0, t2.lastListenSequenceNumber, e, n2, nt.fromBase64String(t2.resumeToken));
}
function ni(t2, e) {
  const n2 = Xs(e.snapshotVersion), s = Xs(e.lastLimboFreeSnapshotVersion);
  let i;
  i = Ot(e.target) ? Gn(t2.Lt, e.target) : zn(t2.Lt, e.target);
  const r2 = e.resumeToken.toBase64();
  return new Ts(e.targetId, xt(e.target), n2, r2, e.sequenceNumber, s, i);
}
function si(t2) {
  const e = Hn({
    parent: t2.parent,
    structuredQuery: t2.structuredQuery
  });
  return "LAST" === t2.limitType ? ae(
    e,
    e.limit,
    "L"
    /* Last */
  ) : e;
}
var ii = class {
  getBundleMetadata(t2, e) {
    return ri(t2).get(e).next((t3) => {
      if (t3)
        return {
          id: (e2 = t3).bundleId,
          createTime: Zs(e2.createTime),
          version: e2.version
        };
      var e2;
    });
  }
  saveBundleMetadata(t2, e) {
    return ri(t2).put({
      bundleId: (n2 = e).id,
      createTime: Xs(Cn(n2.createTime)),
      version: n2.version
    });
    var n2;
  }
  getNamedQuery(t2, e) {
    return oi(t2).get(e).next((t3) => {
      if (t3)
        return {
          name: (e2 = t3).name,
          query: si(e2.bundledQuery),
          readTime: Zs(e2.readTime)
        };
      var e2;
    });
  }
  saveNamedQuery(t2, e) {
    return oi(t2).put(function(t3) {
      return {
        name: t3.name,
        readTime: Xs(Cn(t3.readTime)),
        bundledQuery: t3.bundledQuery
      };
    }(e));
  }
};
function ri(t2) {
  return Ks(t2, bs.store);
}
function oi(t2) {
  return Ks(t2, vs.store);
}
var ci = class {
  constructor() {
    this.Bt = new ui();
  }
  addToCollectionParentIndex(t2, e) {
    return this.Bt.add(e), Ns.resolve();
  }
  getCollectionParents(t2, e) {
    return Ns.resolve(this.Bt.getEntries(e));
  }
};
var ui = class {
  constructor() {
    this.index = {};
  }
  // Returns false if the entry already existed.
  add(t2) {
    const e = t2.lastSegment(), n2 = t2.popLast(), s = this.index[e] || new sn(X2.comparator), i = !s.has(n2);
    return this.index[e] = s.add(n2), i;
  }
  has(t2) {
    const e = t2.lastSegment(), n2 = t2.popLast(), s = this.index[e];
    return s && s.has(n2);
  }
  getEntries(t2) {
    return (this.index[t2] || new sn(X2.comparator)).toArray();
  }
};
var ai = class {
  constructor() {
    this.Ut = new ui();
  }
  /**
   * Adds a new entry to the collection parent index.
   *
   * Repeated calls for the same collectionPath should be avoided within a
   * transaction as IndexedDbIndexManager only caches writes once a transaction
   * has been committed.
   */
  addToCollectionParentIndex(t2, e) {
    if (!this.Ut.has(e)) {
      const n2 = e.lastSegment(), s = e.popLast();
      t2.addOnCommittedListener(() => {
        this.Ut.add(e);
      });
      const i = {
        collectionId: n2,
        parent: us(s)
      };
      return hi(t2).put(i);
    }
    return Ns.resolve();
  }
  getCollectionParents(t2, e) {
    const n2 = [], s = IDBKeyRange.bound(
      [e, ""],
      [j(e), ""],
      /*lowerOpen=*/
      false,
      /*upperOpen=*/
      true
    );
    return hi(t2).Nt(s).next((t3) => {
      for (const s2 of t3) {
        if (s2.collectionId !== e)
          break;
        n2.push(ls(s2.parent));
      }
      return n2;
    });
  }
};
function hi(t2) {
  return Ks(t2, Rs.store);
}
var li = {
  didRun: false,
  sequenceNumbersCollected: 0,
  targetsRemoved: 0,
  documentsRemoved: 0
};
var fi = class {
  constructor(t2, e, n2) {
    this.cacheSizeCollectionThreshold = t2, this.percentileToCollect = e, this.maximumSequenceNumbersToCollect = n2;
  }
  static withCacheSize(t2) {
    return new fi(t2, fi.DEFAULT_COLLECTION_PERCENTILE, fi.DEFAULT_MAX_SEQUENCE_NUMBERS_TO_COLLECT);
  }
};
function di(t2, e, n2) {
  const s = t2.store(_s.store), i = t2.store(ms.store), r2 = [], o = IDBKeyRange.only(n2.batchId);
  let c = 0;
  const u2 = s.Ot({
    range: o
  }, (t3, e2, n3) => (c++, n3.delete()));
  r2.push(u2.next(() => {
    L2(1 === c);
  }));
  const a = [];
  for (const t3 of n2.mutations) {
    const s2 = ms.key(e, t3.key.path, n2.batchId);
    r2.push(i.delete(s2)), a.push(t3.key);
  }
  return Ns.waitFor(r2).next(() => a);
}
function wi(t2) {
  if (!t2)
    return 0;
  let e;
  if (t2.document)
    e = t2.document;
  else if (t2.unknownDocument)
    e = t2.unknownDocument;
  else {
    if (!t2.noDocument)
      throw M2();
    e = t2.noDocument;
  }
  return JSON.stringify(e).length;
}
fi.DEFAULT_COLLECTION_PERCENTILE = 10, fi.DEFAULT_MAX_SEQUENCE_NUMBERS_TO_COLLECT = 1e3, fi.DEFAULT = new fi(41943040, fi.DEFAULT_COLLECTION_PERCENTILE, fi.DEFAULT_MAX_SEQUENCE_NUMBERS_TO_COLLECT), fi.DISABLED = new fi(-1, 0, 0);
var _i = class {
  constructor(t2, e, n2, s) {
    this.userId = t2, this.R = e, this.qt = n2, this.referenceDelegate = s, /**
     * Caches the document keys for pending mutation batches. If the mutation
     * has been removed from IndexedDb, the cached value may continue to
     * be used to retrieve the batch's document keys. To remove a cached value
     * locally, `removeCachedMutationKeys()` should be invoked either directly
     * or through `removeMutationBatches()`.
     *
     * With multi-tab, when the primary client acknowledges or rejects a mutation,
     * this cache is used by secondary clients to invalidate the local
     * view of the documents that were previously affected by the mutation.
     */
    // PORTING NOTE: Multi-tab only.
    this.Kt = {};
  }
  /**
   * Creates a new mutation queue for the given user.
   * @param user - The user for which to create a mutation queue.
   * @param serializer - The serializer to use when persisting to IndexedDb.
   */
  static Qt(t2, e, n2, s) {
    L2("" !== t2.uid);
    const i = t2.isAuthenticated() ? t2.uid : "";
    return new _i(i, e, n2, s);
  }
  checkEmpty(t2) {
    let e = true;
    const n2 = IDBKeyRange.bound([this.userId, Number.NEGATIVE_INFINITY], [this.userId, Number.POSITIVE_INFINITY]);
    return gi(t2).Ot({
      index: _s.userMutationsIndex,
      range: n2
    }, (t3, n3, s) => {
      e = false, s.done();
    }).next(() => e);
  }
  addMutationBatch(t2, e, n2, s) {
    const i = yi(t2), r2 = gi(t2);
    return r2.add({}).next((o) => {
      L2("number" == typeof o);
      const c = new Qs(o, e, n2, s), u2 = function(t3, e2, n3) {
        const s2 = n3.baseMutations.map((e3) => Qn(t3.Lt, e3)), i2 = n3.mutations.map((e3) => Qn(t3.Lt, e3));
        return new _s(e2, n3.batchId, n3.localWriteTime.toMillis(), s2, i2);
      }(this.R, this.userId, c), a = [];
      let h = new sn((t3, e2) => K2(t3.canonicalString(), e2.canonicalString()));
      for (const t3 of s) {
        const e2 = ms.key(this.userId, t3.key.path, o);
        h = h.add(t3.key.path.popLast()), a.push(r2.put(u2)), a.push(i.put(e2, ms.PLACEHOLDER));
      }
      return h.forEach((e2) => {
        a.push(this.qt.addToCollectionParentIndex(t2, e2));
      }), t2.addOnCommittedListener(() => {
        this.Kt[o] = c.keys();
      }), Ns.waitFor(a).next(() => c);
    });
  }
  lookupMutationBatch(t2, e) {
    return gi(t2).get(e).next((t3) => t3 ? (L2(t3.userId === this.userId), ti(this.R, t3)) : null);
  }
  /**
   * Returns the document keys for the mutation batch with the given batchId.
   * For primary clients, this method returns `null` after
   * `removeMutationBatches()` has been called. Secondary clients return a
   * cached result until `removeCachedMutationKeys()` is invoked.
   */
  // PORTING NOTE: Multi-tab only.
  jt(t2, e) {
    return this.Kt[e] ? Ns.resolve(this.Kt[e]) : this.lookupMutationBatch(t2, e).next((t3) => {
      if (t3) {
        const n2 = t3.keys();
        return this.Kt[e] = n2, n2;
      }
      return null;
    });
  }
  getNextMutationBatchAfterBatchId(t2, e) {
    const n2 = e + 1, s = IDBKeyRange.lowerBound([this.userId, n2]);
    let i = null;
    return gi(t2).Ot({
      index: _s.userMutationsIndex,
      range: s
    }, (t3, e2, s2) => {
      e2.userId === this.userId && (L2(e2.batchId >= n2), i = ti(this.R, e2)), s2.done();
    }).next(() => i);
  }
  getHighestUnacknowledgedBatchId(t2) {
    const e = IDBKeyRange.upperBound([this.userId, Number.POSITIVE_INFINITY]);
    let n2 = -1;
    return gi(t2).Ot({
      index: _s.userMutationsIndex,
      range: e,
      reverse: true
    }, (t3, e2, s) => {
      n2 = e2.batchId, s.done();
    }).next(() => n2);
  }
  getAllMutationBatches(t2) {
    const e = IDBKeyRange.bound([this.userId, -1], [this.userId, Number.POSITIVE_INFINITY]);
    return gi(t2).Nt(_s.userMutationsIndex, e).next((t3) => t3.map((t4) => ti(this.R, t4)));
  }
  getAllMutationBatchesAffectingDocumentKey(t2, e) {
    const n2 = ms.prefixForPath(this.userId, e.path), s = IDBKeyRange.lowerBound(n2), i = [];
    return yi(t2).Ot({
      range: s
    }, (n3, s2, r2) => {
      const [o, c, u2] = n3, a = ls(c);
      if (o === this.userId && e.path.isEqual(a))
        return gi(t2).get(u2).next((t3) => {
          if (!t3)
            throw M2();
          L2(t3.userId === this.userId), i.push(ti(this.R, t3));
        });
      r2.done();
    }).next(() => i);
  }
  getAllMutationBatchesAffectingDocumentKeys(t2, e) {
    let n2 = new sn(K2);
    const s = [];
    return e.forEach((e2) => {
      const i = ms.prefixForPath(this.userId, e2.path), r2 = IDBKeyRange.lowerBound(i), o = yi(t2).Ot({
        range: r2
      }, (t3, s2, i2) => {
        const [r3, o2, c] = t3, u2 = ls(o2);
        r3 === this.userId && e2.path.isEqual(u2) ? n2 = n2.add(c) : i2.done();
      });
      s.push(o);
    }), Ns.waitFor(s).next(() => this.Wt(t2, n2));
  }
  getAllMutationBatchesAffectingQuery(t2, e) {
    const n2 = e.path, s = n2.length + 1, i = ms.prefixForPath(this.userId, n2), r2 = IDBKeyRange.lowerBound(i);
    let o = new sn(K2);
    return yi(t2).Ot({
      range: r2
    }, (t3, e2, i2) => {
      const [r3, c, u2] = t3, a = ls(c);
      r3 === this.userId && n2.isPrefixOf(a) ? (
        // Rows with document keys more than one segment longer than the
        // query path can't be matches. For example, a query on 'rooms'
        // can't match the document /rooms/abc/messages/xyx.
        // TODO(mcg): we'll need a different scanner when we implement
        // ancestor queries.
        a.length === s && (o = o.add(u2))
      ) : i2.done();
    }).next(() => this.Wt(t2, o));
  }
  Wt(t2, e) {
    const n2 = [], s = [];
    return e.forEach((e2) => {
      s.push(gi(t2).get(e2).next((t3) => {
        if (null === t3)
          throw M2();
        L2(t3.userId === this.userId), n2.push(ti(this.R, t3));
      }));
    }), Ns.waitFor(s).next(() => n2);
  }
  removeMutationBatch(t2, e) {
    return di(t2.Mt, this.userId, e).next((n2) => (t2.addOnCommittedListener(() => {
      this.Gt(e.batchId);
    }), Ns.forEach(n2, (e2) => this.referenceDelegate.markPotentiallyOrphaned(t2, e2))));
  }
  /**
   * Clears the cached keys for a mutation batch. This method should be
   * called by secondary clients after they process mutation updates.
   *
   * Note that this method does not have to be called from primary clients as
   * the corresponding cache entries are cleared when an acknowledged or
   * rejected batch is removed from the mutation queue.
   */
  // PORTING NOTE: Multi-tab only
  Gt(t2) {
    delete this.Kt[t2];
  }
  performConsistencyCheck(t2) {
    return this.checkEmpty(t2).next((e) => {
      if (!e)
        return Ns.resolve();
      const n2 = IDBKeyRange.lowerBound(ms.prefixForUser(this.userId)), s = [];
      return yi(t2).Ot({
        range: n2
      }, (t3, e2, n3) => {
        if (t3[0] === this.userId) {
          const e3 = ls(t3[1]);
          s.push(e3);
        } else
          n3.done();
      }).next(() => {
        L2(0 === s.length);
      });
    });
  }
  containsKey(t2, e) {
    return mi(t2, this.userId, e);
  }
  // PORTING NOTE: Multi-tab only (state is held in memory in other clients).
  /** Returns the mutation queue's metadata from IndexedDb. */
  zt(t2) {
    return pi(t2).get(this.userId).next((t3) => t3 || new ws(
      this.userId,
      -1,
      /*lastStreamToken=*/
      ""
    ));
  }
};
function mi(t2, e, n2) {
  const s = ms.prefixForPath(e, n2.path), i = s[1], r2 = IDBKeyRange.lowerBound(s);
  let o = false;
  return yi(t2).Ot({
    range: r2,
    $t: true
  }, (t3, n3, s2) => {
    const [
      r3,
      c,
      /*batchID*/
      u2
    ] = t3;
    r3 === e && c === i && (o = true), s2.done();
  }).next(() => o);
}
function gi(t2) {
  return Ks(t2, _s.store);
}
function yi(t2) {
  return Ks(t2, ms.store);
}
function pi(t2) {
  return Ks(t2, ws.store);
}
var Ei = class {
  constructor(t2) {
    this.Ht = t2;
  }
  next() {
    return this.Ht += 2, this.Ht;
  }
  static Jt() {
    return new Ei(0);
  }
  static Yt() {
    return new Ei(-1);
  }
};
var Ti = class {
  constructor(t2, e) {
    this.referenceDelegate = t2, this.R = e;
  }
  // PORTING NOTE: We don't cache global metadata for the target cache, since
  // some of it (in particular `highestTargetId`) can be modified by secondary
  // tabs. We could perhaps be more granular (and e.g. still cache
  // `lastRemoteSnapshotVersion` in memory) but for simplicity we currently go
  // to IndexedDb whenever we need to read metadata. We can revisit if it turns
  // out to have a meaningful performance impact.
  allocateTargetId(t2) {
    return this.Xt(t2).next((e) => {
      const n2 = new Ei(e.highestTargetId);
      return e.highestTargetId = n2.next(), this.Zt(t2, e).next(() => e.highestTargetId);
    });
  }
  getLastRemoteSnapshotVersion(t2) {
    return this.Xt(t2).next((t3) => G2.fromTimestamp(new W2(t3.lastRemoteSnapshotVersion.seconds, t3.lastRemoteSnapshotVersion.nanoseconds)));
  }
  getHighestSequenceNumber(t2) {
    return this.Xt(t2).next((t3) => t3.highestListenSequenceNumber);
  }
  setTargetsMetadata(t2, e, n2) {
    return this.Xt(t2).next((s) => (s.highestListenSequenceNumber = e, n2 && (s.lastRemoteSnapshotVersion = n2.toTimestamp()), e > s.highestListenSequenceNumber && (s.highestListenSequenceNumber = e), this.Zt(t2, s)));
  }
  addTargetData(t2, e) {
    return this.te(t2, e).next(() => this.Xt(t2).next((n2) => (n2.targetCount += 1, this.ee(e, n2), this.Zt(t2, n2))));
  }
  updateTargetData(t2, e) {
    return this.te(t2, e);
  }
  removeTargetData(t2, e) {
    return this.removeMatchingKeysForTargetId(t2, e.targetId).next(() => Ii(t2).delete(e.targetId)).next(() => this.Xt(t2)).next((e2) => (L2(e2.targetCount > 0), e2.targetCount -= 1, this.Zt(t2, e2)));
  }
  /**
   * Drops any targets with sequence number less than or equal to the upper bound, excepting those
   * present in `activeTargetIds`. Document associations for the removed targets are also removed.
   * Returns the number of targets removed.
   */
  removeTargets(t2, e, n2) {
    let s = 0;
    const i = [];
    return Ii(t2).Ot((r2, o) => {
      const c = ei(o);
      c.sequenceNumber <= e && null === n2.get(c.targetId) && (s++, i.push(this.removeTargetData(t2, c)));
    }).next(() => Ns.waitFor(i)).next(() => s);
  }
  /**
   * Call provided function with each `TargetData` that we have cached.
   */
  forEachTarget(t2, e) {
    return Ii(t2).Ot((t3, n2) => {
      const s = ei(n2);
      e(s);
    });
  }
  Xt(t2) {
    return Ai(t2).get(As.key).next((t3) => (L2(null !== t3), t3));
  }
  Zt(t2, e) {
    return Ai(t2).put(As.key, e);
  }
  te(t2, e) {
    return Ii(t2).put(ni(this.R, e));
  }
  /**
   * In-place updates the provided metadata to account for values in the given
   * TargetData. Saving is done separately. Returns true if there were any
   * changes to the metadata.
   */
  ee(t2, e) {
    let n2 = false;
    return t2.targetId > e.highestTargetId && (e.highestTargetId = t2.targetId, n2 = true), t2.sequenceNumber > e.highestListenSequenceNumber && (e.highestListenSequenceNumber = t2.sequenceNumber, n2 = true), n2;
  }
  getTargetCount(t2) {
    return this.Xt(t2).next((t3) => t3.targetCount);
  }
  getTargetData(t2, e) {
    const n2 = xt(e), s = IDBKeyRange.bound([n2, Number.NEGATIVE_INFINITY], [n2, Number.POSITIVE_INFINITY]);
    let i = null;
    return Ii(t2).Ot({
      range: s,
      index: Ts.queryTargetsIndexName
    }, (t3, n3, s2) => {
      const r2 = ei(n3);
      $t(e, r2.target) && (i = r2, s2.done());
    }).next(() => i);
  }
  addMatchingKeys(t2, e, n2) {
    const s = [], i = Ri(t2);
    return e.forEach((e2) => {
      const r2 = us(e2.path);
      s.push(i.put(new Is(n2, r2))), s.push(this.referenceDelegate.addReference(t2, n2, e2));
    }), Ns.waitFor(s);
  }
  removeMatchingKeys(t2, e, n2) {
    const s = Ri(t2);
    return Ns.forEach(e, (e2) => {
      const i = us(e2.path);
      return Ns.waitFor([s.delete([n2, i]), this.referenceDelegate.removeReference(t2, n2, e2)]);
    });
  }
  removeMatchingKeysForTargetId(t2, e) {
    const n2 = Ri(t2), s = IDBKeyRange.bound(
      [e],
      [e + 1],
      /*lowerOpen=*/
      false,
      /*upperOpen=*/
      true
    );
    return n2.delete(s);
  }
  getMatchingKeysForTargetId(t2, e) {
    const n2 = IDBKeyRange.bound(
      [e],
      [e + 1],
      /*lowerOpen=*/
      false,
      /*upperOpen=*/
      true
    ), s = Ri(t2);
    let i = dn();
    return s.Ot({
      range: n2,
      $t: true
    }, (t3, e2, n3) => {
      const s2 = ls(t3[1]), r2 = new dt(s2);
      i = i.add(r2);
    }).next(() => i);
  }
  containsKey(t2, e) {
    const n2 = us(e.path), s = IDBKeyRange.bound(
      [n2],
      [j(n2)],
      /*lowerOpen=*/
      false,
      /*upperOpen=*/
      true
    );
    let i = 0;
    return Ri(t2).Ot({
      index: Is.documentTargetsIndex,
      $t: true,
      range: s
    }, ([t3, e2], n3, s2) => {
      0 !== t3 && (i++, s2.done());
    }).next(() => i > 0);
  }
  /**
   * Looks up a TargetData entry by target ID.
   *
   * @param targetId - The target ID of the TargetData entry to look up.
   * @returns The cached TargetData entry, or null if the cache has no entry for
   * the target.
   */
  // PORTING NOTE: Multi-tab only.
  lt(t2, e) {
    return Ii(t2).get(e).next((t3) => t3 ? ei(t3) : null);
  }
};
function Ii(t2) {
  return Ks(t2, Ts.store);
}
function Ai(t2) {
  return Ks(t2, As.store);
}
function Ri(t2) {
  return Ks(t2, Is.store);
}
async function Pi(t2) {
  if (t2.code !== S2.FAILED_PRECONDITION || t2.message !== Ss)
    throw t2;
  k2("LocalStore", "Unexpectedly lost primary lease");
}
function bi([t2, e], [n2, s]) {
  const i = K2(t2, n2);
  return 0 === i ? K2(e, s) : i;
}
var vi = class {
  constructor(t2) {
    this.ne = t2, this.buffer = new sn(bi), this.se = 0;
  }
  ie() {
    return ++this.se;
  }
  re(t2) {
    const e = [t2, this.ie()];
    if (this.buffer.size < this.ne)
      this.buffer = this.buffer.add(e);
    else {
      const t3 = this.buffer.last();
      bi(e, t3) < 0 && (this.buffer = this.buffer.delete(t3).add(e));
    }
  }
  get maxValue() {
    return this.buffer.last()[0];
  }
};
var Vi = class {
  constructor(t2, e) {
    this.garbageCollector = t2, this.asyncQueue = e, this.oe = false, this.ce = null;
  }
  start(t2) {
    -1 !== this.garbageCollector.params.cacheSizeCollectionThreshold && this.ue(t2);
  }
  stop() {
    this.ce && (this.ce.cancel(), this.ce = null);
  }
  get started() {
    return null !== this.ce;
  }
  ue(t2) {
    const e = this.oe ? 3e5 : 6e4;
    k2("LruGarbageCollector", `Garbage collection scheduled in ${e}ms`), this.ce = this.asyncQueue.enqueueAfterDelay("lru_garbage_collection", e, async () => {
      this.ce = null, this.oe = true;
      try {
        await t2.collectGarbage(this.garbageCollector);
      } catch (t3) {
        Fs(t3) ? k2("LruGarbageCollector", "Ignoring IndexedDB error during garbage collection: ", t3) : await Pi(t3);
      }
      await this.ue(t2);
    });
  }
};
var Si = class {
  constructor(t2, e) {
    this.ae = t2, this.params = e;
  }
  calculateTargetCount(t2, e) {
    return this.ae.he(t2).next((t3) => Math.floor(e / 100 * t3));
  }
  nthSequenceNumber(t2, e) {
    if (0 === e)
      return Ns.resolve(V2.o);
    const n2 = new vi(e);
    return this.ae.forEachTarget(t2, (t3) => n2.re(t3.sequenceNumber)).next(() => this.ae.le(t2, (t3) => n2.re(t3))).next(() => n2.maxValue);
  }
  removeTargets(t2, e, n2) {
    return this.ae.removeTargets(t2, e, n2);
  }
  removeOrphanedDocuments(t2, e) {
    return this.ae.removeOrphanedDocuments(t2, e);
  }
  collect(t2, e) {
    return -1 === this.params.cacheSizeCollectionThreshold ? (k2("LruGarbageCollector", "Garbage collection skipped; disabled"), Ns.resolve(li)) : this.getCacheSize(t2).next((n2) => n2 < this.params.cacheSizeCollectionThreshold ? (k2("LruGarbageCollector", `Garbage collection skipped; Cache size ${n2} is lower than threshold ${this.params.cacheSizeCollectionThreshold}`), li) : this.fe(t2, e));
  }
  getCacheSize(t2) {
    return this.ae.getCacheSize(t2);
  }
  fe(t2, e) {
    let n2, s, i, r2, o, c, a;
    const h = Date.now();
    return this.calculateTargetCount(t2, this.params.percentileToCollect).next((e2) => (
      // Cap at the configured max
      (e2 > this.params.maximumSequenceNumbersToCollect ? (k2("LruGarbageCollector", `Capping sequence numbers to collect down to the maximum of ${this.params.maximumSequenceNumbersToCollect} from ${e2}`), s = this.params.maximumSequenceNumbersToCollect) : s = e2, r2 = Date.now(), this.nthSequenceNumber(t2, s))
    )).next((s2) => (n2 = s2, o = Date.now(), this.removeTargets(t2, n2, e))).next((e2) => (i = e2, c = Date.now(), this.removeOrphanedDocuments(t2, n2))).next((t3) => {
      if (a = Date.now(), N2() <= LogLevel.DEBUG) {
        k2("LruGarbageCollector", `LRU Garbage Collection
	Counted targets in ${r2 - h}ms
	Determined least recently used ${s} in ` + (o - r2) + `ms
	Removed ${i} targets in ` + (c - o) + `ms
	Removed ${t3} documents in ` + (a - c) + `ms
Total Duration: ${a - h}ms`);
      }
      return Ns.resolve({
        didRun: true,
        sequenceNumbersCollected: s,
        targetsRemoved: i,
        documentsRemoved: t3
      });
    });
  }
};
var Di = class {
  constructor(t2, e) {
    this.db = t2, this.garbageCollector = function(t3, e2) {
      return new Si(t3, e2);
    }(this, e);
  }
  he(t2) {
    const e = this.de(t2);
    return this.db.getTargetCache().getTargetCount(t2).next((t3) => e.next((e2) => t3 + e2));
  }
  de(t2) {
    let e = 0;
    return this.le(t2, (t3) => {
      e++;
    }).next(() => e);
  }
  forEachTarget(t2, e) {
    return this.db.getTargetCache().forEachTarget(t2, e);
  }
  le(t2, e) {
    return this.we(t2, (t3, n2) => e(n2));
  }
  addReference(t2, e, n2) {
    return Ci(t2, n2);
  }
  removeReference(t2, e, n2) {
    return Ci(t2, n2);
  }
  removeTargets(t2, e, n2) {
    return this.db.getTargetCache().removeTargets(t2, e, n2);
  }
  markPotentiallyOrphaned(t2, e) {
    return Ci(t2, e);
  }
  /**
   * Returns true if anything would prevent this document from being garbage
   * collected, given that the document in question is not present in any
   * targets and has a sequence number less than or equal to the upper bound for
   * the collection run.
   */
  _e(t2, e) {
    return function(t3, e2) {
      let n2 = false;
      return pi(t3).Ft((s) => mi(t3, s, e2).next((t4) => (t4 && (n2 = true), Ns.resolve(!t4)))).next(() => n2);
    }(t2, e);
  }
  removeOrphanedDocuments(t2, e) {
    const n2 = this.db.getRemoteDocumentCache().newChangeBuffer(), s = [];
    let i = 0;
    return this.we(t2, (r2, o) => {
      if (o <= e) {
        const e2 = this._e(t2, r2).next((e3) => {
          if (!e3)
            return i++, n2.getEntry(t2, r2).next(() => (n2.removeEntry(r2), Ri(t2).delete([0, us(r2.path)])));
        });
        s.push(e2);
      }
    }).next(() => Ns.waitFor(s)).next(() => n2.apply(t2)).next(() => i);
  }
  removeTarget(t2, e) {
    const n2 = e.withSequenceNumber(t2.currentSequenceNumber);
    return this.db.getTargetCache().updateTargetData(t2, n2);
  }
  updateLimboDocument(t2, e) {
    return Ci(t2, e);
  }
  /**
   * Call provided function for each document in the cache that is 'orphaned'. Orphaned
   * means not a part of any target, so the only entry in the target-document index for
   * that document will be the sentinel row (targetId 0), which will also have the sequence
   * number for the last time the document was accessed.
   */
  we(t2, e) {
    const n2 = Ri(t2);
    let s, i = V2.o;
    return n2.Ot({
      index: Is.documentTargetsIndex
    }, ([t3, n3], { path: r2, sequenceNumber: o }) => {
      0 === t3 ? (
        // if nextToReport is valid, report it, this is a new key so the
        // last one must not be a member of any targets.
        (i !== V2.o && e(new dt(ls(s)), i), // set nextToReport to be this sequence number. It's the next one we
        // might report, if we don't find any targets for this document.
        // Note that the sequence number must be defined when the targetId
        // is 0.
        i = o, s = r2)
      ) : (
        // set nextToReport to be invalid, we know we don't need to report
        // this one since we found a target for it.
        i = V2.o
      );
    }).next(() => {
      i !== V2.o && e(new dt(ls(s)), i);
    });
  }
  getCacheSize(t2) {
    return this.db.getRemoteDocumentCache().getSize(t2);
  }
};
function Ci(t2, e) {
  return Ri(t2).put(
    /**
    * @returns A value suitable for writing a sentinel row in the target-document
    * store.
    */
    function(t3, e2) {
      return new Is(0, us(t3.path), e2);
    }(e, t2.currentSequenceNumber)
  );
}
var Ni = class {
  constructor(t2, e) {
    this.mapKeyFn = t2, this.equalsFn = e, /**
     * The inner map for a key/value pair. Due to the possibility of collisions we
     * keep a list of entries that we do a linear search through to find an actual
     * match. Note that collisions should be rare, so we still expect near
     * constant time lookups in practice.
     */
    this.inner = {};
  }
  /** Get a value for this key, or undefined if it does not exist. */
  get(t2) {
    const e = this.mapKeyFn(t2), n2 = this.inner[e];
    if (void 0 !== n2) {
      for (const [e2, s] of n2)
        if (this.equalsFn(e2, t2))
          return s;
    }
  }
  has(t2) {
    return void 0 !== this.get(t2);
  }
  /** Put this key and value in the map. */
  set(t2, e) {
    const n2 = this.mapKeyFn(t2), s = this.inner[n2];
    if (void 0 !== s) {
      for (let n3 = 0; n3 < s.length; n3++)
        if (this.equalsFn(s[n3][0], t2))
          return void (s[n3] = [t2, e]);
      s.push([t2, e]);
    } else
      this.inner[n2] = [[t2, e]];
  }
  /**
   * Remove this key from the map. Returns a boolean if anything was deleted.
   */
  delete(t2) {
    const e = this.mapKeyFn(t2), n2 = this.inner[e];
    if (void 0 === n2)
      return false;
    for (let s = 0; s < n2.length; s++)
      if (this.equalsFn(n2[s][0], t2))
        return 1 === n2.length ? delete this.inner[e] : n2.splice(s, 1), true;
    return false;
  }
  forEach(t2) {
    H2(this.inner, (e, n2) => {
      for (const [e2, s] of n2)
        t2(e2, s);
    });
  }
  isEmpty() {
    return J2(this.inner);
  }
};
var xi = class {
  constructor() {
    this.changes = new Ni((t2) => t2.toString(), (t2, e) => t2.isEqual(e)), this.changesApplied = false;
  }
  getReadTime(t2) {
    const e = this.changes.get(t2);
    return e ? e.readTime : G2.min();
  }
  /**
   * Buffers a `RemoteDocumentCache.addEntry()` call.
   *
   * You can only modify documents that have already been retrieved via
   * `getEntry()/getEntries()` (enforced via IndexedDbs `apply()`).
   */
  addEntry(t2, e) {
    this.assertNotApplied(), this.changes.set(t2.key, {
      document: t2,
      readTime: e
    });
  }
  /**
   * Buffers a `RemoteDocumentCache.removeEntry()` call.
   *
   * You can only remove documents that have already been retrieved via
   * `getEntry()/getEntries()` (enforced via IndexedDbs `apply()`).
   */
  removeEntry(t2, e = null) {
    this.assertNotApplied(), this.changes.set(t2, {
      document: Dt.newInvalidDocument(t2),
      readTime: e
    });
  }
  /**
   * Looks up an entry in the cache. The buffered changes will first be checked,
   * and if no buffered change applies, this will forward to
   * `RemoteDocumentCache.getEntry()`.
   *
   * @param transaction - The transaction in which to perform any persistence
   *     operations.
   * @param documentKey - The key of the entry to look up.
   * @returns The cached document or an invalid document if we have nothing
   * cached.
   */
  getEntry(t2, e) {
    this.assertNotApplied();
    const n2 = this.changes.get(e);
    return void 0 !== n2 ? Ns.resolve(n2.document) : this.getFromCache(t2, e);
  }
  /**
   * Looks up several entries in the cache, forwarding to
   * `RemoteDocumentCache.getEntry()`.
   *
   * @param transaction - The transaction in which to perform any persistence
   *     operations.
   * @param documentKeys - The keys of the entries to look up.
   * @returns A map of cached documents, indexed by key. If an entry cannot be
   *     found, the corresponding key will be mapped to an invalid document.
   */
  getEntries(t2, e) {
    return this.getAllFromCache(t2, e);
  }
  /**
   * Applies buffered changes to the underlying RemoteDocumentCache, using
   * the provided transaction.
   */
  apply(t2) {
    return this.assertNotApplied(), this.changesApplied = true, this.applyChanges(t2);
  }
  /** Helper to assert this.changes is not null  */
  assertNotApplied() {
  }
};
var ki = class {
  /**
   * @param serializer - The document serializer.
   * @param indexManager - The query indexes that need to be maintained.
   */
  constructor(t2, e) {
    this.R = t2, this.qt = e;
  }
  /**
   * Adds the supplied entries to the cache.
   *
   * All calls of `addEntry` are required to go through the RemoteDocumentChangeBuffer
   * returned by `newChangeBuffer()` to ensure proper accounting of metadata.
   */
  addEntry(t2, e, n2) {
    return Fi(t2).put(Mi(e), n2);
  }
  /**
   * Removes a document from the cache.
   *
   * All calls of `removeEntry`  are required to go through the RemoteDocumentChangeBuffer
   * returned by `newChangeBuffer()` to ensure proper accounting of metadata.
   */
  removeEntry(t2, e) {
    const n2 = Fi(t2), s = Mi(e);
    return n2.delete(s);
  }
  /**
   * Updates the current cache size.
   *
   * Callers to `addEntry()` and `removeEntry()` *must* call this afterwards to update the
   * cache's metadata.
   */
  updateMetadata(t2, e) {
    return this.getMetadata(t2).next((n2) => (n2.byteSize += e, this.me(t2, n2)));
  }
  getEntry(t2, e) {
    return Fi(t2).get(Mi(e)).next((t3) => this.ge(e, t3));
  }
  /**
   * Looks up an entry in the cache.
   *
   * @param documentKey - The key of the entry to look up.
   * @returns The cached document entry and its size.
   */
  ye(t2, e) {
    return Fi(t2).get(Mi(e)).next((t3) => ({
      document: this.ge(e, t3),
      size: wi(t3)
    }));
  }
  getEntries(t2, e) {
    let n2 = cn();
    return this.pe(t2, e, (t3, e2) => {
      const s = this.ge(t3, e2);
      n2 = n2.insert(t3, s);
    }).next(() => n2);
  }
  /**
   * Looks up several entries in the cache.
   *
   * @param documentKeys - The set of keys entries to look up.
   * @returns A map of documents indexed by key and a map of sizes indexed by
   *     key (zero if the document does not exist).
   */
  Ee(t2, e) {
    let n2 = cn(), s = new tn(dt.comparator);
    return this.pe(t2, e, (t3, e2) => {
      const i = this.ge(t3, e2);
      n2 = n2.insert(t3, i), s = s.insert(t3, wi(e2));
    }).next(() => ({
      documents: n2,
      Te: s
    }));
  }
  pe(t2, e, n2) {
    if (e.isEmpty())
      return Ns.resolve();
    const s = IDBKeyRange.bound(e.first().path.toArray(), e.last().path.toArray()), i = e.getIterator();
    let r2 = i.getNext();
    return Fi(t2).Ot({
      range: s
    }, (t3, e2, s2) => {
      const o = dt.fromSegments(t3);
      for (; r2 && dt.comparator(r2, o) < 0; )
        n2(r2, null), r2 = i.getNext();
      r2 && r2.isEqual(o) && // Key found in cache.
      (n2(r2, e2), r2 = i.hasNext() ? i.getNext() : null), // Skip to the next key (if there is one).
      r2 ? s2.Ct(r2.path.toArray()) : s2.done();
    }).next(() => {
      for (; r2; )
        n2(r2, null), r2 = i.hasNext() ? i.getNext() : null;
    });
  }
  getDocumentsMatchingQuery(t2, e, n2) {
    let s = cn();
    const i = e.path.length + 1, r2 = {};
    if (n2.isEqual(G2.min())) {
      const t3 = e.path.toArray();
      r2.range = IDBKeyRange.lowerBound(t3);
    } else {
      const t3 = e.path.toArray(), s2 = Js(n2);
      r2.range = IDBKeyRange.lowerBound(
        [t3, s2],
        /* open= */
        true
      ), r2.index = ps.collectionReadTimeIndex;
    }
    return Fi(t2).Ot(r2, (t3, n3, r3) => {
      if (t3.length !== i)
        return;
      const o = zs(this.R, n3);
      e.path.isPrefixOf(o.key.path) ? de(e, o) && (s = s.insert(o.key, o)) : r3.done();
    }).next(() => s);
  }
  newChangeBuffer(t2) {
    return new $i(this, !!t2 && t2.trackRemovals);
  }
  getSize(t2) {
    return this.getMetadata(t2).next((t3) => t3.byteSize);
  }
  getMetadata(t2) {
    return Oi(t2).get(Es.key).next((t3) => (L2(!!t3), t3));
  }
  me(t2, e) {
    return Oi(t2).put(Es.key, e);
  }
  /**
   * Decodes `remoteDoc` and returns the document (or null, if the document
   * corresponds to the format used for sentinel deletes).
   */
  ge(t2, e) {
    if (e) {
      const t3 = zs(this.R, e);
      if (!(t3.isNoDocument() && t3.version.isEqual(G2.min())))
        return t3;
    }
    return Dt.newInvalidDocument(t2);
  }
};
var $i = class extends xi {
  /**
   * @param documentCache - The IndexedDbRemoteDocumentCache to apply the changes to.
   * @param trackRemovals - Whether to create sentinel deletes that can be tracked by
   * `getNewDocumentChanges()`.
   */
  constructor(t2, e) {
    super(), this.Ie = t2, this.trackRemovals = e, // A map of document sizes prior to applying the changes in this buffer.
    this.Ae = new Ni((t3) => t3.toString(), (t3, e2) => t3.isEqual(e2));
  }
  applyChanges(t2) {
    const e = [];
    let n2 = 0, s = new sn((t3, e2) => K2(t3.canonicalString(), e2.canonicalString()));
    return this.changes.forEach((i, r2) => {
      const o = this.Ae.get(i);
      if (r2.document.isValidDocument()) {
        const c = Hs(this.Ie.R, r2.document, this.getReadTime(i));
        s = s.add(i.path.popLast());
        const u2 = wi(c);
        n2 += u2 - o, e.push(this.Ie.addEntry(t2, i, c));
      } else if (n2 -= o, this.trackRemovals) {
        const n3 = Hs(this.Ie.R, Dt.newNoDocument(i, G2.min()), this.getReadTime(i));
        e.push(this.Ie.addEntry(t2, i, n3));
      } else
        e.push(this.Ie.removeEntry(t2, i));
    }), s.forEach((n3) => {
      e.push(this.Ie.qt.addToCollectionParentIndex(t2, n3));
    }), e.push(this.Ie.updateMetadata(t2, n2)), Ns.waitFor(e);
  }
  getFromCache(t2, e) {
    return this.Ie.ye(t2, e).next((t3) => (this.Ae.set(e, t3.size), t3.document));
  }
  getAllFromCache(t2, e) {
    return this.Ie.Ee(t2, e).next(({ documents: t3, Te: e2 }) => (
      // Note: `getAllFromCache` returns two maps instead of a single map from
      // keys to `DocumentSizeEntry`s. This is to allow returning the
      // `MutableDocumentMap` directly, without a conversion.
      (e2.forEach((t4, e3) => {
        this.Ae.set(t4, e3);
      }), t3)
    ));
  }
};
function Oi(t2) {
  return Ks(t2, Es.store);
}
function Fi(t2) {
  return Ks(t2, ps.store);
}
function Mi(t2) {
  return t2.path.toArray();
}
var Li = class {
  constructor(t2) {
    this.R = t2;
  }
  /**
   * Performs database creation and schema upgrades.
   *
   * Note that in production, this method is only ever used to upgrade the schema
   * to SCHEMA_VERSION. Different values of toVersion are only used for testing
   * and local feature development.
   */
  Rt(t2, e, n2, s) {
    L2(n2 < s && n2 >= 0 && s <= 11);
    const i = new xs("createOrUpgrade", e);
    n2 < 1 && s >= 1 && (function(t3) {
      t3.createObjectStore(ds.store);
    }(t2), function(t3) {
      t3.createObjectStore(ws.store, {
        keyPath: ws.keyPath
      });
      t3.createObjectStore(_s.store, {
        keyPath: _s.keyPath,
        autoIncrement: true
      }).createIndex(_s.userMutationsIndex, _s.userMutationsKeyPath, {
        unique: true
      }), t3.createObjectStore(ms.store);
    }(t2), Bi(t2), function(t3) {
      t3.createObjectStore(ps.store);
    }(t2));
    let r2 = Ns.resolve();
    return n2 < 3 && s >= 3 && // Brand new clients don't need to drop and recreate--only clients that
    // potentially have corrupt data.
    (0 !== n2 && (!function(t3) {
      t3.deleteObjectStore(Is.store), t3.deleteObjectStore(Ts.store), t3.deleteObjectStore(As.store);
    }(t2), Bi(t2)), r2 = r2.next(() => (
      /**
      * Creates the target global singleton row.
      *
      * @param txn - The version upgrade transaction for indexeddb
      */
      function(t3) {
        const e2 = t3.store(As.store), n3 = new As(
          /*highestTargetId=*/
          0,
          /*lastListenSequenceNumber=*/
          0,
          G2.min().toTimestamp(),
          /*targetCount=*/
          0
        );
        return e2.put(As.key, n3);
      }(i)
    ))), n2 < 4 && s >= 4 && (0 !== n2 && // Schema version 3 uses auto-generated keys to generate globally unique
    // mutation batch IDs (this was previously ensured internally by the
    // client). To migrate to the new schema, we have to read all mutations
    // and write them back out. We preserve the existing batch IDs to guarantee
    // consistency with other object stores. Any further mutation batch IDs will
    // be auto-generated.
    (r2 = r2.next(() => function(t3, e2) {
      return e2.store(_s.store).Nt().next((n3) => {
        t3.deleteObjectStore(_s.store);
        t3.createObjectStore(_s.store, {
          keyPath: _s.keyPath,
          autoIncrement: true
        }).createIndex(_s.userMutationsIndex, _s.userMutationsKeyPath, {
          unique: true
        });
        const s2 = e2.store(_s.store), i2 = n3.map((t4) => s2.put(t4));
        return Ns.waitFor(i2);
      });
    }(t2, i))), r2 = r2.next(() => {
      !function(t3) {
        t3.createObjectStore(Ps.store, {
          keyPath: Ps.keyPath
        });
      }(t2);
    })), n2 < 5 && s >= 5 && (r2 = r2.next(() => this.Re(i))), n2 < 6 && s >= 6 && (r2 = r2.next(() => (function(t3) {
      t3.createObjectStore(Es.store);
    }(t2), this.Pe(i)))), n2 < 7 && s >= 7 && (r2 = r2.next(() => this.be(i))), n2 < 8 && s >= 8 && (r2 = r2.next(() => this.ve(t2, i))), n2 < 9 && s >= 9 && (r2 = r2.next(() => {
      !function(t3) {
        t3.objectStoreNames.contains("remoteDocumentChanges") && t3.deleteObjectStore("remoteDocumentChanges");
      }(t2), function(t3) {
        const e2 = t3.objectStore(ps.store);
        e2.createIndex(ps.readTimeIndex, ps.readTimeIndexPath, {
          unique: false
        }), e2.createIndex(ps.collectionReadTimeIndex, ps.collectionReadTimeIndexPath, {
          unique: false
        });
      }(e);
    })), n2 < 10 && s >= 10 && (r2 = r2.next(() => this.Ve(i))), n2 < 11 && s >= 11 && (r2 = r2.next(() => {
      !function(t3) {
        t3.createObjectStore(bs.store, {
          keyPath: bs.keyPath
        });
      }(t2), function(t3) {
        t3.createObjectStore(vs.store, {
          keyPath: vs.keyPath
        });
      }(t2);
    })), r2;
  }
  Pe(t2) {
    let e = 0;
    return t2.store(ps.store).Ot((t3, n2) => {
      e += wi(n2);
    }).next(() => {
      const n2 = new Es(e);
      return t2.store(Es.store).put(Es.key, n2);
    });
  }
  Re(t2) {
    const e = t2.store(ws.store), n2 = t2.store(_s.store);
    return e.Nt().next((e2) => Ns.forEach(e2, (e3) => {
      const s = IDBKeyRange.bound([e3.userId, -1], [e3.userId, e3.lastAcknowledgedBatchId]);
      return n2.Nt(_s.userMutationsIndex, s).next((n3) => Ns.forEach(n3, (n4) => {
        L2(n4.userId === e3.userId);
        const s2 = ti(this.R, n4);
        return di(t2, e3.userId, s2).next(() => {
        });
      }));
    }));
  }
  /**
   * Ensures that every document in the remote document cache has a corresponding sentinel row
   * with a sequence number. Missing rows are given the most recently used sequence number.
   */
  be(t2) {
    const e = t2.store(Is.store), n2 = t2.store(ps.store);
    return t2.store(As.store).get(As.key).next((t3) => {
      const s = [];
      return n2.Ot((n3, i) => {
        const r2 = new X2(n3), o = function(t4) {
          return [0, us(t4)];
        }(r2);
        s.push(e.get(o).next((n4) => n4 ? Ns.resolve() : ((n5) => e.put(new Is(0, us(n5), t3.highestListenSequenceNumber)))(r2)));
      }).next(() => Ns.waitFor(s));
    });
  }
  ve(t2, e) {
    t2.createObjectStore(Rs.store, {
      keyPath: Rs.keyPath
    });
    const n2 = e.store(Rs.store), s = new ui(), i = (t3) => {
      if (s.add(t3)) {
        const e2 = t3.lastSegment(), s2 = t3.popLast();
        return n2.put({
          collectionId: e2,
          parent: us(s2)
        });
      }
    };
    return e.store(ps.store).Ot({
      $t: true
    }, (t3, e2) => {
      const n3 = new X2(t3);
      return i(n3.popLast());
    }).next(() => e.store(ms.store).Ot({
      $t: true
    }, ([t3, e2, n3], s2) => {
      const r2 = ls(e2);
      return i(r2.popLast());
    }));
  }
  Ve(t2) {
    const e = t2.store(Ts.store);
    return e.Ot((t3, n2) => {
      const s = ei(n2), i = ni(this.R, s);
      return e.put(i);
    });
  }
};
function Bi(t2) {
  t2.createObjectStore(Is.store, {
    keyPath: Is.keyPath
  }).createIndex(Is.documentTargetsIndex, Is.documentTargetsKeyPath, {
    unique: true
  });
  t2.createObjectStore(Ts.store, {
    keyPath: Ts.keyPath
  }).createIndex(Ts.queryTargetsIndexName, Ts.queryTargetsKeyPath, {
    unique: true
  }), t2.createObjectStore(As.store);
}
var Ui = "Failed to obtain exclusive access to the persistence layer. To allow shared access, multi-tab synchronization has to be enabled in all tabs. If you are using `experimentalForceOwningTab:true`, make sure that only one tab has persistence enabled at any given time.";
var qi = class {
  constructor(t2, e, n2, s, i, r2, o, c, u2, a) {
    if (this.allowTabSynchronization = t2, this.persistenceKey = e, this.clientId = n2, this.Se = i, this.window = r2, this.document = o, this.De = u2, this.Ce = a, this.Ne = null, this.xe = false, this.isPrimary = false, this.networkEnabled = true, /** Our window.unload handler, if registered. */
    this.ke = null, this.inForeground = false, /** Our 'visibilitychange' listener if registered. */
    this.$e = null, /** The client metadata refresh task. */
    this.Oe = null, /** The last time we garbage collected the client metadata object store. */
    this.Fe = Number.NEGATIVE_INFINITY, /** A listener to notify on primary state changes. */
    this.Me = (t3) => Promise.resolve(), !qi.gt())
      throw new D2(S2.UNIMPLEMENTED, "This platform is either missing IndexedDB or is known to have an incomplete implementation. Offline persistence has been disabled.");
    this.referenceDelegate = new Di(this, s), this.Le = e + "main", this.R = new Gs(c), this.Be = new ks(this.Le, 11, new Li(this.R)), this.Ue = new Ti(this.referenceDelegate, this.R), this.qt = new ai(), this.qe = function(t3, e2) {
      return new ki(t3, e2);
    }(this.R, this.qt), this.Ke = new ii(), this.window && this.window.localStorage ? this.Qe = this.window.localStorage : (this.Qe = null, false === a && $("IndexedDbPersistence", "LocalStorage is unavailable. As a result, persistence may not work reliably. In particular enablePersistence() could fail immediately after refreshing the page."));
  }
  /**
   * Attempt to start IndexedDb persistence.
   *
   * @returns Whether persistence was enabled.
   */
  start() {
    return this.je().then(() => {
      if (!this.isPrimary && !this.allowTabSynchronization)
        throw new D2(S2.FAILED_PRECONDITION, Ui);
      return this.We(), this.Ge(), this.ze(), this.runTransaction("getHighestListenSequenceNumber", "readonly", (t2) => this.Ue.getHighestSequenceNumber(t2));
    }).then((t2) => {
      this.Ne = new V2(t2, this.De);
    }).then(() => {
      this.xe = true;
    }).catch((t2) => (this.Be && this.Be.close(), Promise.reject(t2)));
  }
  /**
   * Registers a listener that gets called when the primary state of the
   * instance changes. Upon registering, this listener is invoked immediately
   * with the current primary state.
   *
   * PORTING NOTE: This is only used for Web multi-tab.
   */
  He(t2) {
    return this.Me = async (e) => {
      if (this.started)
        return t2(e);
    }, t2(this.isPrimary);
  }
  /**
   * Registers a listener that gets called when the database receives a
   * version change event indicating that it has deleted.
   *
   * PORTING NOTE: This is only used for Web multi-tab.
   */
  setDatabaseDeletedListener(t2) {
    this.Be.bt(async (e) => {
      null === e.newVersion && await t2();
    });
  }
  /**
   * Adjusts the current network state in the client's metadata, potentially
   * affecting the primary lease.
   *
   * PORTING NOTE: This is only used for Web multi-tab.
   */
  setNetworkEnabled(t2) {
    this.networkEnabled !== t2 && (this.networkEnabled = t2, // Schedule a primary lease refresh for immediate execution. The eventual
    // lease update will be propagated via `primaryStateListener`.
    this.Se.enqueueAndForget(async () => {
      this.started && await this.je();
    }));
  }
  /**
   * Updates the client metadata in IndexedDb and attempts to either obtain or
   * extend the primary lease for the local client. Asynchronously notifies the
   * primary state listener if the client either newly obtained or released its
   * primary lease.
   */
  je() {
    return this.runTransaction("updateClientMetadataAndTryBecomePrimary", "readwrite", (t2) => Qi(t2).put(new Ps(this.clientId, Date.now(), this.networkEnabled, this.inForeground)).next(() => {
      if (this.isPrimary)
        return this.Je(t2).next((t3) => {
          t3 || (this.isPrimary = false, this.Se.enqueueRetryable(() => this.Me(false)));
        });
    }).next(() => this.Ye(t2)).next((e) => this.isPrimary && !e ? this.Xe(t2).next(() => false) : !!e && this.Ze(t2).next(() => true))).catch((t2) => {
      if (Fs(t2))
        return k2("IndexedDbPersistence", "Failed to extend owner lease: ", t2), this.isPrimary;
      if (!this.allowTabSynchronization)
        throw t2;
      return k2("IndexedDbPersistence", "Releasing owner lease after error during lease refresh", t2), /* isPrimary= */
      false;
    }).then((t2) => {
      this.isPrimary !== t2 && this.Se.enqueueRetryable(() => this.Me(t2)), this.isPrimary = t2;
    });
  }
  Je(t2) {
    return Ki(t2).get(ds.key).next((t3) => Ns.resolve(this.tn(t3)));
  }
  en(t2) {
    return Qi(t2).delete(this.clientId);
  }
  /**
   * If the garbage collection threshold has passed, prunes the
   * RemoteDocumentChanges and the ClientMetadata store based on the last update
   * time of all clients.
   */
  async nn() {
    if (this.isPrimary && !this.sn(this.Fe, 18e5)) {
      this.Fe = Date.now();
      const t2 = await this.runTransaction("maybeGarbageCollectMultiClientState", "readwrite-primary", (t3) => {
        const e = Ks(t3, Ps.store);
        return e.Nt().next((t4) => {
          const n2 = this.rn(t4, 18e5), s = t4.filter((t5) => -1 === n2.indexOf(t5));
          return Ns.forEach(s, (t5) => e.delete(t5.clientId)).next(() => s);
        });
      }).catch(() => []);
      if (this.Qe)
        for (const e of t2)
          this.Qe.removeItem(this.on(e.clientId));
    }
  }
  /**
   * Schedules a recurring timer to update the client metadata and to either
   * extend or acquire the primary lease if the client is eligible.
   */
  ze() {
    this.Oe = this.Se.enqueueAfterDelay("client_metadata_refresh", 4e3, () => this.je().then(() => this.nn()).then(() => this.ze()));
  }
  /** Checks whether `client` is the local client. */
  tn(t2) {
    return !!t2 && t2.ownerId === this.clientId;
  }
  /**
   * Evaluate the state of all active clients and determine whether the local
   * client is or can act as the holder of the primary lease. Returns whether
   * the client is eligible for the lease, but does not actually acquire it.
   * May return 'false' even if there is no active leaseholder and another
   * (foreground) client should become leaseholder instead.
   */
  Ye(t2) {
    if (this.Ce)
      return Ns.resolve(true);
    return Ki(t2).get(ds.key).next((e) => {
      if (null !== e && this.sn(e.leaseTimestampMs, 5e3) && !this.cn(e.ownerId)) {
        if (this.tn(e) && this.networkEnabled)
          return true;
        if (!this.tn(e)) {
          if (!e.allowTabSynchronization)
            throw new D2(S2.FAILED_PRECONDITION, Ui);
          return false;
        }
      }
      return !(!this.networkEnabled || !this.inForeground) || Qi(t2).Nt().next((t3) => void 0 === this.rn(t3, 5e3).find((t4) => {
        if (this.clientId !== t4.clientId) {
          const e2 = !this.networkEnabled && t4.networkEnabled, n2 = !this.inForeground && t4.inForeground, s = this.networkEnabled === t4.networkEnabled;
          if (e2 || n2 && s)
            return true;
        }
        return false;
      }));
    }).next((t3) => (this.isPrimary !== t3 && k2("IndexedDbPersistence", `Client ${t3 ? "is" : "is not"} eligible for a primary lease.`), t3));
  }
  async shutdown() {
    this.xe = false, this.un(), this.Oe && (this.Oe.cancel(), this.Oe = null), this.an(), this.hn(), // Use `SimpleDb.runTransaction` directly to avoid failing if another tab
    // has obtained the primary lease.
    await this.Be.runTransaction("shutdown", "readwrite", [ds.store, Ps.store], (t2) => {
      const e = new qs(t2, V2.o);
      return this.Xe(e).next(() => this.en(e));
    }), this.Be.close(), // Remove the entry marking the client as zombied from LocalStorage since
    // we successfully deleted its metadata from IndexedDb.
    this.ln();
  }
  /**
   * Returns clients that are not zombied and have an updateTime within the
   * provided threshold.
   */
  rn(t2, e) {
    return t2.filter((t3) => this.sn(t3.updateTimeMs, e) && !this.cn(t3.clientId));
  }
  /**
   * Returns the IDs of the clients that are currently active. If multi-tab
   * is not supported, returns an array that only contains the local client's
   * ID.
   *
   * PORTING NOTE: This is only used for Web multi-tab.
   */
  fn() {
    return this.runTransaction("getActiveClients", "readonly", (t2) => Qi(t2).Nt().next((t3) => this.rn(t3, 18e5).map((t4) => t4.clientId)));
  }
  get started() {
    return this.xe;
  }
  getMutationQueue(t2) {
    return _i.Qt(t2, this.R, this.qt, this.referenceDelegate);
  }
  getTargetCache() {
    return this.Ue;
  }
  getRemoteDocumentCache() {
    return this.qe;
  }
  getIndexManager() {
    return this.qt;
  }
  getBundleCache() {
    return this.Ke;
  }
  runTransaction(t2, e, n2) {
    k2("IndexedDbPersistence", "Starting transaction:", t2);
    const s = "readonly" === e ? "readonly" : "readwrite";
    let i;
    return this.Be.runTransaction(t2, s, Vs, (s2) => (i = new qs(s2, this.Ne ? this.Ne.next() : V2.o), "readwrite-primary" === e ? this.Je(i).next((t3) => !!t3 || this.Ye(i)).next((e2) => {
      if (!e2)
        throw $(`Failed to obtain primary lease for action '${t2}'.`), this.isPrimary = false, this.Se.enqueueRetryable(() => this.Me(false)), new D2(S2.FAILED_PRECONDITION, Ss);
      return n2(i);
    }).next((t3) => this.Ze(i).next(() => t3)) : this.dn(i).next(() => n2(i)))).then((t3) => (i.raiseOnCommittedEvent(), t3));
  }
  /**
   * Verifies that the current tab is the primary leaseholder or alternatively
   * that the leaseholder has opted into multi-tab synchronization.
   */
  // TODO(b/114226234): Remove this check when `synchronizeTabs` can no longer
  // be turned off.
  dn(t2) {
    return Ki(t2).get(ds.key).next((t3) => {
      if (null !== t3 && this.sn(t3.leaseTimestampMs, 5e3) && !this.cn(t3.ownerId) && !this.tn(t3) && !(this.Ce || this.allowTabSynchronization && t3.allowTabSynchronization))
        throw new D2(S2.FAILED_PRECONDITION, Ui);
    });
  }
  /**
   * Obtains or extends the new primary lease for the local client. This
   * method does not verify that the client is eligible for this lease.
   */
  Ze(t2) {
    const e = new ds(this.clientId, this.allowTabSynchronization, Date.now());
    return Ki(t2).put(ds.key, e);
  }
  static gt() {
    return ks.gt();
  }
  /** Checks the primary lease and removes it if we are the current primary. */
  Xe(t2) {
    const e = Ki(t2);
    return e.get(ds.key).next((t3) => this.tn(t3) ? (k2("IndexedDbPersistence", "Releasing primary lease."), e.delete(ds.key)) : Ns.resolve());
  }
  /** Verifies that `updateTimeMs` is within `maxAgeMs`. */
  sn(t2, e) {
    const n2 = Date.now();
    return !(t2 < n2 - e) && (!(t2 > n2) || ($(`Detected an update time that is in the future: ${t2} > ${n2}`), false));
  }
  We() {
    null !== this.document && "function" == typeof this.document.addEventListener && (this.$e = () => {
      this.Se.enqueueAndForget(() => (this.inForeground = "visible" === this.document.visibilityState, this.je()));
    }, this.document.addEventListener("visibilitychange", this.$e), this.inForeground = "visible" === this.document.visibilityState);
  }
  an() {
    this.$e && (this.document.removeEventListener("visibilitychange", this.$e), this.$e = null);
  }
  /**
   * Attaches a window.unload handler that will synchronously write our
   * clientId to a "zombie client id" location in LocalStorage. This can be used
   * by tabs trying to acquire the primary lease to determine that the lease
   * is no longer valid even if the timestamp is recent. This is particularly
   * important for the refresh case (so the tab correctly re-acquires the
   * primary lease). LocalStorage is used for this rather than IndexedDb because
   * it is a synchronous API and so can be used reliably from  an unload
   * handler.
   */
  Ge() {
    var t2;
    "function" == typeof (null === (t2 = this.window) || void 0 === t2 ? void 0 : t2.addEventListener) && (this.ke = () => {
      this.un(), this.Se.enqueueAndForget(() => this.shutdown());
    }, this.window.addEventListener("pagehide", this.ke));
  }
  hn() {
    this.ke && (this.window.removeEventListener("pagehide", this.ke), this.ke = null);
  }
  /**
   * Returns whether a client is "zombied" based on its LocalStorage entry.
   * Clients become zombied when their tab closes without running all of the
   * cleanup logic in `shutdown()`.
   */
  cn(t2) {
    var e;
    try {
      const n2 = null !== (null === (e = this.Qe) || void 0 === e ? void 0 : e.getItem(this.on(t2)));
      return k2("IndexedDbPersistence", `Client '${t2}' ${n2 ? "is" : "is not"} zombied in LocalStorage`), n2;
    } catch (t3) {
      return $("IndexedDbPersistence", "Failed to get zombied client id.", t3), false;
    }
  }
  /**
   * Record client as zombied (a client that had its tab closed). Zombied
   * clients are ignored during primary tab selection.
   */
  un() {
    if (this.Qe)
      try {
        this.Qe.setItem(this.on(this.clientId), String(Date.now()));
      } catch (t2) {
        $("Failed to set zombie client id.", t2);
      }
  }
  /** Removes the zombied client entry if it exists. */
  ln() {
    if (this.Qe)
      try {
        this.Qe.removeItem(this.on(this.clientId));
      } catch (t2) {
      }
  }
  on(t2) {
    return `firestore_zombie_${this.persistenceKey}_${t2}`;
  }
};
function Ki(t2) {
  return Ks(t2, ds.store);
}
function Qi(t2) {
  return Ks(t2, Ps.store);
}
function ji(t2, e) {
  let n2 = t2.projectId;
  return t2.isDefaultDatabase || (n2 += "." + t2.database), "firestore/" + e + "/" + n2 + "/";
}
var Wi = class {
  constructor(t2, e) {
    this.progress = t2, this.wn = e;
  }
};
var Gi = class {
  constructor(t2, e, n2) {
    this.qe = t2, this._n = e, this.qt = n2;
  }
  /**
   * Get the local view of the document identified by `key`.
   *
   * @returns Local view of the document or null if we don't have any cached
   * state for it.
   */
  mn(t2, e) {
    return this._n.getAllMutationBatchesAffectingDocumentKey(t2, e).next((n2) => this.gn(t2, e, n2));
  }
  /** Internal version of `getDocument` that allows reusing batches. */
  gn(t2, e, n2) {
    return this.qe.getEntry(t2, e).next((t3) => {
      for (const e2 of n2)
        e2.applyToLocalView(t3);
      return t3;
    });
  }
  // Returns the view of the given `docs` as they would appear after applying
  // all mutations in the given `batches`.
  yn(t2, e) {
    t2.forEach((t3, n2) => {
      for (const t4 of e)
        t4.applyToLocalView(n2);
    });
  }
  /**
   * Gets the local view of the documents identified by `keys`.
   *
   * If we don't have cached state for a document in `keys`, a NoDocument will
   * be stored for that key in the resulting set.
   */
  pn(t2, e) {
    return this.qe.getEntries(t2, e).next((e2) => this.En(t2, e2).next(() => e2));
  }
  /**
   * Applies the local view the given `baseDocs` without retrieving documents
   * from the local store.
   */
  En(t2, e) {
    return this._n.getAllMutationBatchesAffectingDocumentKeys(t2, e).next((t3) => this.yn(e, t3));
  }
  /**
   * Performs a query against the local view of all documents.
   *
   * @param transaction - The persistence transaction.
   * @param query - The query to match documents against.
   * @param sinceReadTime - If not set to SnapshotVersion.min(), return only
   *     documents that have been read since this snapshot version (exclusive).
   */
  getDocumentsMatchingQuery(t2, e, n2) {
    return function(t3) {
      return dt.isDocumentKey(t3.path) && null === t3.collectionGroup && 0 === t3.filters.length;
    }(e) ? this.Tn(t2, e.path) : oe(e) ? this.In(t2, e, n2) : this.An(t2, e, n2);
  }
  Tn(t2, e) {
    return this.mn(t2, new dt(e)).next((t3) => {
      let e2 = an();
      return t3.isFoundDocument() && (e2 = e2.insert(t3.key, t3)), e2;
    });
  }
  In(t2, e, n2) {
    const s = e.collectionGroup;
    let i = an();
    return this.qt.getCollectionParents(t2, s).next((r2) => Ns.forEach(r2, (r3) => {
      const o = function(t3, e2) {
        return new Zt(
          e2,
          /*collectionGroup=*/
          null,
          t3.explicitOrderBy.slice(),
          t3.filters.slice(),
          t3.limit,
          t3.limitType,
          t3.startAt,
          t3.endAt
        );
      }(e, r3.child(s));
      return this.An(t2, o, n2).next((t3) => {
        t3.forEach((t4, e2) => {
          i = i.insert(t4, e2);
        });
      });
    }).next(() => i));
  }
  An(t2, e, n2) {
    let s, i;
    return this.qe.getDocumentsMatchingQuery(t2, e, n2).next((n3) => (s = n3, this._n.getAllMutationBatchesAffectingQuery(t2, e))).next((e2) => (i = e2, this.Rn(t2, i, s).next((t3) => {
      s = t3;
      for (const t4 of i)
        for (const e3 of t4.mutations) {
          const n3 = e3.key;
          let i2 = s.get(n3);
          null == i2 && // Create invalid document to apply mutations on top of
          (i2 = Dt.newInvalidDocument(n3), s = s.insert(n3, i2)), Me(e3, i2, t4.localWriteTime), i2.isFoundDocument() || (s = s.remove(n3));
        }
    }))).next(() => (
      // Finally, filter out any documents that don't actually match
      // the query.
      (s.forEach((t3, n3) => {
        de(e, n3) || (s = s.remove(t3));
      }), s)
    ));
  }
  Rn(t2, e, n2) {
    let s = dn();
    for (const t3 of e)
      for (const e2 of t3.mutations)
        e2 instanceof Ke && null === n2.get(e2.key) && (s = s.add(e2.key));
    let i = n2;
    return this.qe.getEntries(t2, s).next((t3) => (t3.forEach((t4, e2) => {
      e2.isFoundDocument() && (i = i.insert(t4, e2));
    }), i));
  }
};
var zi = class {
  constructor(t2, e, n2, s) {
    this.targetId = t2, this.fromCache = e, this.Pn = n2, this.bn = s;
  }
  static vn(t2, e) {
    let n2 = dn(), s = dn();
    for (const t3 of e.docChanges)
      switch (t3.type) {
        case 0:
          n2 = n2.add(t3.doc.key);
          break;
        case 1:
          s = s.add(t3.doc.key);
      }
    return new zi(t2, e.fromCache, n2, s);
  }
};
var Hi = class {
  /** Sets the document view to query against. */
  Vn(t2) {
    this.Sn = t2;
  }
  /** Returns all local documents matching the specified query. */
  getDocumentsMatchingQuery(t2, e, n2, s) {
    return function(t3) {
      return 0 === t3.filters.length && null === t3.limit && null == t3.startAt && null == t3.endAt && (0 === t3.explicitOrderBy.length || 1 === t3.explicitOrderBy.length && t3.explicitOrderBy[0].field.isKeyField());
    }(e) || n2.isEqual(G2.min()) ? this.Dn(t2, e) : this.Sn.pn(t2, s).next((i) => {
      const r2 = this.Cn(e, i);
      return (ne(e) || se(e)) && this.Nn(e.limitType, r2, s, n2) ? this.Dn(t2, e) : (N2() <= LogLevel.DEBUG && k2("QueryEngine", "Re-using previous result from %s to execute query: %s", n2.toString(), fe(e)), this.Sn.getDocumentsMatchingQuery(t2, e, n2).next((t3) => (
        // We merge `previousResults` into `updateResults`, since
        // `updateResults` is already a DocumentMap. If a document is
        // contained in both lists, then its contents are the same.
        (r2.forEach((e2) => {
          t3 = t3.insert(e2.key, e2);
        }), t3)
      )));
    });
  }
  /** Applies the query filter and sorting to the provided documents.  */
  Cn(t2, e) {
    let n2 = new sn(we(t2));
    return e.forEach((e2, s) => {
      de(t2, s) && (n2 = n2.add(s));
    }), n2;
  }
  /**
   * Determines if a limit query needs to be refilled from cache, making it
   * ineligible for index-free execution.
   *
   * @param sortedPreviousResults - The documents that matched the query when it
   * was last synchronized, sorted by the query's comparator.
   * @param remoteKeys - The document keys that matched the query at the last
   * snapshot.
   * @param limboFreeSnapshotVersion - The version of the snapshot when the
   * query was last synchronized.
   */
  Nn(t2, e, n2, s) {
    if (n2.size !== e.size)
      return true;
    const i = "F" === t2 ? e.last() : e.first();
    return !!i && (i.hasPendingWrites || i.version.compareTo(s) > 0);
  }
  Dn(t2, e) {
    return N2() <= LogLevel.DEBUG && k2("QueryEngine", "Using full collection scan to execute query:", fe(e)), this.Sn.getDocumentsMatchingQuery(t2, e, G2.min());
  }
};
var Ji = class {
  constructor(t2, e, n2, s) {
    this.persistence = t2, this.xn = e, this.R = s, /**
     * Maps a targetID to data about its target.
     *
     * PORTING NOTE: We are using an immutable data structure on Web to make re-runs
     * of `applyRemoteEvent()` idempotent.
     */
    this.kn = new tn(K2), /** Maps a target to its targetID. */
    // TODO(wuandy): Evaluate if TargetId can be part of Target.
    this.$n = new Ni((t3) => xt(t3), $t), /**
     * The read time of the last entry processed by `getNewDocumentChanges()`.
     *
     * PORTING NOTE: This is only used for multi-tab synchronization.
     */
    this.On = G2.min(), this._n = t2.getMutationQueue(n2), this.Fn = t2.getRemoteDocumentCache(), this.Ue = t2.getTargetCache(), this.Mn = new Gi(this.Fn, this._n, this.persistence.getIndexManager()), this.Ke = t2.getBundleCache(), this.xn.Vn(this.Mn);
  }
  collectGarbage(t2) {
    return this.persistence.runTransaction("Collect garbage", "readwrite-primary", (e) => t2.collect(e, this.kn));
  }
};
function Yi(t2, e, n2, s) {
  return new Ji(t2, e, n2, s);
}
async function Xi(t2, e) {
  const n2 = B(t2);
  let s = n2._n, i = n2.Mn;
  const r2 = await n2.persistence.runTransaction("Handle user change", "readonly", (t3) => {
    let r3;
    return n2._n.getAllMutationBatches(t3).next((o) => (r3 = o, s = n2.persistence.getMutationQueue(e), // Recreate our LocalDocumentsView using the new
    // MutationQueue.
    i = new Gi(n2.Fn, s, n2.persistence.getIndexManager()), s.getAllMutationBatches(t3))).next((e2) => {
      const n3 = [], s2 = [];
      let o = dn();
      for (const t4 of r3) {
        n3.push(t4.batchId);
        for (const e3 of t4.mutations)
          o = o.add(e3.key);
      }
      for (const t4 of e2) {
        s2.push(t4.batchId);
        for (const e3 of t4.mutations)
          o = o.add(e3.key);
      }
      return i.pn(t3, o).next((t4) => ({
        Ln: t4,
        removedBatchIds: n3,
        addedBatchIds: s2
      }));
    });
  });
  return n2._n = s, n2.Mn = i, n2.xn.Vn(n2.Mn), r2;
}
function Zi(t2, e) {
  const n2 = B(t2);
  return n2.persistence.runTransaction("Acknowledge batch", "readwrite-primary", (t3) => {
    const s = e.batch.keys(), i = n2.Fn.newChangeBuffer({
      trackRemovals: true
    });
    return function(t4, e2, n3, s2) {
      const i2 = n3.batch, r2 = i2.keys();
      let o = Ns.resolve();
      return r2.forEach((t5) => {
        o = o.next(() => s2.getEntry(e2, t5)).next((e3) => {
          const r3 = n3.docVersions.get(t5);
          L2(null !== r3), e3.version.compareTo(r3) < 0 && (i2.applyToRemoteDocument(e3, n3), e3.isValidDocument() && // We use the commitVersion as the readTime rather than the
          // document's updateTime since the updateTime is not advanced
          // for updates that do not modify the underlying document.
          s2.addEntry(e3, n3.commitVersion));
        });
      }), o.next(() => t4._n.removeMutationBatch(e2, i2));
    }(n2, t3, e, i).next(() => i.apply(t3)).next(() => n2._n.performConsistencyCheck(t3)).next(() => n2.Mn.pn(t3, s));
  });
}
function tr(t2) {
  const e = B(t2);
  return e.persistence.runTransaction("Get last remote snapshot version", "readonly", (t3) => e.Ue.getLastRemoteSnapshotVersion(t3));
}
function er(t2, e) {
  const n2 = B(t2), s = e.snapshotVersion;
  let i = n2.kn;
  return n2.persistence.runTransaction("Apply remote event", "readwrite-primary", (t3) => {
    const r2 = n2.Fn.newChangeBuffer({
      trackRemovals: true
    });
    i = n2.kn;
    const o = [];
    e.targetChanges.forEach((e2, r3) => {
      const c2 = i.get(r3);
      if (!c2)
        return;
      o.push(n2.Ue.removeMatchingKeys(t3, e2.removedDocuments, r3).next(() => n2.Ue.addMatchingKeys(t3, e2.addedDocuments, r3)));
      const u2 = e2.resumeToken;
      if (u2.approximateByteSize() > 0) {
        const a = c2.withResumeToken(u2, s).withSequenceNumber(t3.currentSequenceNumber);
        i = i.insert(r3, a), // Update the target data if there are target changes (or if
        // sufficient time has passed since the last update).
        /**
        * Returns true if the newTargetData should be persisted during an update of
        * an active target. TargetData should always be persisted when a target is
        * being released and should not call this function.
        *
        * While the target is active, TargetData updates can be omitted when nothing
        * about the target has changed except metadata like the resume token or
        * snapshot version. Occasionally it's worth the extra write to prevent these
        * values from getting too stale after a crash, but this doesn't have to be
        * too frequent.
        */
        function(t4, e3, n3) {
          if (L2(e3.resumeToken.approximateByteSize() > 0), 0 === t4.resumeToken.approximateByteSize())
            return true;
          if (e3.snapshotVersion.toMicroseconds() - t4.snapshotVersion.toMicroseconds() >= 3e8)
            return true;
          return n3.addedDocuments.size + n3.modifiedDocuments.size + n3.removedDocuments.size > 0;
        }(c2, a, e2) && o.push(n2.Ue.updateTargetData(t3, a));
      }
    });
    let c = cn();
    if (e.documentUpdates.forEach((s2, i2) => {
      e.resolvedLimboDocuments.has(s2) && o.push(n2.persistence.referenceDelegate.updateLimboDocument(t3, s2));
    }), // Each loop iteration only affects its "own" doc, so it's safe to get all the remote
    // documents in advance in a single call.
    o.push(nr(t3, r2, e.documentUpdates, s, void 0).next((t4) => {
      c = t4;
    })), !s.isEqual(G2.min())) {
      const e2 = n2.Ue.getLastRemoteSnapshotVersion(t3).next((e3) => n2.Ue.setTargetsMetadata(t3, t3.currentSequenceNumber, s));
      o.push(e2);
    }
    return Ns.waitFor(o).next(() => r2.apply(t3)).next(() => n2.Mn.En(t3, c)).next(() => c);
  }).then((t3) => (n2.kn = i, t3));
}
function nr(t2, e, n2, s, i) {
  let r2 = dn();
  return n2.forEach((t3) => r2 = r2.add(t3)), e.getEntries(t2, r2).next((t3) => {
    let r3 = cn();
    return n2.forEach((n3, o) => {
      const c = t3.get(n3), u2 = (null == i ? void 0 : i.get(n3)) || s;
      o.isNoDocument() && o.version.isEqual(G2.min()) ? (
        // NoDocuments with SnapshotVersion.min() are used in manufactured
        // events. We remove these documents from cache since we lost
        // access.
        (e.removeEntry(n3, u2), r3 = r3.insert(n3, o))
      ) : !c.isValidDocument() || o.version.compareTo(c.version) > 0 || 0 === o.version.compareTo(c.version) && c.hasPendingWrites ? (e.addEntry(o, u2), r3 = r3.insert(n3, o)) : k2("LocalStore", "Ignoring outdated watch update for ", n3, ". Current version:", c.version, " Watch version:", o.version);
    }), r3;
  });
}
function sr(t2, e) {
  const n2 = B(t2);
  return n2.persistence.runTransaction("Get next mutation batch", "readonly", (t3) => (void 0 === e && (e = -1), n2._n.getNextMutationBatchAfterBatchId(t3, e)));
}
function ir(t2, e) {
  const n2 = B(t2);
  return n2.persistence.runTransaction("Allocate target", "readwrite", (t3) => {
    let s;
    return n2.Ue.getTargetData(t3, e).next((i) => i ? (
      // This target has been listened to previously, so reuse the
      // previous targetID.
      // TODO(mcg): freshen last accessed date?
      (s = i, Ns.resolve(s))
    ) : n2.Ue.allocateTargetId(t3).next((i2) => (s = new Ws(e, i2, 0, t3.currentSequenceNumber), n2.Ue.addTargetData(t3, s).next(() => s))));
  }).then((t3) => {
    const s = n2.kn.get(t3.targetId);
    return (null === s || t3.snapshotVersion.compareTo(s.snapshotVersion) > 0) && (n2.kn = n2.kn.insert(t3.targetId, t3), n2.$n.set(e, t3.targetId)), t3;
  });
}
async function rr(t2, e, n2) {
  const s = B(t2), i = s.kn.get(e), r2 = n2 ? "readwrite" : "readwrite-primary";
  try {
    n2 || await s.persistence.runTransaction("Release target", r2, (t3) => s.persistence.referenceDelegate.removeTarget(t3, i));
  } catch (t3) {
    if (!Fs(t3))
      throw t3;
    k2("LocalStore", `Failed to update sequence numbers for target ${e}: ${t3}`);
  }
  s.kn = s.kn.remove(e), s.$n.delete(i.target);
}
function or(t2, e, n2) {
  const s = B(t2);
  let i = G2.min(), r2 = dn();
  return s.persistence.runTransaction("Execute query", "readonly", (t3) => function(t4, e2, n3) {
    const s2 = B(t4), i2 = s2.$n.get(n3);
    return void 0 !== i2 ? Ns.resolve(s2.kn.get(i2)) : s2.Ue.getTargetData(e2, n3);
  }(s, t3, ue(e)).next((e2) => {
    if (e2)
      return i = e2.lastLimboFreeSnapshotVersion, s.Ue.getMatchingKeysForTargetId(t3, e2.targetId).next((t4) => {
        r2 = t4;
      });
  }).next(() => s.xn.getDocumentsMatchingQuery(t3, e, n2 ? i : G2.min(), n2 ? r2 : dn())).next((t4) => ({
    documents: t4,
    Bn: r2
  })));
}
function cr(t2, e) {
  const n2 = B(t2), s = B(n2.Ue), i = n2.kn.get(e);
  return i ? Promise.resolve(i.target) : n2.persistence.runTransaction("Get target data", "readonly", (t3) => s.lt(t3, e).next((t4) => t4 ? t4.target : null));
}
function ur(t2) {
  const e = B(t2);
  return e.persistence.runTransaction("Get new document changes", "readonly", (t3) => function(t4, e2, n2) {
    const s = B(t4);
    let i = cn(), r2 = Js(n2);
    const o = Fi(e2), c = IDBKeyRange.lowerBound(r2, true);
    return o.Ot({
      index: ps.readTimeIndex,
      range: c
    }, (t5, e3) => {
      const n3 = zs(s.R, e3);
      i = i.insert(n3.key, n3), r2 = e3.readTime;
    }).next(() => ({
      wn: i,
      readTime: Ys(r2)
    }));
  }(e.Fn, t3, e.On)).then(({ wn: t3, readTime: n2 }) => (e.On = n2, t3));
}
async function ar(t2) {
  const e = B(t2);
  return e.persistence.runTransaction("Synchronize last document change read time", "readonly", (t3) => function(t4) {
    const e2 = Fi(t4);
    let n2 = G2.min();
    return e2.Ot({
      index: ps.readTimeIndex,
      reverse: true
    }, (t5, e3, s) => {
      e3.readTime && (n2 = Ys(e3.readTime)), s.done();
    }).next(() => n2);
  }(t3)).then((t3) => {
    e.On = t3;
  });
}
async function hr(t2, e, n2, s) {
  const i = B(t2);
  let r2 = dn(), o = cn(), c = ln();
  for (const t3 of n2) {
    const n3 = e.Un(t3.metadata.name);
    t3.document && (r2 = r2.add(n3)), o = o.insert(n3, e.qn(t3)), c = c.insert(n3, e.Kn(t3.metadata.readTime));
  }
  const u2 = i.Fn.newChangeBuffer({
    trackRemovals: true
  }), a = await ir(i, function(t3) {
    return ue(ee(X2.fromString(`__bundle__/docs/${t3}`)));
  }(s));
  return i.persistence.runTransaction("Apply bundle documents", "readwrite", (t3) => nr(t3, u2, o, G2.min(), c).next((e2) => (u2.apply(t3), e2)).next((e2) => i.Ue.removeMatchingKeysForTargetId(t3, a.targetId).next(() => i.Ue.addMatchingKeys(t3, r2, a.targetId)).next(() => i.Mn.En(t3, e2)).next(() => e2)));
}
async function lr(t2, e, n2 = dn()) {
  const s = await ir(t2, ue(si(e.bundledQuery))), i = B(t2);
  return i.persistence.runTransaction("Save named query", "readwrite", (t3) => {
    const r2 = Cn(e.readTime);
    if (s.snapshotVersion.compareTo(r2) >= 0)
      return i.Ke.saveNamedQuery(t3, e);
    const o = s.withResumeToken(nt.EMPTY_BYTE_STRING, r2);
    return i.kn = i.kn.insert(o.targetId, o), i.Ue.updateTargetData(t3, o).next(() => i.Ue.removeMatchingKeysForTargetId(t3, s.targetId)).next(() => i.Ue.addMatchingKeys(t3, n2, s.targetId)).next(() => i.Ke.saveNamedQuery(t3, e));
  });
}
var fr = class {
  constructor(t2) {
    this.R = t2, this.Qn = /* @__PURE__ */ new Map(), this.jn = /* @__PURE__ */ new Map();
  }
  getBundleMetadata(t2, e) {
    return Ns.resolve(this.Qn.get(e));
  }
  saveBundleMetadata(t2, e) {
    var n2;
    return this.Qn.set(e.id, {
      id: (n2 = e).id,
      version: n2.version,
      createTime: Cn(n2.createTime)
    }), Ns.resolve();
  }
  getNamedQuery(t2, e) {
    return Ns.resolve(this.jn.get(e));
  }
  saveNamedQuery(t2, e) {
    return this.jn.set(e.name, function(t3) {
      return {
        name: t3.name,
        query: si(t3.bundledQuery),
        readTime: Cn(t3.readTime)
      };
    }(e)), Ns.resolve();
  }
};
var dr = class {
  constructor() {
    this.Wn = new sn(wr.Gn), // A set of outstanding references to a document sorted by target id.
    this.zn = new sn(wr.Hn);
  }
  /** Returns true if the reference set contains no references. */
  isEmpty() {
    return this.Wn.isEmpty();
  }
  /** Adds a reference to the given document key for the given ID. */
  addReference(t2, e) {
    const n2 = new wr(t2, e);
    this.Wn = this.Wn.add(n2), this.zn = this.zn.add(n2);
  }
  /** Add references to the given document keys for the given ID. */
  Jn(t2, e) {
    t2.forEach((t3) => this.addReference(t3, e));
  }
  /**
   * Removes a reference to the given document key for the given
   * ID.
   */
  removeReference(t2, e) {
    this.Yn(new wr(t2, e));
  }
  Xn(t2, e) {
    t2.forEach((t3) => this.removeReference(t3, e));
  }
  /**
   * Clears all references with a given ID. Calls removeRef() for each key
   * removed.
   */
  Zn(t2) {
    const e = new dt(new X2([])), n2 = new wr(e, t2), s = new wr(e, t2 + 1), i = [];
    return this.zn.forEachInRange([n2, s], (t3) => {
      this.Yn(t3), i.push(t3.key);
    }), i;
  }
  ts() {
    this.Wn.forEach((t2) => this.Yn(t2));
  }
  Yn(t2) {
    this.Wn = this.Wn.delete(t2), this.zn = this.zn.delete(t2);
  }
  es(t2) {
    const e = new dt(new X2([])), n2 = new wr(e, t2), s = new wr(e, t2 + 1);
    let i = dn();
    return this.zn.forEachInRange([n2, s], (t3) => {
      i = i.add(t3.key);
    }), i;
  }
  containsKey(t2) {
    const e = new wr(t2, 0), n2 = this.Wn.firstAfterOrEqual(e);
    return null !== n2 && t2.isEqual(n2.key);
  }
};
var wr = class {
  constructor(t2, e) {
    this.key = t2, this.ns = e;
  }
  /** Compare by key then by ID */
  static Gn(t2, e) {
    return dt.comparator(t2.key, e.key) || K2(t2.ns, e.ns);
  }
  /** Compare by ID then by key */
  static Hn(t2, e) {
    return K2(t2.ns, e.ns) || dt.comparator(t2.key, e.key);
  }
};
var _r = class {
  constructor(t2, e) {
    this.qt = t2, this.referenceDelegate = e, /**
     * The set of all mutations that have been sent but not yet been applied to
     * the backend.
     */
    this._n = [], /** Next value to use when assigning sequential IDs to each mutation batch. */
    this.ss = 1, /** An ordered mapping between documents and the mutations batch IDs. */
    this.rs = new sn(wr.Gn);
  }
  checkEmpty(t2) {
    return Ns.resolve(0 === this._n.length);
  }
  addMutationBatch(t2, e, n2, s) {
    const i = this.ss;
    this.ss++, this._n.length > 0 && this._n[this._n.length - 1];
    const r2 = new Qs(i, e, n2, s);
    this._n.push(r2);
    for (const e2 of s)
      this.rs = this.rs.add(new wr(e2.key, i)), this.qt.addToCollectionParentIndex(t2, e2.key.path.popLast());
    return Ns.resolve(r2);
  }
  lookupMutationBatch(t2, e) {
    return Ns.resolve(this.os(e));
  }
  getNextMutationBatchAfterBatchId(t2, e) {
    const n2 = e + 1, s = this.cs(n2), i = s < 0 ? 0 : s;
    return Ns.resolve(this._n.length > i ? this._n[i] : null);
  }
  getHighestUnacknowledgedBatchId() {
    return Ns.resolve(0 === this._n.length ? -1 : this.ss - 1);
  }
  getAllMutationBatches(t2) {
    return Ns.resolve(this._n.slice());
  }
  getAllMutationBatchesAffectingDocumentKey(t2, e) {
    const n2 = new wr(e, 0), s = new wr(e, Number.POSITIVE_INFINITY), i = [];
    return this.rs.forEachInRange([n2, s], (t3) => {
      const e2 = this.os(t3.ns);
      i.push(e2);
    }), Ns.resolve(i);
  }
  getAllMutationBatchesAffectingDocumentKeys(t2, e) {
    let n2 = new sn(K2);
    return e.forEach((t3) => {
      const e2 = new wr(t3, 0), s = new wr(t3, Number.POSITIVE_INFINITY);
      this.rs.forEachInRange([e2, s], (t4) => {
        n2 = n2.add(t4.ns);
      });
    }), Ns.resolve(this.us(n2));
  }
  getAllMutationBatchesAffectingQuery(t2, e) {
    const n2 = e.path, s = n2.length + 1;
    let i = n2;
    dt.isDocumentKey(i) || (i = i.child(""));
    const r2 = new wr(new dt(i), 0);
    let o = new sn(K2);
    return this.rs.forEachWhile((t3) => {
      const e2 = t3.key.path;
      return !!n2.isPrefixOf(e2) && // Rows with document keys more than one segment longer than the query
      // path can't be matches. For example, a query on 'rooms' can't match
      // the document /rooms/abc/messages/xyx.
      // TODO(mcg): we'll need a different scanner when we implement
      // ancestor queries.
      (e2.length === s && (o = o.add(t3.ns)), true);
    }, r2), Ns.resolve(this.us(o));
  }
  us(t2) {
    const e = [];
    return t2.forEach((t3) => {
      const n2 = this.os(t3);
      null !== n2 && e.push(n2);
    }), e;
  }
  removeMutationBatch(t2, e) {
    L2(0 === this.hs(e.batchId, "removed")), this._n.shift();
    let n2 = this.rs;
    return Ns.forEach(e.mutations, (s) => {
      const i = new wr(s.key, e.batchId);
      return n2 = n2.delete(i), this.referenceDelegate.markPotentiallyOrphaned(t2, s.key);
    }).next(() => {
      this.rs = n2;
    });
  }
  Gt(t2) {
  }
  containsKey(t2, e) {
    const n2 = new wr(e, 0), s = this.rs.firstAfterOrEqual(n2);
    return Ns.resolve(e.isEqual(s && s.key));
  }
  performConsistencyCheck(t2) {
    return this._n.length, Ns.resolve();
  }
  /**
   * Finds the index of the given batchId in the mutation queue and asserts that
   * the resulting index is within the bounds of the queue.
   *
   * @param batchId - The batchId to search for
   * @param action - A description of what the caller is doing, phrased in passive
   * form (e.g. "acknowledged" in a routine that acknowledges batches).
   */
  hs(t2, e) {
    return this.cs(t2);
  }
  /**
   * Finds the index of the given batchId in the mutation queue. This operation
   * is O(1).
   *
   * @returns The computed index of the batch with the given batchId, based on
   * the state of the queue. Note this index can be negative if the requested
   * batchId has already been remvoed from the queue or past the end of the
   * queue if the batchId is larger than the last added batch.
   */
  cs(t2) {
    if (0 === this._n.length)
      return 0;
    return t2 - this._n[0].batchId;
  }
  /**
   * A version of lookupMutationBatch that doesn't return a promise, this makes
   * other functions that uses this code easier to read and more efficent.
   */
  os(t2) {
    const e = this.cs(t2);
    if (e < 0 || e >= this._n.length)
      return null;
    return this._n[e];
  }
};
var mr = class {
  /**
   * @param sizer - Used to assess the size of a document. For eager GC, this is
   * expected to just return 0 to avoid unnecessarily doing the work of
   * calculating the size.
   */
  constructor(t2, e) {
    this.qt = t2, this.ls = e, /** Underlying cache of documents and their read times. */
    this.docs = new tn(dt.comparator), /** Size of all cached documents. */
    this.size = 0;
  }
  /**
   * Adds the supplied entry to the cache and updates the cache size as appropriate.
   *
   * All calls of `addEntry`  are required to go through the RemoteDocumentChangeBuffer
   * returned by `newChangeBuffer()`.
   */
  addEntry(t2, e, n2) {
    const s = e.key, i = this.docs.get(s), r2 = i ? i.size : 0, o = this.ls(e);
    return this.docs = this.docs.insert(s, {
      document: e.clone(),
      size: o,
      readTime: n2
    }), this.size += o - r2, this.qt.addToCollectionParentIndex(t2, s.path.popLast());
  }
  /**
   * Removes the specified entry from the cache and updates the cache size as appropriate.
   *
   * All calls of `removeEntry` are required to go through the RemoteDocumentChangeBuffer
   * returned by `newChangeBuffer()`.
   */
  removeEntry(t2) {
    const e = this.docs.get(t2);
    e && (this.docs = this.docs.remove(t2), this.size -= e.size);
  }
  getEntry(t2, e) {
    const n2 = this.docs.get(e);
    return Ns.resolve(n2 ? n2.document.clone() : Dt.newInvalidDocument(e));
  }
  getEntries(t2, e) {
    let n2 = cn();
    return e.forEach((t3) => {
      const e2 = this.docs.get(t3);
      n2 = n2.insert(t3, e2 ? e2.document.clone() : Dt.newInvalidDocument(t3));
    }), Ns.resolve(n2);
  }
  getDocumentsMatchingQuery(t2, e, n2) {
    let s = cn();
    const i = new dt(e.path.child("")), r2 = this.docs.getIteratorFrom(i);
    for (; r2.hasNext(); ) {
      const { key: t3, value: { document: i2, readTime: o } } = r2.getNext();
      if (!e.path.isPrefixOf(t3.path))
        break;
      o.compareTo(n2) <= 0 || de(e, i2) && (s = s.insert(i2.key, i2.clone()));
    }
    return Ns.resolve(s);
  }
  fs(t2, e) {
    return Ns.forEach(this.docs, (t3) => e(t3));
  }
  newChangeBuffer(t2) {
    return new gr(this);
  }
  getSize(t2) {
    return Ns.resolve(this.size);
  }
};
var gr = class extends xi {
  constructor(t2) {
    super(), this.Ie = t2;
  }
  applyChanges(t2) {
    const e = [];
    return this.changes.forEach((n2, s) => {
      s.document.isValidDocument() ? e.push(this.Ie.addEntry(t2, s.document, this.getReadTime(n2))) : this.Ie.removeEntry(n2);
    }), Ns.waitFor(e);
  }
  getFromCache(t2, e) {
    return this.Ie.getEntry(t2, e);
  }
  getAllFromCache(t2, e) {
    return this.Ie.getEntries(t2, e);
  }
};
var yr = class {
  constructor(t2) {
    this.persistence = t2, /**
     * Maps a target to the data about that target
     */
    this.ds = new Ni((t3) => xt(t3), $t), /** The last received snapshot version. */
    this.lastRemoteSnapshotVersion = G2.min(), /** The highest numbered target ID encountered. */
    this.highestTargetId = 0, /** The highest sequence number encountered. */
    this.ws = 0, /**
     * A ordered bidirectional mapping between documents and the remote target
     * IDs.
     */
    this._s = new dr(), this.targetCount = 0, this.gs = Ei.Jt();
  }
  forEachTarget(t2, e) {
    return this.ds.forEach((t3, n2) => e(n2)), Ns.resolve();
  }
  getLastRemoteSnapshotVersion(t2) {
    return Ns.resolve(this.lastRemoteSnapshotVersion);
  }
  getHighestSequenceNumber(t2) {
    return Ns.resolve(this.ws);
  }
  allocateTargetId(t2) {
    return this.highestTargetId = this.gs.next(), Ns.resolve(this.highestTargetId);
  }
  setTargetsMetadata(t2, e, n2) {
    return n2 && (this.lastRemoteSnapshotVersion = n2), e > this.ws && (this.ws = e), Ns.resolve();
  }
  te(t2) {
    this.ds.set(t2.target, t2);
    const e = t2.targetId;
    e > this.highestTargetId && (this.gs = new Ei(e), this.highestTargetId = e), t2.sequenceNumber > this.ws && (this.ws = t2.sequenceNumber);
  }
  addTargetData(t2, e) {
    return this.te(e), this.targetCount += 1, Ns.resolve();
  }
  updateTargetData(t2, e) {
    return this.te(e), Ns.resolve();
  }
  removeTargetData(t2, e) {
    return this.ds.delete(e.target), this._s.Zn(e.targetId), this.targetCount -= 1, Ns.resolve();
  }
  removeTargets(t2, e, n2) {
    let s = 0;
    const i = [];
    return this.ds.forEach((r2, o) => {
      o.sequenceNumber <= e && null === n2.get(o.targetId) && (this.ds.delete(r2), i.push(this.removeMatchingKeysForTargetId(t2, o.targetId)), s++);
    }), Ns.waitFor(i).next(() => s);
  }
  getTargetCount(t2) {
    return Ns.resolve(this.targetCount);
  }
  getTargetData(t2, e) {
    const n2 = this.ds.get(e) || null;
    return Ns.resolve(n2);
  }
  addMatchingKeys(t2, e, n2) {
    return this._s.Jn(e, n2), Ns.resolve();
  }
  removeMatchingKeys(t2, e, n2) {
    this._s.Xn(e, n2);
    const s = this.persistence.referenceDelegate, i = [];
    return s && e.forEach((e2) => {
      i.push(s.markPotentiallyOrphaned(t2, e2));
    }), Ns.waitFor(i);
  }
  removeMatchingKeysForTargetId(t2, e) {
    return this._s.Zn(e), Ns.resolve();
  }
  getMatchingKeysForTargetId(t2, e) {
    const n2 = this._s.es(e);
    return Ns.resolve(n2);
  }
  containsKey(t2, e) {
    return Ns.resolve(this._s.containsKey(e));
  }
};
var pr = class {
  /**
   * The constructor accepts a factory for creating a reference delegate. This
   * allows both the delegate and this instance to have strong references to
   * each other without having nullable fields that would then need to be
   * checked or asserted on every access.
   */
  constructor(t2, e) {
    this.ys = {}, this.Ne = new V2(0), this.xe = false, this.xe = true, this.referenceDelegate = t2(this), this.Ue = new yr(this);
    this.qt = new ci(), this.qe = function(t3, e2) {
      return new mr(t3, e2);
    }(this.qt, (t3) => this.referenceDelegate.ps(t3)), this.R = new Gs(e), this.Ke = new fr(this.R);
  }
  start() {
    return Promise.resolve();
  }
  shutdown() {
    return this.xe = false, Promise.resolve();
  }
  get started() {
    return this.xe;
  }
  setDatabaseDeletedListener() {
  }
  setNetworkEnabled() {
  }
  getIndexManager() {
    return this.qt;
  }
  getMutationQueue(t2) {
    let e = this.ys[t2.toKey()];
    return e || (e = new _r(this.qt, this.referenceDelegate), this.ys[t2.toKey()] = e), e;
  }
  getTargetCache() {
    return this.Ue;
  }
  getRemoteDocumentCache() {
    return this.qe;
  }
  getBundleCache() {
    return this.Ke;
  }
  runTransaction(t2, e, n2) {
    k2("MemoryPersistence", "Starting transaction:", t2);
    const s = new Er(this.Ne.next());
    return this.referenceDelegate.Es(), n2(s).next((t3) => this.referenceDelegate.Ts(s).next(() => t3)).toPromise().then((t3) => (s.raiseOnCommittedEvent(), t3));
  }
  Is(t2, e) {
    return Ns.or(Object.values(this.ys).map((n2) => () => n2.containsKey(t2, e)));
  }
};
var Er = class extends Ds {
  constructor(t2) {
    super(), this.currentSequenceNumber = t2;
  }
};
var Tr = class {
  constructor(t2) {
    this.persistence = t2, /** Tracks all documents that are active in Query views. */
    this.As = new dr(), /** The list of documents that are potentially GCed after each transaction. */
    this.Rs = null;
  }
  static Ps(t2) {
    return new Tr(t2);
  }
  get bs() {
    if (this.Rs)
      return this.Rs;
    throw M2();
  }
  addReference(t2, e, n2) {
    return this.As.addReference(n2, e), this.bs.delete(n2.toString()), Ns.resolve();
  }
  removeReference(t2, e, n2) {
    return this.As.removeReference(n2, e), this.bs.add(n2.toString()), Ns.resolve();
  }
  markPotentiallyOrphaned(t2, e) {
    return this.bs.add(e.toString()), Ns.resolve();
  }
  removeTarget(t2, e) {
    this.As.Zn(e.targetId).forEach((t3) => this.bs.add(t3.toString()));
    const n2 = this.persistence.getTargetCache();
    return n2.getMatchingKeysForTargetId(t2, e.targetId).next((t3) => {
      t3.forEach((t4) => this.bs.add(t4.toString()));
    }).next(() => n2.removeTargetData(t2, e));
  }
  Es() {
    this.Rs = /* @__PURE__ */ new Set();
  }
  Ts(t2) {
    const e = this.persistence.getRemoteDocumentCache().newChangeBuffer();
    return Ns.forEach(this.bs, (n2) => {
      const s = dt.fromPath(n2);
      return this.vs(t2, s).next((t3) => {
        t3 || e.removeEntry(s);
      });
    }).next(() => (this.Rs = null, e.apply(t2)));
  }
  updateLimboDocument(t2, e) {
    return this.vs(t2, e).next((t3) => {
      t3 ? this.bs.delete(e.toString()) : this.bs.add(e.toString());
    });
  }
  ps(t2) {
    return 0;
  }
  vs(t2, e) {
    return Ns.or([() => Ns.resolve(this.As.containsKey(e)), () => this.persistence.getTargetCache().containsKey(t2, e), () => this.persistence.Is(t2, e)]);
  }
};
var Ir = class {
  constructor(t2) {
    this.uid = t2;
  }
  isAuthenticated() {
    return null != this.uid;
  }
  /**
   * Returns a key representing this user, suitable for inclusion in a
   * dictionary.
   */
  toKey() {
    return this.isAuthenticated() ? "uid:" + this.uid : "anonymous-user";
  }
  isEqual(t2) {
    return t2.uid === this.uid;
  }
};
Ir.UNAUTHENTICATED = new Ir(null), // TODO(mikelehen): Look into getting a proper uid-equivalent for
// non-FirebaseAuth providers.
Ir.GOOGLE_CREDENTIALS = new Ir("google-credentials-uid"), Ir.FIRST_PARTY = new Ir("first-party-uid");
function Ar(t2, e) {
  return `firestore_clients_${t2}_${e}`;
}
function Rr(t2, e, n2) {
  let s = `firestore_mutations_${t2}_${n2}`;
  return e.isAuthenticated() && (s += `_${e.uid}`), s;
}
function Pr(t2, e) {
  return `firestore_targets_${t2}_${e}`;
}
var br = class {
  constructor(t2, e, n2, s) {
    this.user = t2, this.batchId = e, this.state = n2, this.error = s;
  }
  /**
   * Parses a MutationMetadata from its JSON representation in WebStorage.
   * Logs a warning and returns null if the format of the data is not valid.
   */
  static Vs(t2, e, n2) {
    const s = JSON.parse(n2);
    let i, r2 = "object" == typeof s && -1 !== ["pending", "acknowledged", "rejected"].indexOf(s.state) && (void 0 === s.error || "object" == typeof s.error);
    return r2 && s.error && (r2 = "string" == typeof s.error.message && "string" == typeof s.error.code, r2 && (i = new D2(s.error.code, s.error.message))), r2 ? new br(t2, e, s.state, i) : ($("SharedClientState", `Failed to parse mutation state for ID '${e}': ${n2}`), null);
  }
  Ss() {
    const t2 = {
      state: this.state,
      updateTimeMs: Date.now()
    };
    return this.error && (t2.error = {
      code: this.error.code,
      message: this.error.message
    }), JSON.stringify(t2);
  }
};
var vr = class {
  constructor(t2, e, n2) {
    this.targetId = t2, this.state = e, this.error = n2;
  }
  /**
   * Parses a QueryTargetMetadata from its JSON representation in WebStorage.
   * Logs a warning and returns null if the format of the data is not valid.
   */
  static Vs(t2, e) {
    const n2 = JSON.parse(e);
    let s, i = "object" == typeof n2 && -1 !== ["not-current", "current", "rejected"].indexOf(n2.state) && (void 0 === n2.error || "object" == typeof n2.error);
    return i && n2.error && (i = "string" == typeof n2.error.message && "string" == typeof n2.error.code, i && (s = new D2(n2.error.code, n2.error.message))), i ? new vr(t2, n2.state, s) : ($("SharedClientState", `Failed to parse target state for ID '${t2}': ${e}`), null);
  }
  Ss() {
    const t2 = {
      state: this.state,
      updateTimeMs: Date.now()
    };
    return this.error && (t2.error = {
      code: this.error.code,
      message: this.error.message
    }), JSON.stringify(t2);
  }
};
var Vr = class {
  constructor(t2, e) {
    this.clientId = t2, this.activeTargetIds = e;
  }
  /**
   * Parses a RemoteClientState from the JSON representation in WebStorage.
   * Logs a warning and returns null if the format of the data is not valid.
   */
  static Vs(t2, e) {
    const n2 = JSON.parse(e);
    let s = "object" == typeof n2 && n2.activeTargetIds instanceof Array, i = _n();
    for (let t3 = 0; s && t3 < n2.activeTargetIds.length; ++t3)
      s = ft(n2.activeTargetIds[t3]), i = i.add(n2.activeTargetIds[t3]);
    return s ? new Vr(t2, i) : ($("SharedClientState", `Failed to parse client data for instance '${t2}': ${e}`), null);
  }
};
var Sr = class {
  constructor(t2, e) {
    this.clientId = t2, this.onlineState = e;
  }
  /**
   * Parses a SharedOnlineState from its JSON representation in WebStorage.
   * Logs a warning and returns null if the format of the data is not valid.
   */
  static Vs(t2) {
    const e = JSON.parse(t2);
    return "object" == typeof e && -1 !== ["Unknown", "Online", "Offline"].indexOf(e.onlineState) && "string" == typeof e.clientId ? new Sr(e.clientId, e.onlineState) : ($("SharedClientState", `Failed to parse online state: ${t2}`), null);
  }
};
var Dr = class {
  constructor() {
    this.activeTargetIds = _n();
  }
  Ds(t2) {
    this.activeTargetIds = this.activeTargetIds.add(t2);
  }
  Cs(t2) {
    this.activeTargetIds = this.activeTargetIds.delete(t2);
  }
  /**
   * Converts this entry into a JSON-encoded format we can use for WebStorage.
   * Does not encode `clientId` as it is part of the key in WebStorage.
   */
  Ss() {
    const t2 = {
      activeTargetIds: this.activeTargetIds.toArray(),
      updateTimeMs: Date.now()
    };
    return JSON.stringify(t2);
  }
};
var Cr = class {
  constructor(t2, e, n2, s, i) {
    this.window = t2, this.Se = e, this.persistenceKey = n2, this.Ns = s, this.syncEngine = null, this.onlineStateHandler = null, this.sequenceNumberHandler = null, this.xs = this.ks.bind(this), this.$s = new tn(K2), this.started = false, /**
     * Captures WebStorage events that occur before `start()` is called. These
     * events are replayed once `WebStorageSharedClientState` is started.
     */
    this.Os = [];
    const r2 = n2.replace(/[.*+?^${}()|[\]\\]/g, "\\$&");
    this.storage = this.window.localStorage, this.currentUser = i, this.Fs = Ar(this.persistenceKey, this.Ns), this.Ms = /** Assembles the key for the current sequence number. */
    function(t3) {
      return `firestore_sequence_number_${t3}`;
    }(this.persistenceKey), this.$s = this.$s.insert(this.Ns, new Dr()), this.Ls = new RegExp(`^firestore_clients_${r2}_([^_]*)$`), this.Bs = new RegExp(`^firestore_mutations_${r2}_(\\d+)(?:_(.*))?$`), this.Us = new RegExp(`^firestore_targets_${r2}_(\\d+)$`), this.qs = /** Assembles the key for the online state of the primary tab. */
    function(t3) {
      return `firestore_online_state_${t3}`;
    }(this.persistenceKey), this.Ks = function(t3) {
      return `firestore_bundle_loaded_${t3}`;
    }(this.persistenceKey), // Rather than adding the storage observer during start(), we add the
    // storage observer during initialization. This ensures that we collect
    // events before other components populate their initial state (during their
    // respective start() calls). Otherwise, we might for example miss a
    // mutation that is added after LocalStore's start() processed the existing
    // mutations but before we observe WebStorage events.
    this.window.addEventListener("storage", this.xs);
  }
  /** Returns 'true' if WebStorage is available in the current environment. */
  static gt(t2) {
    return !(!t2 || !t2.localStorage);
  }
  async start() {
    const t2 = await this.syncEngine.fn();
    for (const e2 of t2) {
      if (e2 === this.Ns)
        continue;
      const t3 = this.getItem(Ar(this.persistenceKey, e2));
      if (t3) {
        const n2 = Vr.Vs(e2, t3);
        n2 && (this.$s = this.$s.insert(n2.clientId, n2));
      }
    }
    this.Qs();
    const e = this.storage.getItem(this.qs);
    if (e) {
      const t3 = this.js(e);
      t3 && this.Ws(t3);
    }
    for (const t3 of this.Os)
      this.ks(t3);
    this.Os = [], // Register a window unload hook to remove the client metadata entry from
    // WebStorage even if `shutdown()` was not called.
    this.window.addEventListener("pagehide", () => this.shutdown()), this.started = true;
  }
  writeSequenceNumber(t2) {
    this.setItem(this.Ms, JSON.stringify(t2));
  }
  getAllActiveQueryTargets() {
    return this.Gs(this.$s);
  }
  isActiveQueryTarget(t2) {
    let e = false;
    return this.$s.forEach((n2, s) => {
      s.activeTargetIds.has(t2) && (e = true);
    }), e;
  }
  addPendingMutation(t2) {
    this.zs(t2, "pending");
  }
  updateMutationState(t2, e, n2) {
    this.zs(t2, e, n2), // Once a final mutation result is observed by other clients, they no longer
    // access the mutation's metadata entry. Since WebStorage replays events
    // in order, it is safe to delete the entry right after updating it.
    this.Hs(t2);
  }
  addLocalQueryTarget(t2) {
    let e = "not-current";
    if (this.isActiveQueryTarget(t2)) {
      const n2 = this.storage.getItem(Pr(this.persistenceKey, t2));
      if (n2) {
        const s = vr.Vs(t2, n2);
        s && (e = s.state);
      }
    }
    return this.Js.Ds(t2), this.Qs(), e;
  }
  removeLocalQueryTarget(t2) {
    this.Js.Cs(t2), this.Qs();
  }
  isLocalQueryTarget(t2) {
    return this.Js.activeTargetIds.has(t2);
  }
  clearQueryState(t2) {
    this.removeItem(Pr(this.persistenceKey, t2));
  }
  updateQueryState(t2, e, n2) {
    this.Ys(t2, e, n2);
  }
  handleUserChange(t2, e, n2) {
    e.forEach((t3) => {
      this.Hs(t3);
    }), this.currentUser = t2, n2.forEach((t3) => {
      this.addPendingMutation(t3);
    });
  }
  setOnlineState(t2) {
    this.Xs(t2);
  }
  notifyBundleLoaded() {
    this.Zs();
  }
  shutdown() {
    this.started && (this.window.removeEventListener("storage", this.xs), this.removeItem(this.Fs), this.started = false);
  }
  getItem(t2) {
    const e = this.storage.getItem(t2);
    return k2("SharedClientState", "READ", t2, e), e;
  }
  setItem(t2, e) {
    k2("SharedClientState", "SET", t2, e), this.storage.setItem(t2, e);
  }
  removeItem(t2) {
    k2("SharedClientState", "REMOVE", t2), this.storage.removeItem(t2);
  }
  ks(t2) {
    const e = t2;
    if (e.storageArea === this.storage) {
      if (k2("SharedClientState", "EVENT", e.key, e.newValue), e.key === this.Fs)
        return void $("Received WebStorage notification for local change. Another client might have garbage-collected our state");
      this.Se.enqueueRetryable(async () => {
        if (this.started) {
          if (null !== e.key) {
            if (this.Ls.test(e.key)) {
              if (null == e.newValue) {
                const t3 = this.ti(e.key);
                return this.ei(t3, null);
              }
              {
                const t3 = this.ni(e.key, e.newValue);
                if (t3)
                  return this.ei(t3.clientId, t3);
              }
            } else if (this.Bs.test(e.key)) {
              if (null !== e.newValue) {
                const t3 = this.si(e.key, e.newValue);
                if (t3)
                  return this.ii(t3);
              }
            } else if (this.Us.test(e.key)) {
              if (null !== e.newValue) {
                const t3 = this.ri(e.key, e.newValue);
                if (t3)
                  return this.oi(t3);
              }
            } else if (e.key === this.qs) {
              if (null !== e.newValue) {
                const t3 = this.js(e.newValue);
                if (t3)
                  return this.Ws(t3);
              }
            } else if (e.key === this.Ms) {
              const t3 = function(t4) {
                let e2 = V2.o;
                if (null != t4)
                  try {
                    const n2 = JSON.parse(t4);
                    L2("number" == typeof n2), e2 = n2;
                  } catch (t5) {
                    $("SharedClientState", "Failed to read sequence number from WebStorage", t5);
                  }
                return e2;
              }(e.newValue);
              t3 !== V2.o && this.sequenceNumberHandler(t3);
            } else if (e.key === this.Ks)
              return this.syncEngine.ci();
          }
        } else
          this.Os.push(e);
      });
    }
  }
  get Js() {
    return this.$s.get(this.Ns);
  }
  Qs() {
    this.setItem(this.Fs, this.Js.Ss());
  }
  zs(t2, e, n2) {
    const s = new br(this.currentUser, t2, e, n2), i = Rr(this.persistenceKey, this.currentUser, t2);
    this.setItem(i, s.Ss());
  }
  Hs(t2) {
    const e = Rr(this.persistenceKey, this.currentUser, t2);
    this.removeItem(e);
  }
  Xs(t2) {
    const e = {
      clientId: this.Ns,
      onlineState: t2
    };
    this.storage.setItem(this.qs, JSON.stringify(e));
  }
  Ys(t2, e, n2) {
    const s = Pr(this.persistenceKey, t2), i = new vr(t2, e, n2);
    this.setItem(s, i.Ss());
  }
  Zs() {
    this.setItem(this.Ks, "value-not-used");
  }
  /**
   * Parses a client state key in WebStorage. Returns null if the key does not
   * match the expected key format.
   */
  ti(t2) {
    const e = this.Ls.exec(t2);
    return e ? e[1] : null;
  }
  /**
   * Parses a client state in WebStorage. Returns 'null' if the value could not
   * be parsed.
   */
  ni(t2, e) {
    const n2 = this.ti(t2);
    return Vr.Vs(n2, e);
  }
  /**
   * Parses a mutation batch state in WebStorage. Returns 'null' if the value
   * could not be parsed.
   */
  si(t2, e) {
    const n2 = this.Bs.exec(t2), s = Number(n2[1]), i = void 0 !== n2[2] ? n2[2] : null;
    return br.Vs(new Ir(i), s, e);
  }
  /**
   * Parses a query target state from WebStorage. Returns 'null' if the value
   * could not be parsed.
   */
  ri(t2, e) {
    const n2 = this.Us.exec(t2), s = Number(n2[1]);
    return vr.Vs(s, e);
  }
  /**
   * Parses an online state from WebStorage. Returns 'null' if the value
   * could not be parsed.
   */
  js(t2) {
    return Sr.Vs(t2);
  }
  async ii(t2) {
    if (t2.user.uid === this.currentUser.uid)
      return this.syncEngine.ui(t2.batchId, t2.state, t2.error);
    k2("SharedClientState", `Ignoring mutation for non-active user ${t2.user.uid}`);
  }
  oi(t2) {
    return this.syncEngine.ai(t2.targetId, t2.state, t2.error);
  }
  ei(t2, e) {
    const n2 = e ? this.$s.insert(t2, e) : this.$s.remove(t2), s = this.Gs(this.$s), i = this.Gs(n2), r2 = [], o = [];
    return i.forEach((t3) => {
      s.has(t3) || r2.push(t3);
    }), s.forEach((t3) => {
      i.has(t3) || o.push(t3);
    }), this.syncEngine.hi(r2, o).then(() => {
      this.$s = n2;
    });
  }
  Ws(t2) {
    this.$s.get(t2.clientId) && this.onlineStateHandler(t2.onlineState);
  }
  Gs(t2) {
    let e = _n();
    return t2.forEach((t3, n2) => {
      e = e.unionWith(n2.activeTargetIds);
    }), e;
  }
};
var Nr = class {
  constructor() {
    this.li = new Dr(), this.fi = {}, this.onlineStateHandler = null, this.sequenceNumberHandler = null;
  }
  addPendingMutation(t2) {
  }
  updateMutationState(t2, e, n2) {
  }
  addLocalQueryTarget(t2) {
    return this.li.Ds(t2), this.fi[t2] || "not-current";
  }
  updateQueryState(t2, e, n2) {
    this.fi[t2] = e;
  }
  removeLocalQueryTarget(t2) {
    this.li.Cs(t2);
  }
  isLocalQueryTarget(t2) {
    return this.li.activeTargetIds.has(t2);
  }
  clearQueryState(t2) {
    delete this.fi[t2];
  }
  getAllActiveQueryTargets() {
    return this.li.activeTargetIds;
  }
  isActiveQueryTarget(t2) {
    return this.li.activeTargetIds.has(t2);
  }
  start() {
    return this.li = new Dr(), Promise.resolve();
  }
  handleUserChange(t2, e, n2) {
  }
  setOnlineState(t2) {
  }
  shutdown() {
  }
  writeSequenceNumber(t2) {
  }
  notifyBundleLoaded() {
  }
};
var xr = class {
  di(t2) {
  }
  shutdown() {
  }
};
var kr = class {
  constructor() {
    this.wi = () => this._i(), this.mi = () => this.gi(), this.yi = [], this.pi();
  }
  di(t2) {
    this.yi.push(t2);
  }
  shutdown() {
    window.removeEventListener("online", this.wi), window.removeEventListener("offline", this.mi);
  }
  pi() {
    window.addEventListener("online", this.wi), window.addEventListener("offline", this.mi);
  }
  _i() {
    k2("ConnectivityMonitor", "Network connectivity changed: AVAILABLE");
    for (const t2 of this.yi)
      t2(
        0
        /* AVAILABLE */
      );
  }
  gi() {
    k2("ConnectivityMonitor", "Network connectivity changed: UNAVAILABLE");
    for (const t2 of this.yi)
      t2(
        1
        /* UNAVAILABLE */
      );
  }
  // TODO(chenbrian): Consider passing in window either into this component or
  // here for testing via FakeWindow.
  /** Checks that all used attributes of window are available. */
  static gt() {
    return "undefined" != typeof window && void 0 !== window.addEventListener && void 0 !== window.removeEventListener;
  }
};
var $r = {
  BatchGetDocuments: "batchGet",
  Commit: "commit",
  RunQuery: "runQuery"
};
var Or = class {
  constructor(t2) {
    this.Ei = t2.Ei, this.Ti = t2.Ti;
  }
  Ii(t2) {
    this.Ai = t2;
  }
  Ri(t2) {
    this.Pi = t2;
  }
  onMessage(t2) {
    this.bi = t2;
  }
  close() {
    this.Ti();
  }
  send(t2) {
    this.Ei(t2);
  }
  vi() {
    this.Ai();
  }
  Vi(t2) {
    this.Pi(t2);
  }
  Si(t2) {
    this.bi(t2);
  }
};
var Fr = class extends /**
 * Base class for all Rest-based connections to the backend (WebChannel and
 * HTTP).
 */
class {
  constructor(t2) {
    this.databaseInfo = t2, this.databaseId = t2.databaseId;
    const e = t2.ssl ? "https" : "http";
    this.Di = e + "://" + t2.host, this.Ci = "projects/" + this.databaseId.projectId + "/databases/" + this.databaseId.database + "/documents";
  }
  Ni(t2, e, n2, s) {
    const i = this.xi(t2, e);
    k2("RestConnection", "Sending: ", i, n2);
    const r2 = {};
    return this.ki(r2, s), this.$i(t2, i, r2, n2).then((t3) => (k2("RestConnection", "Received: ", t3), t3), (e2) => {
      throw O2("RestConnection", `${t2} failed with error: `, e2, "url: ", i, "request:", n2), e2;
    });
  }
  Oi(t2, e, n2, s) {
    return this.Ni(t2, e, n2, s);
  }
  /**
   * Modifies the headers for a request, adding any authorization token if
   * present and any additional headers for the request.
   */
  ki(t2, e) {
    if (t2["X-Goog-Api-Client"] = "gl-js/ fire/" + v, // Content-Type: text/plain will avoid preflight requests which might
    // mess with CORS and redirects by proxies. If we add custom headers
    // we will need to change this code to potentially use the $httpOverwrite
    // parameter supported by ESF to avoid triggering preflight requests.
    t2["Content-Type"] = "text/plain", this.databaseInfo.appId && (t2["X-Firebase-GMPID"] = this.databaseInfo.appId), e)
      for (const n2 in e.authHeaders)
        e.authHeaders.hasOwnProperty(n2) && (t2[n2] = e.authHeaders[n2]);
  }
  xi(t2, e) {
    const n2 = $r[t2];
    return `${this.Di}/v1/${e}:${n2}`;
  }
} {
  constructor(t2) {
    super(t2), this.forceLongPolling = t2.forceLongPolling, this.autoDetectLongPolling = t2.autoDetectLongPolling, this.useFetchStreams = t2.useFetchStreams;
  }
  $i(t2, e, n2, s) {
    return new Promise((i, r2) => {
      const o = new XhrIo();
      o.listenOnce(EventType.COMPLETE, () => {
        try {
          switch (o.getLastErrorCode()) {
            case ErrorCode.NO_ERROR:
              const e2 = o.getResponseJson();
              k2("Connection", "XHR received:", JSON.stringify(e2)), i(e2);
              break;
            case ErrorCode.TIMEOUT:
              k2("Connection", 'RPC "' + t2 + '" timed out'), r2(new D2(S2.DEADLINE_EXCEEDED, "Request time out"));
              break;
            case ErrorCode.HTTP_ERROR:
              const n3 = o.getStatus();
              if (k2("Connection", 'RPC "' + t2 + '" failed with status:', n3, "response text:", o.getResponseText()), n3 > 0) {
                const t3 = o.getResponseJson().error;
                if (t3 && t3.status && t3.message) {
                  const e3 = function(t4) {
                    const e4 = t4.toLowerCase().replace(/_/g, "-");
                    return Object.values(S2).indexOf(e4) >= 0 ? e4 : S2.UNKNOWN;
                  }(t3.status);
                  r2(new D2(e3, t3.message));
                } else
                  r2(new D2(S2.UNKNOWN, "Server responded with status " + o.getStatus()));
              } else
                r2(new D2(S2.UNAVAILABLE, "Connection failed."));
              break;
            default:
              M2();
          }
        } finally {
          k2("Connection", 'RPC "' + t2 + '" completed.');
        }
      });
      const c = JSON.stringify(s);
      o.send(e, "POST", c, n2, 15);
    });
  }
  Fi(t2, e) {
    const n2 = [this.Di, "/", "google.firestore.v1.Firestore", "/", t2, "/channel"], s = createWebChannelTransport(), i = getStatEventTarget(), r2 = {
      // Required for backend stickiness, routing behavior is based on this
      // parameter.
      httpSessionIdParam: "gsessionid",
      initMessageHeaders: {},
      messageUrlParams: {
        // This param is used to improve routing and project isolation by the
        // backend and must be included in every request.
        database: `projects/${this.databaseId.projectId}/databases/${this.databaseId.database}`
      },
      sendRawJson: true,
      supportsCrossDomainXhr: true,
      internalChannelParams: {
        // Override the default timeout (randomized between 10-20 seconds) since
        // a large write batch on a slow internet connection may take a long
        // time to send to the backend. Rather than have WebChannel impose a
        // tight timeout which could lead to infinite timeouts and retries, we
        // set it very large (5-10 minutes) and rely on the browser's builtin
        // timeouts to kick in if the request isn't working.
        forwardChannelRequestTimeoutMs: 6e5
      },
      forceLongPolling: this.forceLongPolling,
      detectBufferingProxy: this.autoDetectLongPolling
    };
    this.useFetchStreams && (r2.xmlHttpFactory = new FetchXmlHttpFactory({})), this.ki(r2.initMessageHeaders, e), // Sending the custom headers we just added to request.initMessageHeaders
    // (Authorization, etc.) will trigger the browser to make a CORS preflight
    // request because the XHR will no longer meet the criteria for a "simple"
    // CORS request:
    // https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS#Simple_requests
    // Therefore to avoid the CORS preflight request (an extra network
    // roundtrip), we use the httpHeadersOverwriteParam option to specify that
    // the headers should instead be encoded into a special "$httpHeaders" query
    // parameter, which is recognized by the webchannel backend. This is
    // formally defined here:
    // https://github.com/google/closure-library/blob/b0e1815b13fb92a46d7c9b3c30de5d6a396a3245/closure/goog/net/rpc/httpcors.js#L32
    // TODO(b/145624756): There is a backend bug where $httpHeaders isn't respected if the request
    // doesn't have an Origin header. So we have to exclude a few browser environments that are
    // known to (sometimes) not include an Origin. See
    // https://github.com/firebase/firebase-js-sdk/issues/1491.
    isMobileCordova() || isReactNative() || isElectron() || isIE() || isUWP() || isBrowserExtension() || (r2.httpHeadersOverwriteParam = "$httpHeaders");
    const o = n2.join("");
    k2("Connection", "Creating WebChannel: " + o, r2);
    const c = s.createWebChannel(o, r2);
    let u2 = false, a = false;
    const m = new Or({
      Ei: (t3) => {
        a ? k2("Connection", "Not sending because WebChannel is closed:", t3) : (u2 || (k2("Connection", "Opening WebChannel transport."), c.open(), u2 = true), k2("Connection", "WebChannel sending:", t3), c.send(t3));
      },
      Ti: () => c.close()
    }), g2 = (t3, e2, n3) => {
      t3.listen(e2, (t4) => {
        try {
          n3(t4);
        } catch (t5) {
          setTimeout(() => {
            throw t5;
          }, 0);
        }
      });
    };
    return g2(c, WebChannel.EventType.OPEN, () => {
      a || k2("Connection", "WebChannel transport opened.");
    }), g2(c, WebChannel.EventType.CLOSE, () => {
      a || (a = true, k2("Connection", "WebChannel transport closed"), m.Vi());
    }), g2(c, WebChannel.EventType.ERROR, (t3) => {
      a || (a = true, O2("Connection", "WebChannel transport errored:", t3), m.Vi(new D2(S2.UNAVAILABLE, "The operation could not be completed")));
    }), g2(c, WebChannel.EventType.MESSAGE, (t3) => {
      var e2;
      if (!a) {
        const n3 = t3.data[0];
        L2(!!n3);
        const s2 = n3, i2 = s2.error || (null === (e2 = s2[0]) || void 0 === e2 ? void 0 : e2.error);
        if (i2) {
          k2("Connection", "WebChannel received error:", i2);
          const t4 = i2.status;
          let e3 = (
            /**
            * Maps an error Code from a GRPC status identifier like 'NOT_FOUND'.
            *
            * @returns The Code equivalent to the given status string or undefined if
            *     there is no match.
            */
            function(t5) {
              const e4 = Je[t5];
              if (void 0 !== e4)
                return Ze(e4);
            }(t4)
          ), n4 = i2.message;
          void 0 === e3 && (e3 = S2.INTERNAL, n4 = "Unknown error status: " + t4 + " with message " + i2.message), // Mark closed so no further events are propagated
          a = true, m.Vi(new D2(e3, n4)), c.close();
        } else
          k2("Connection", "WebChannel received:", n3), m.Si(n3);
      }
    }), g2(i, Event.STAT_EVENT, (t3) => {
      t3.stat === Stat.PROXY ? k2("Connection", "Detected buffering proxy") : t3.stat === Stat.NOPROXY && k2("Connection", "Detected no buffering proxy");
    }), setTimeout(() => {
      m.vi();
    }, 0), m;
  }
};
function Mr() {
  return "undefined" != typeof window ? window : null;
}
function Lr() {
  return "undefined" != typeof document ? document : null;
}
function Br(t2) {
  return new vn(
    t2,
    /* useProto3Json= */
    true
  );
}
var Ur = class {
  constructor(t2, e, n2 = 1e3, s = 1.5, i = 6e4) {
    this.Se = t2, this.timerId = e, this.Mi = n2, this.Li = s, this.Bi = i, this.Ui = 0, this.qi = null, /** The last backoff attempt, as epoch milliseconds. */
    this.Ki = Date.now(), this.reset();
  }
  /**
   * Resets the backoff delay.
   *
   * The very next backoffAndWait() will have no delay. If it is called again
   * (i.e. due to an error), initialDelayMs (plus jitter) will be used, and
   * subsequent ones will increase according to the backoffFactor.
   */
  reset() {
    this.Ui = 0;
  }
  /**
   * Resets the backoff delay to the maximum delay (e.g. for use after a
   * RESOURCE_EXHAUSTED error).
   */
  Qi() {
    this.Ui = this.Bi;
  }
  /**
   * Returns a promise that resolves after currentDelayMs, and increases the
   * delay for any subsequent attempts. If there was a pending backoff operation
   * already, it will be canceled.
   */
  ji(t2) {
    this.cancel();
    const e = Math.floor(this.Ui + this.Wi()), n2 = Math.max(0, Date.now() - this.Ki), s = Math.max(0, e - n2);
    s > 0 && k2("ExponentialBackoff", `Backing off for ${s} ms (base delay: ${this.Ui} ms, delay with jitter: ${e} ms, last attempt: ${n2} ms ago)`), this.qi = this.Se.enqueueAfterDelay(this.timerId, s, () => (this.Ki = Date.now(), t2())), // Apply backoff factor to determine next delay and ensure it is within
    // bounds.
    this.Ui *= this.Li, this.Ui < this.Mi && (this.Ui = this.Mi), this.Ui > this.Bi && (this.Ui = this.Bi);
  }
  Gi() {
    null !== this.qi && (this.qi.skipDelay(), this.qi = null);
  }
  cancel() {
    null !== this.qi && (this.qi.cancel(), this.qi = null);
  }
  /** Returns a random value in the range [-currentBaseMs/2, currentBaseMs/2] */
  Wi() {
    return (Math.random() - 0.5) * this.Ui;
  }
};
var qr = class {
  constructor(t2, e, n2, s, i, r2) {
    this.Se = t2, this.zi = n2, this.Hi = s, this.Ji = i, this.listener = r2, this.state = 0, /**
     * A close count that's incremented every time the stream is closed; used by
     * getCloseGuardedDispatcher() to invalidate callbacks that happen after
     * close.
     */
    this.Yi = 0, this.Xi = null, this.stream = null, this.Zi = new Ur(t2, e);
  }
  /**
   * Returns true if start() has been called and no error has occurred. True
   * indicates the stream is open or in the process of opening (which
   * encompasses respecting backoff, getting auth tokens, and starting the
   * actual RPC). Use isOpen() to determine if the stream is open and ready for
   * outbound requests.
   */
  tr() {
    return 1 === this.state || 2 === this.state || 4 === this.state;
  }
  /**
   * Returns true if the underlying RPC is open (the onOpen() listener has been
   * called) and the stream is ready for outbound requests.
   */
  er() {
    return 2 === this.state;
  }
  /**
   * Starts the RPC. Only allowed if isStarted() returns false. The stream is
   * not immediately ready for use: onOpen() will be invoked when the RPC is
   * ready for outbound requests, at which point isOpen() will return true.
   *
   * When start returns, isStarted() will return true.
   */
  start() {
    3 !== this.state ? this.auth() : this.nr();
  }
  /**
   * Stops the RPC. This call is idempotent and allowed regardless of the
   * current isStarted() state.
   *
   * When stop returns, isStarted() and isOpen() will both return false.
   */
  async stop() {
    this.tr() && await this.close(
      0
      /* Initial */
    );
  }
  /**
   * After an error the stream will usually back off on the next attempt to
   * start it. If the error warrants an immediate restart of the stream, the
   * sender can use this to indicate that the receiver should not back off.
   *
   * Each error will call the onClose() listener. That function can decide to
   * inhibit backoff if required.
   */
  sr() {
    this.state = 0, this.Zi.reset();
  }
  /**
   * Marks this stream as idle. If no further actions are performed on the
   * stream for one minute, the stream will automatically close itself and
   * notify the stream's onClose() handler with Status.OK. The stream will then
   * be in a !isStarted() state, requiring the caller to start the stream again
   * before further use.
   *
   * Only streams that are in state 'Open' can be marked idle, as all other
   * states imply pending network operations.
   */
  ir() {
    this.er() && null === this.Xi && (this.Xi = this.Se.enqueueAfterDelay(this.zi, 6e4, () => this.rr()));
  }
  /** Sends a message to the underlying stream. */
  cr(t2) {
    this.ur(), this.stream.send(t2);
  }
  /** Called by the idle timer when the stream should close due to inactivity. */
  async rr() {
    if (this.er())
      return this.close(
        0
        /* Initial */
      );
  }
  /** Marks the stream as active again. */
  ur() {
    this.Xi && (this.Xi.cancel(), this.Xi = null);
  }
  /**
   * Closes the stream and cleans up as necessary:
   *
   * * closes the underlying GRPC stream;
   * * calls the onClose handler with the given 'error';
   * * sets internal stream state to 'finalState';
   * * adjusts the backoff timer based on the error
   *
   * A new stream can be opened by calling start().
   *
   * @param finalState - the intended state of the stream after closing.
   * @param error - the error the connection was closed with.
   */
  async close(t2, e) {
    this.ur(), this.Zi.cancel(), // Invalidates any stream-related callbacks (e.g. from auth or the
    // underlying stream), guaranteeing they won't execute.
    this.Yi++, 3 !== t2 ? (
      // If this is an intentional close ensure we don't delay our next connection attempt.
      this.Zi.reset()
    ) : e && e.code === S2.RESOURCE_EXHAUSTED ? (
      // Log the error. (Probably either 'quota exceeded' or 'max queue length reached'.)
      ($(e.toString()), $("Using maximum backoff delay to prevent overloading the backend."), this.Zi.Qi())
    ) : e && e.code === S2.UNAUTHENTICATED && // "unauthenticated" error means the token was rejected. Try force refreshing it in case it
    // just expired.
    this.Ji.invalidateToken(), // Clean up the underlying stream because we are no longer interested in events.
    null !== this.stream && (this.ar(), this.stream.close(), this.stream = null), // This state must be assigned before calling onClose() to allow the callback to
    // inhibit backoff or otherwise manipulate the state in its non-started state.
    this.state = t2, // Notify the listener that the stream closed.
    await this.listener.Ri(e);
  }
  /**
   * Can be overridden to perform additional cleanup before the stream is closed.
   * Calling super.tearDown() is not required.
   */
  ar() {
  }
  auth() {
    this.state = 1;
    const t2 = this.hr(this.Yi), e = this.Yi;
    this.Ji.getToken().then((t3) => {
      this.Yi === e && // Normally we'd have to schedule the callback on the AsyncQueue.
      // However, the following calls are safe to be called outside the
      // AsyncQueue since they don't chain asynchronous calls
      this.lr(t3);
    }, (e2) => {
      t2(() => {
        const t3 = new D2(S2.UNKNOWN, "Fetching auth token failed: " + e2.message);
        return this.dr(t3);
      });
    });
  }
  lr(t2) {
    const e = this.hr(this.Yi);
    this.stream = this.wr(t2), this.stream.Ii(() => {
      e(() => (this.state = 2, this.listener.Ii()));
    }), this.stream.Ri((t3) => {
      e(() => this.dr(t3));
    }), this.stream.onMessage((t3) => {
      e(() => this.onMessage(t3));
    });
  }
  nr() {
    this.state = 4, this.Zi.ji(async () => {
      this.state = 0, this.start();
    });
  }
  // Visible for tests
  dr(t2) {
    return k2("PersistentStream", `close with error: ${t2}`), this.stream = null, this.close(3, t2);
  }
  /**
   * Returns a "dispatcher" function that dispatches operations onto the
   * AsyncQueue but only runs them if closeCount remains unchanged. This allows
   * us to turn auth / stream callbacks into no-ops if the stream is closed /
   * re-opened, etc.
   */
  hr(t2) {
    return (e) => {
      this.Se.enqueueAndForget(() => this.Yi === t2 ? e() : (k2("PersistentStream", "stream callback skipped by getCloseGuardedDispatcher."), Promise.resolve()));
    };
  }
};
var Kr = class extends qr {
  constructor(t2, e, n2, s, i) {
    super(t2, "listen_stream_connection_backoff", "listen_stream_idle", e, n2, i), this.R = s;
  }
  wr(t2) {
    return this.Hi.Fi("Listen", t2);
  }
  onMessage(t2) {
    this.Zi.reset();
    const e = Kn(this.R, t2), n2 = function(t3) {
      if (!("targetChange" in t3))
        return G2.min();
      const e2 = t3.targetChange;
      return e2.targetIds && e2.targetIds.length ? G2.min() : e2.readTime ? Cn(e2.readTime) : G2.min();
    }(t2);
    return this.listener._r(e, n2);
  }
  /**
   * Registers interest in the results of the given target. If the target
   * includes a resumeToken it will be included in the request. Results that
   * affect the target will be streamed back as WatchChange messages that
   * reference the targetId.
   */
  mr(t2) {
    const e = {};
    e.database = Mn(this.R), e.addTarget = function(t3, e2) {
      let n3;
      const s = e2.target;
      return n3 = Ot(s) ? {
        documents: Gn(t3, s)
      } : {
        query: zn(t3, s)
      }, n3.targetId = e2.targetId, e2.resumeToken.approximateByteSize() > 0 ? n3.resumeToken = Sn(t3, e2.resumeToken) : e2.snapshotVersion.compareTo(G2.min()) > 0 && // TODO(wuandy): Consider removing above check because it is most likely true.
      // Right now, many tests depend on this behaviour though (leaving min() out
      // of serialization).
      (n3.readTime = Vn(t3, e2.snapshotVersion.toTimestamp())), n3;
    }(this.R, t2);
    const n2 = Jn(this.R, t2);
    n2 && (e.labels = n2), this.cr(e);
  }
  /**
   * Unregisters interest in the results of the target associated with the
   * given targetId.
   */
  gr(t2) {
    const e = {};
    e.database = Mn(this.R), e.removeTarget = t2, this.cr(e);
  }
};
var Qr = class extends qr {
  constructor(t2, e, n2, s, i) {
    super(t2, "write_stream_connection_backoff", "write_stream_idle", e, n2, i), this.R = s, this.yr = false;
  }
  /**
   * Tracks whether or not a handshake has been successfully exchanged and
   * the stream is ready to accept mutations.
   */
  get pr() {
    return this.yr;
  }
  // Override of PersistentStream.start
  start() {
    this.yr = false, this.lastStreamToken = void 0, super.start();
  }
  ar() {
    this.yr && this.Er([]);
  }
  wr(t2) {
    return this.Hi.Fi("Write", t2);
  }
  onMessage(t2) {
    if (
      // Always capture the last stream token.
      L2(!!t2.streamToken), this.lastStreamToken = t2.streamToken, this.yr
    ) {
      this.Zi.reset();
      const e = Wn(t2.writeResults, t2.commitTime), n2 = Cn(t2.commitTime);
      return this.listener.Tr(n2, e);
    }
    return L2(!t2.writeResults || 0 === t2.writeResults.length), this.yr = true, this.listener.Ir();
  }
  /**
   * Sends an initial streamToken to the server, performing the handshake
   * required to make the StreamingWrite RPC work. Subsequent
   * calls should wait until onHandshakeComplete was called.
   */
  Ar() {
    const t2 = {};
    t2.database = Mn(this.R), this.cr(t2);
  }
  /** Sends a group of mutations to the Firestore backend to apply. */
  Er(t2) {
    const e = {
      streamToken: this.lastStreamToken,
      writes: t2.map((t3) => Qn(this.R, t3))
    };
    this.cr(e);
  }
};
var jr = class extends class {
} {
  constructor(t2, e, n2) {
    super(), this.credentials = t2, this.Hi = e, this.R = n2, this.Rr = false;
  }
  Pr() {
    if (this.Rr)
      throw new D2(S2.FAILED_PRECONDITION, "The client has already been terminated.");
  }
  /** Gets an auth token and invokes the provided RPC. */
  Ni(t2, e, n2) {
    return this.Pr(), this.credentials.getToken().then((s) => this.Hi.Ni(t2, e, n2, s)).catch((t3) => {
      throw "FirebaseError" === t3.name ? (t3.code === S2.UNAUTHENTICATED && this.credentials.invalidateToken(), t3) : new D2(S2.UNKNOWN, t3.toString());
    });
  }
  /** Gets an auth token and invokes the provided RPC with streamed results. */
  Oi(t2, e, n2) {
    return this.Pr(), this.credentials.getToken().then((s) => this.Hi.Oi(t2, e, n2, s)).catch((t3) => {
      throw "FirebaseError" === t3.name ? (t3.code === S2.UNAUTHENTICATED && this.credentials.invalidateToken(), t3) : new D2(S2.UNKNOWN, t3.toString());
    });
  }
  terminate() {
    this.Rr = true;
  }
};
var Wr = class {
  constructor(t2, e) {
    this.asyncQueue = t2, this.onlineStateHandler = e, /** The current OnlineState. */
    this.state = "Unknown", /**
     * A count of consecutive failures to open the stream. If it reaches the
     * maximum defined by MAX_WATCH_STREAM_FAILURES, we'll set the OnlineState to
     * Offline.
     */
    this.br = 0, /**
     * A timer that elapses after ONLINE_STATE_TIMEOUT_MS, at which point we
     * transition from OnlineState.Unknown to OnlineState.Offline without waiting
     * for the stream to actually fail (MAX_WATCH_STREAM_FAILURES times).
     */
    this.vr = null, /**
     * Whether the client should log a warning message if it fails to connect to
     * the backend (initially true, cleared after a successful stream, or if we've
     * logged the message already).
     */
    this.Vr = true;
  }
  /**
   * Called by RemoteStore when a watch stream is started (including on each
   * backoff attempt).
   *
   * If this is the first attempt, it sets the OnlineState to Unknown and starts
   * the onlineStateTimer.
   */
  Sr() {
    0 === this.br && (this.Dr(
      "Unknown"
      /* Unknown */
    ), this.vr = this.asyncQueue.enqueueAfterDelay("online_state_timeout", 1e4, () => (this.vr = null, this.Cr("Backend didn't respond within 10 seconds."), this.Dr(
      "Offline"
      /* Offline */
    ), Promise.resolve())));
  }
  /**
   * Updates our OnlineState as appropriate after the watch stream reports a
   * failure. The first failure moves us to the 'Unknown' state. We then may
   * allow multiple failures (based on MAX_WATCH_STREAM_FAILURES) before we
   * actually transition to the 'Offline' state.
   */
  Nr(t2) {
    "Online" === this.state ? this.Dr(
      "Unknown"
      /* Unknown */
    ) : (this.br++, this.br >= 1 && (this.kr(), this.Cr(`Connection failed 1 times. Most recent error: ${t2.toString()}`), this.Dr(
      "Offline"
      /* Offline */
    )));
  }
  /**
   * Explicitly sets the OnlineState to the specified state.
   *
   * Note that this resets our timers / failure counters, etc. used by our
   * Offline heuristics, so must not be used in place of
   * handleWatchStreamStart() and handleWatchStreamFailure().
   */
  set(t2) {
    this.kr(), this.br = 0, "Online" === t2 && // We've connected to watch at least once. Don't warn the developer
    // about being offline going forward.
    (this.Vr = false), this.Dr(t2);
  }
  Dr(t2) {
    t2 !== this.state && (this.state = t2, this.onlineStateHandler(t2));
  }
  Cr(t2) {
    const e = `Could not reach Cloud Firestore backend. ${t2}
This typically indicates that your device does not have a healthy Internet connection at the moment. The client will operate in offline mode until it is able to successfully connect to the backend.`;
    this.Vr ? ($(e), this.Vr = false) : k2("OnlineStateTracker", e);
  }
  kr() {
    null !== this.vr && (this.vr.cancel(), this.vr = null);
  }
};
var Gr = class {
  constructor(t2, e, n2, s, i) {
    this.localStore = t2, this.datastore = e, this.asyncQueue = n2, this.remoteSyncer = {}, /**
     * A list of up to MAX_PENDING_WRITES writes that we have fetched from the
     * LocalStore via fillWritePipeline() and have or will send to the write
     * stream.
     *
     * Whenever writePipeline.length > 0 the RemoteStore will attempt to start or
     * restart the write stream. When the stream is established the writes in the
     * pipeline will be sent in order.
     *
     * Writes remain in writePipeline until they are acknowledged by the backend
     * and thus will automatically be re-sent if the stream is interrupted /
     * restarted before they're acknowledged.
     *
     * Write responses from the backend are linked to their originating request
     * purely based on order, and so we can just shift() writes from the front of
     * the writePipeline as we receive responses.
     */
    this.$r = [], /**
     * A mapping of watched targets that the client cares about tracking and the
     * user has explicitly called a 'listen' for this target.
     *
     * These targets may or may not have been sent to or acknowledged by the
     * server. On re-establishing the listen stream, these targets should be sent
     * to the server. The targets removed with unlistens are removed eagerly
     * without waiting for confirmation from the listen stream.
     */
    this.Or = /* @__PURE__ */ new Map(), /**
     * A set of reasons for why the RemoteStore may be offline. If empty, the
     * RemoteStore may start its network connections.
     */
    this.Fr = /* @__PURE__ */ new Set(), /**
     * Event handlers that get called when the network is disabled or enabled.
     *
     * PORTING NOTE: These functions are used on the Web client to create the
     * underlying streams (to support tree-shakeable streams). On Android and iOS,
     * the streams are created during construction of RemoteStore.
     */
    this.Mr = [], this.Lr = i, this.Lr.di((t3) => {
      n2.enqueueAndForget(async () => {
        no(this) && (k2("RemoteStore", "Restarting streams for network reachability change."), await async function(t4) {
          const e2 = B(t4);
          e2.Fr.add(
            4
            /* ConnectivityChange */
          ), await Hr(e2), e2.Br.set(
            "Unknown"
            /* Unknown */
          ), e2.Fr.delete(
            4
            /* ConnectivityChange */
          ), await zr(e2);
        }(this));
      });
    }), this.Br = new Wr(n2, s);
  }
};
async function zr(t2) {
  if (no(t2))
    for (const e of t2.Mr)
      await e(
        /* enabled= */
        true
      );
}
async function Hr(t2) {
  for (const e of t2.Mr)
    await e(
      /* enabled= */
      false
    );
}
function Jr(t2, e) {
  const n2 = B(t2);
  n2.Or.has(e.targetId) || // Mark this as something the client is currently listening for.
  (n2.Or.set(e.targetId, e), eo(n2) ? (
    // The listen will be sent in onWatchStreamOpen
    to(n2)
  ) : Eo(n2).er() && Xr(n2, e));
}
function Yr(t2, e) {
  const n2 = B(t2), s = Eo(n2);
  n2.Or.delete(e), s.er() && Zr(n2, e), 0 === n2.Or.size && (s.er() ? s.ir() : no(n2) && // Revert to OnlineState.Unknown if the watch stream is not open and we
  // have no listeners, since without any listens to send we cannot
  // confirm if the stream is healthy and upgrade to OnlineState.Online.
  n2.Br.set(
    "Unknown"
    /* Unknown */
  ));
}
function Xr(t2, e) {
  t2.Ur.q(e.targetId), Eo(t2).mr(e);
}
function Zr(t2, e) {
  t2.Ur.q(e), Eo(t2).gr(e);
}
function to(t2) {
  t2.Ur = new In({
    getRemoteKeysForTarget: (e) => t2.remoteSyncer.getRemoteKeysForTarget(e),
    lt: (e) => t2.Or.get(e) || null
  }), Eo(t2).start(), t2.Br.Sr();
}
function eo(t2) {
  return no(t2) && !Eo(t2).tr() && t2.Or.size > 0;
}
function no(t2) {
  return 0 === B(t2).Fr.size;
}
function so(t2) {
  t2.Ur = void 0;
}
async function io(t2) {
  t2.Or.forEach((e, n2) => {
    Xr(t2, e);
  });
}
async function ro(t2, e) {
  so(t2), // If we still need the watch stream, retry the connection.
  eo(t2) ? (t2.Br.Nr(e), to(t2)) : (
    // No need to restart watch stream because there are no active targets.
    // The online state is set to unknown because there is no active attempt
    // at establishing a connection
    t2.Br.set(
      "Unknown"
      /* Unknown */
    )
  );
}
async function oo(t2, e, n2) {
  if (
    // Mark the client as online since we got a message from the server
    t2.Br.set(
      "Online"
      /* Online */
    ), e instanceof En && 2 === e.state && e.cause
  )
    try {
      await /** Handles an error on a target */
      async function(t3, e2) {
        const n3 = e2.cause;
        for (const s of e2.targetIds)
          t3.Or.has(s) && (await t3.remoteSyncer.rejectListen(s, n3), t3.Or.delete(s), t3.Ur.removeTarget(s));
      }(t2, e);
    } catch (n3) {
      k2("RemoteStore", "Failed to remove targets %s: %s ", e.targetIds.join(","), n3), await co(t2, n3);
    }
  else if (e instanceof yn ? t2.Ur.X(e) : e instanceof pn ? t2.Ur.rt(e) : t2.Ur.et(e), !n2.isEqual(G2.min()))
    try {
      const e2 = await tr(t2.localStore);
      n2.compareTo(e2) >= 0 && // We have received a target change with a global snapshot if the snapshot
      // version is not equal to SnapshotVersion.min().
      await /**
      * Takes a batch of changes from the Datastore, repackages them as a
      * RemoteEvent, and passes that on to the listener, which is typically the
      * SyncEngine.
      */
      function(t3, e3) {
        const n3 = t3.Ur.ut(e3);
        return n3.targetChanges.forEach((n4, s) => {
          if (n4.resumeToken.approximateByteSize() > 0) {
            const i = t3.Or.get(s);
            i && t3.Or.set(s, i.withResumeToken(n4.resumeToken, e3));
          }
        }), // Re-establish listens for the targets that have been invalidated by
        // existence filter mismatches.
        n3.targetMismatches.forEach((e4) => {
          const n4 = t3.Or.get(e4);
          if (!n4)
            return;
          t3.Or.set(e4, n4.withResumeToken(nt.EMPTY_BYTE_STRING, n4.snapshotVersion)), // Cause a hard reset by unwatching and rewatching immediately, but
          // deliberately don't send a resume token so that we get a full update.
          Zr(t3, e4);
          const s = new Ws(n4.target, e4, 1, n4.sequenceNumber);
          Xr(t3, s);
        }), t3.remoteSyncer.applyRemoteEvent(n3);
      }(t2, n2);
    } catch (e2) {
      k2("RemoteStore", "Failed to raise snapshot:", e2), await co(t2, e2);
    }
}
async function co(t2, e, n2) {
  if (!Fs(e))
    throw e;
  t2.Fr.add(
    1
    /* IndexedDbFailed */
  ), // Disable network and raise offline snapshots
  await Hr(t2), t2.Br.set(
    "Offline"
    /* Offline */
  ), n2 || // Use a simple read operation to determine if IndexedDB recovered.
  // Ideally, we would expose a health check directly on SimpleDb, but
  // RemoteStore only has access to persistence through LocalStore.
  (n2 = () => tr(t2.localStore)), // Probe IndexedDB periodically and re-enable network
  t2.asyncQueue.enqueueRetryable(async () => {
    k2("RemoteStore", "Retrying IndexedDB access"), await n2(), t2.Fr.delete(
      1
      /* IndexedDbFailed */
    ), await zr(t2);
  });
}
function uo(t2, e) {
  return e().catch((n2) => co(t2, n2, e));
}
async function ao(t2) {
  const e = B(t2), n2 = To(e);
  let s = e.$r.length > 0 ? e.$r[e.$r.length - 1].batchId : -1;
  for (; ho(e); )
    try {
      const t3 = await sr(e.localStore, s);
      if (null === t3) {
        0 === e.$r.length && n2.ir();
        break;
      }
      s = t3.batchId, lo(e, t3);
    } catch (t3) {
      await co(e, t3);
    }
  fo(e) && wo(e);
}
function ho(t2) {
  return no(t2) && t2.$r.length < 10;
}
function lo(t2, e) {
  t2.$r.push(e);
  const n2 = To(t2);
  n2.er() && n2.pr && n2.Er(e.mutations);
}
function fo(t2) {
  return no(t2) && !To(t2).tr() && t2.$r.length > 0;
}
function wo(t2) {
  To(t2).start();
}
async function _o(t2) {
  To(t2).Ar();
}
async function mo(t2) {
  const e = To(t2);
  for (const n2 of t2.$r)
    e.Er(n2.mutations);
}
async function go(t2, e, n2) {
  const s = t2.$r.shift(), i = js.from(s, e, n2);
  await uo(t2, () => t2.remoteSyncer.applySuccessfulWrite(i)), // It's possible that with the completion of this mutation another
  // slot has freed up.
  await ao(t2);
}
async function yo(t2, e) {
  e && To(t2).pr && // This error affects the actual write.
  await async function(t3, e2) {
    if (n2 = e2.code, Xe(n2) && n2 !== S2.ABORTED) {
      const n3 = t3.$r.shift();
      To(t3).sr(), await uo(t3, () => t3.remoteSyncer.rejectFailedWrite(n3.batchId, e2)), // It's possible that with the completion of this mutation
      // another slot has freed up.
      await ao(t3);
    }
    var n2;
  }(t2, e), // The write stream might have been started by refilling the write
  // pipeline for failed writes
  fo(t2) && wo(t2);
}
async function po(t2, e) {
  const n2 = B(t2);
  e ? (n2.Fr.delete(
    2
    /* IsSecondary */
  ), await zr(n2)) : e || (n2.Fr.add(
    2
    /* IsSecondary */
  ), await Hr(n2), n2.Br.set(
    "Unknown"
    /* Unknown */
  ));
}
function Eo(t2) {
  return t2.qr || // Create stream (but note that it is not started yet).
  (t2.qr = function(t3, e, n2) {
    const s = B(t3);
    return s.Pr(), new Kr(e, s.Hi, s.credentials, s.R, n2);
  }(t2.datastore, t2.asyncQueue, {
    Ii: io.bind(null, t2),
    Ri: ro.bind(null, t2),
    _r: oo.bind(null, t2)
  }), t2.Mr.push(async (e) => {
    e ? (t2.qr.sr(), eo(t2) ? to(t2) : t2.Br.set(
      "Unknown"
      /* Unknown */
    )) : (await t2.qr.stop(), so(t2));
  })), t2.qr;
}
function To(t2) {
  return t2.Kr || // Create stream (but note that it is not started yet).
  (t2.Kr = function(t3, e, n2) {
    const s = B(t3);
    return s.Pr(), new Qr(e, s.Hi, s.credentials, s.R, n2);
  }(t2.datastore, t2.asyncQueue, {
    Ii: _o.bind(null, t2),
    Ri: yo.bind(null, t2),
    Ir: mo.bind(null, t2),
    Tr: go.bind(null, t2)
  }), t2.Mr.push(async (e) => {
    e ? (t2.Kr.sr(), // This will start the write stream if necessary.
    await ao(t2)) : (await t2.Kr.stop(), t2.$r.length > 0 && (k2("RemoteStore", `Stopping write stream with ${t2.$r.length} pending writes`), t2.$r = []));
  })), t2.Kr;
}
var Io = class {
  constructor(t2, e, n2, s, i) {
    this.asyncQueue = t2, this.timerId = e, this.targetTimeMs = n2, this.op = s, this.removalCallback = i, this.deferred = new Cs(), this.then = this.deferred.promise.then.bind(this.deferred.promise), // It's normal for the deferred promise to be canceled (due to cancellation)
    // and so we attach a dummy catch callback to avoid
    // 'UnhandledPromiseRejectionWarning' log spam.
    this.deferred.promise.catch((t3) => {
    });
  }
  /**
   * Creates and returns a DelayedOperation that has been scheduled to be
   * executed on the provided asyncQueue after the provided delayMs.
   *
   * @param asyncQueue - The queue to schedule the operation on.
   * @param id - A Timer ID identifying the type of operation this is.
   * @param delayMs - The delay (ms) before the operation should be scheduled.
   * @param op - The operation to run.
   * @param removalCallback - A callback to be called synchronously once the
   *   operation is executed or canceled, notifying the AsyncQueue to remove it
   *   from its delayedOperations list.
   *   PORTING NOTE: This exists to prevent making removeDelayedOperation() and
   *   the DelayedOperation class public.
   */
  static createAndSchedule(t2, e, n2, s, i) {
    const r2 = Date.now() + n2, o = new Io(t2, e, r2, s, i);
    return o.start(n2), o;
  }
  /**
   * Starts the timer. This is called immediately after construction by
   * createAndSchedule().
   */
  start(t2) {
    this.timerHandle = setTimeout(() => this.handleDelayElapsed(), t2);
  }
  /**
   * Queues the operation to run immediately (if it hasn't already been run or
   * canceled).
   */
  skipDelay() {
    return this.handleDelayElapsed();
  }
  /**
   * Cancels the operation if it hasn't already been executed or canceled. The
   * promise will be rejected.
   *
   * As long as the operation has not yet been run, calling cancel() provides a
   * guarantee that the operation will not be run.
   */
  cancel(t2) {
    null !== this.timerHandle && (this.clearTimeout(), this.deferred.reject(new D2(S2.CANCELLED, "Operation cancelled" + (t2 ? ": " + t2 : ""))));
  }
  handleDelayElapsed() {
    this.asyncQueue.enqueueAndForget(() => null !== this.timerHandle ? (this.clearTimeout(), this.op().then((t2) => this.deferred.resolve(t2))) : Promise.resolve());
  }
  clearTimeout() {
    null !== this.timerHandle && (this.removalCallback(this), clearTimeout(this.timerHandle), this.timerHandle = null);
  }
};
function Ao(t2, e) {
  if ($("AsyncQueue", `${e}: ${t2}`), Fs(t2))
    return new D2(S2.UNAVAILABLE, `${e}: ${t2}`);
  throw t2;
}
var Ro = class {
  /** The default ordering is by key if the comparator is omitted */
  constructor(t2) {
    this.comparator = t2 ? (e, n2) => t2(e, n2) || dt.comparator(e.key, n2.key) : (t3, e) => dt.comparator(t3.key, e.key), this.keyedMap = an(), this.sortedSet = new tn(this.comparator);
  }
  /**
   * Returns an empty copy of the existing DocumentSet, using the same
   * comparator.
   */
  static emptySet(t2) {
    return new Ro(t2.comparator);
  }
  has(t2) {
    return null != this.keyedMap.get(t2);
  }
  get(t2) {
    return this.keyedMap.get(t2);
  }
  first() {
    return this.sortedSet.minKey();
  }
  last() {
    return this.sortedSet.maxKey();
  }
  isEmpty() {
    return this.sortedSet.isEmpty();
  }
  /**
   * Returns the index of the provided key in the document set, or -1 if the
   * document key is not present in the set;
   */
  indexOf(t2) {
    const e = this.keyedMap.get(t2);
    return e ? this.sortedSet.indexOf(e) : -1;
  }
  get size() {
    return this.sortedSet.size;
  }
  /** Iterates documents in order defined by "comparator" */
  forEach(t2) {
    this.sortedSet.inorderTraversal((e, n2) => (t2(e), false));
  }
  /** Inserts or updates a document with the same key */
  add(t2) {
    const e = this.delete(t2.key);
    return e.copy(e.keyedMap.insert(t2.key, t2), e.sortedSet.insert(t2, null));
  }
  /** Deletes a document with a given key */
  delete(t2) {
    const e = this.get(t2);
    return e ? this.copy(this.keyedMap.remove(t2), this.sortedSet.remove(e)) : this;
  }
  isEqual(t2) {
    if (!(t2 instanceof Ro))
      return false;
    if (this.size !== t2.size)
      return false;
    const e = this.sortedSet.getIterator(), n2 = t2.sortedSet.getIterator();
    for (; e.hasNext(); ) {
      const t3 = e.getNext().key, s = n2.getNext().key;
      if (!t3.isEqual(s))
        return false;
    }
    return true;
  }
  toString() {
    const t2 = [];
    return this.forEach((e) => {
      t2.push(e.toString());
    }), 0 === t2.length ? "DocumentSet ()" : "DocumentSet (\n  " + t2.join("  \n") + "\n)";
  }
  copy(t2, e) {
    const n2 = new Ro();
    return n2.comparator = this.comparator, n2.keyedMap = t2, n2.sortedSet = e, n2;
  }
};
var Po = class {
  constructor() {
    this.Qr = new tn(dt.comparator);
  }
  track(t2) {
    const e = t2.doc.key, n2 = this.Qr.get(e);
    n2 ? (
      // Merge the new change with the existing change.
      0 !== t2.type && 3 === n2.type ? this.Qr = this.Qr.insert(e, t2) : 3 === t2.type && 1 !== n2.type ? this.Qr = this.Qr.insert(e, {
        type: n2.type,
        doc: t2.doc
      }) : 2 === t2.type && 2 === n2.type ? this.Qr = this.Qr.insert(e, {
        type: 2,
        doc: t2.doc
      }) : 2 === t2.type && 0 === n2.type ? this.Qr = this.Qr.insert(e, {
        type: 0,
        doc: t2.doc
      }) : 1 === t2.type && 0 === n2.type ? this.Qr = this.Qr.remove(e) : 1 === t2.type && 2 === n2.type ? this.Qr = this.Qr.insert(e, {
        type: 1,
        doc: n2.doc
      }) : 0 === t2.type && 1 === n2.type ? this.Qr = this.Qr.insert(e, {
        type: 2,
        doc: t2.doc
      }) : (
        // This includes these cases, which don't make sense:
        // Added->Added
        // Removed->Removed
        // Modified->Added
        // Removed->Modified
        // Metadata->Added
        // Removed->Metadata
        M2()
      )
    ) : this.Qr = this.Qr.insert(e, t2);
  }
  jr() {
    const t2 = [];
    return this.Qr.inorderTraversal((e, n2) => {
      t2.push(n2);
    }), t2;
  }
};
var bo = class {
  constructor(t2, e, n2, s, i, r2, o, c) {
    this.query = t2, this.docs = e, this.oldDocs = n2, this.docChanges = s, this.mutatedKeys = i, this.fromCache = r2, this.syncStateChanged = o, this.excludesMetadataChanges = c;
  }
  /** Returns a view snapshot as if all documents in the snapshot were added. */
  static fromInitialDocuments(t2, e, n2, s) {
    const i = [];
    return e.forEach((t3) => {
      i.push({
        type: 0,
        doc: t3
      });
    }), new bo(
      t2,
      e,
      Ro.emptySet(e),
      i,
      n2,
      s,
      /* syncStateChanged= */
      true,
      /* excludesMetadataChanges= */
      false
    );
  }
  get hasPendingWrites() {
    return !this.mutatedKeys.isEmpty();
  }
  isEqual(t2) {
    if (!(this.fromCache === t2.fromCache && this.syncStateChanged === t2.syncStateChanged && this.mutatedKeys.isEqual(t2.mutatedKeys) && he(this.query, t2.query) && this.docs.isEqual(t2.docs) && this.oldDocs.isEqual(t2.oldDocs)))
      return false;
    const e = this.docChanges, n2 = t2.docChanges;
    if (e.length !== n2.length)
      return false;
    for (let t3 = 0; t3 < e.length; t3++)
      if (e[t3].type !== n2[t3].type || !e[t3].doc.isEqual(n2[t3].doc))
        return false;
    return true;
  }
};
var vo = class {
  constructor() {
    this.Wr = void 0, this.listeners = [];
  }
};
var Vo = class {
  constructor() {
    this.queries = new Ni((t2) => le(t2), he), this.onlineState = "Unknown", this.Gr = /* @__PURE__ */ new Set();
  }
};
async function So(t2, e) {
  const n2 = B(t2), s = e.query;
  let i = false, r2 = n2.queries.get(s);
  if (r2 || (i = true, r2 = new vo()), i)
    try {
      r2.Wr = await n2.onListen(s);
    } catch (t3) {
      const n3 = Ao(t3, `Initialization of query '${fe(e.query)}' failed`);
      return void e.onError(n3);
    }
  if (n2.queries.set(s, r2), r2.listeners.push(e), // Run global snapshot listeners if a consistent snapshot has been emitted.
  e.zr(n2.onlineState), r2.Wr) {
    e.Hr(r2.Wr) && xo(n2);
  }
}
async function Do(t2, e) {
  const n2 = B(t2), s = e.query;
  let i = false;
  const r2 = n2.queries.get(s);
  if (r2) {
    const t3 = r2.listeners.indexOf(e);
    t3 >= 0 && (r2.listeners.splice(t3, 1), i = 0 === r2.listeners.length);
  }
  if (i)
    return n2.queries.delete(s), n2.onUnlisten(s);
}
function Co(t2, e) {
  const n2 = B(t2);
  let s = false;
  for (const t3 of e) {
    const e2 = t3.query, i = n2.queries.get(e2);
    if (i) {
      for (const e3 of i.listeners)
        e3.Hr(t3) && (s = true);
      i.Wr = t3;
    }
  }
  s && xo(n2);
}
function No(t2, e, n2) {
  const s = B(t2), i = s.queries.get(e);
  if (i)
    for (const t3 of i.listeners)
      t3.onError(n2);
  s.queries.delete(e);
}
function xo(t2) {
  t2.Gr.forEach((t3) => {
    t3.next();
  });
}
var ko = class {
  constructor(t2, e, n2) {
    this.query = t2, this.Jr = e, /**
     * Initial snapshots (e.g. from cache) may not be propagated to the wrapped
     * observer. This flag is set to true once we've actually raised an event.
     */
    this.Yr = false, this.Xr = null, this.onlineState = "Unknown", this.options = n2 || {};
  }
  /**
   * Applies the new ViewSnapshot to this listener, raising a user-facing event
   * if applicable (depending on what changed, whether the user has opted into
   * metadata-only changes, etc.). Returns true if a user-facing event was
   * indeed raised.
   */
  Hr(t2) {
    if (!this.options.includeMetadataChanges) {
      const e2 = [];
      for (const n2 of t2.docChanges)
        3 !== n2.type && e2.push(n2);
      t2 = new bo(
        t2.query,
        t2.docs,
        t2.oldDocs,
        e2,
        t2.mutatedKeys,
        t2.fromCache,
        t2.syncStateChanged,
        /* excludesMetadataChanges= */
        true
      );
    }
    let e = false;
    return this.Yr ? this.Zr(t2) && (this.Jr.next(t2), e = true) : this.eo(t2, this.onlineState) && (this.no(t2), e = true), this.Xr = t2, e;
  }
  onError(t2) {
    this.Jr.error(t2);
  }
  /** Returns whether a snapshot was raised. */
  zr(t2) {
    this.onlineState = t2;
    let e = false;
    return this.Xr && !this.Yr && this.eo(this.Xr, t2) && (this.no(this.Xr), e = true), e;
  }
  eo(t2, e) {
    if (!t2.fromCache)
      return true;
    const n2 = "Offline" !== e;
    return (!this.options.so || !n2) && (!t2.docs.isEmpty() || "Offline" === e);
  }
  Zr(t2) {
    if (t2.docChanges.length > 0)
      return true;
    const e = this.Xr && this.Xr.hasPendingWrites !== t2.hasPendingWrites;
    return !(!t2.syncStateChanged && !e) && true === this.options.includeMetadataChanges;
  }
  no(t2) {
    t2 = bo.fromInitialDocuments(t2.query, t2.docs, t2.mutatedKeys, t2.fromCache), this.Yr = true, this.Jr.next(t2);
  }
};
var $o = class {
  constructor(t2, e) {
    this.payload = t2, this.byteLength = e;
  }
  io() {
    return "metadata" in this.payload;
  }
};
var Oo = class {
  constructor(t2) {
    this.R = t2;
  }
  Un(t2) {
    return $n(this.R, t2);
  }
  /**
   * Converts a BundleDocument to a MutableDocument.
   */
  qn(t2) {
    return t2.metadata.exists ? Un(this.R, t2.document, false) : Dt.newNoDocument(this.Un(t2.metadata.name), this.Kn(t2.metadata.readTime));
  }
  Kn(t2) {
    return Cn(t2);
  }
};
var Fo = class {
  constructor(t2, e, n2) {
    this.ro = t2, this.localStore = e, this.R = n2, /** Batched queries to be saved into storage */
    this.queries = [], /** Batched documents to be saved into storage */
    this.documents = [], this.progress = Mo(t2);
  }
  /**
   * Adds an element from the bundle to the loader.
   *
   * Returns a new progress if adding the element leads to a new progress,
   * otherwise returns null.
   */
  oo(t2) {
    this.progress.bytesLoaded += t2.byteLength;
    let e = this.progress.documentsLoaded;
    return t2.payload.namedQuery ? this.queries.push(t2.payload.namedQuery) : t2.payload.documentMetadata ? (this.documents.push({
      metadata: t2.payload.documentMetadata
    }), t2.payload.documentMetadata.exists || ++e) : t2.payload.document && (this.documents[this.documents.length - 1].document = t2.payload.document, ++e), e !== this.progress.documentsLoaded ? (this.progress.documentsLoaded = e, Object.assign({}, this.progress)) : null;
  }
  co(t2) {
    const e = /* @__PURE__ */ new Map(), n2 = new Oo(this.R);
    for (const s of t2)
      if (s.metadata.queries) {
        const t3 = n2.Un(s.metadata.name);
        for (const n3 of s.metadata.queries) {
          const s2 = (e.get(n3) || dn()).add(t3);
          e.set(n3, s2);
        }
      }
    return e;
  }
  /**
   * Update the progress to 'Success' and return the updated progress.
   */
  async complete() {
    const t2 = await hr(this.localStore, new Oo(this.R), this.documents, this.ro.id), e = this.co(this.documents);
    for (const t3 of this.queries)
      await lr(this.localStore, t3, e.get(t3.name));
    return this.progress.taskState = "Success", new Wi(Object.assign({}, this.progress), t2);
  }
};
function Mo(t2) {
  return {
    taskState: "Running",
    documentsLoaded: 0,
    bytesLoaded: 0,
    totalDocuments: t2.totalDocuments,
    totalBytes: t2.totalBytes
  };
}
var Lo = class {
  constructor(t2) {
    this.key = t2;
  }
};
var Bo = class {
  constructor(t2) {
    this.key = t2;
  }
};
var Uo = class {
  constructor(t2, e) {
    this.query = t2, this.uo = e, this.ao = null, /**
     * A flag whether the view is current with the backend. A view is considered
     * current after it has seen the current flag from the backend and did not
     * lose consistency within the watch stream (e.g. because of an existence
     * filter mismatch).
     */
    this.current = false, /** Documents in the view but not in the remote target */
    this.ho = dn(), /** Document Keys that have local changes */
    this.mutatedKeys = dn(), this.lo = we(t2), this.fo = new Ro(this.lo);
  }
  /**
   * The set of remote documents that the server has told us belongs to the target associated with
   * this view.
   */
  get wo() {
    return this.uo;
  }
  /**
   * Iterates over a set of doc changes, applies the query limit, and computes
   * what the new results should be, what the changes were, and whether we may
   * need to go back to the local cache for more results. Does not make any
   * changes to the view.
   * @param docChanges - The doc changes to apply to this view.
   * @param previousChanges - If this is being called with a refill, then start
   *        with this set of docs and changes instead of the current view.
   * @returns a new set of docs, changes, and refill flag.
   */
  _o(t2, e) {
    const n2 = e ? e.mo : new Po(), s = e ? e.fo : this.fo;
    let i = e ? e.mutatedKeys : this.mutatedKeys, r2 = s, o = false;
    const c = ne(this.query) && s.size === this.query.limit ? s.last() : null, u2 = se(this.query) && s.size === this.query.limit ? s.first() : null;
    if (t2.inorderTraversal((t3, e2) => {
      const a = s.get(t3), h = de(this.query, e2) ? e2 : null, l = !!a && this.mutatedKeys.has(a.key), f = !!h && (h.hasLocalMutations || // We only consider committed mutations for documents that were
      // mutated during the lifetime of the view.
      this.mutatedKeys.has(h.key) && h.hasCommittedMutations);
      let d = false;
      if (a && h) {
        a.data.isEqual(h.data) ? l !== f && (n2.track({
          type: 3,
          doc: h
        }), d = true) : this.yo(a, h) || (n2.track({
          type: 2,
          doc: h
        }), d = true, (c && this.lo(h, c) > 0 || u2 && this.lo(h, u2) < 0) && // This doc moved from inside the limit to outside the limit.
        // That means there may be some other doc in the local cache
        // that should be included instead.
        (o = true));
      } else
        !a && h ? (n2.track({
          type: 0,
          doc: h
        }), d = true) : a && !h && (n2.track({
          type: 1,
          doc: a
        }), d = true, (c || u2) && // A doc was removed from a full limit query. We'll need to
        // requery from the local cache to see if we know about some other
        // doc that should be in the results.
        (o = true));
      d && (h ? (r2 = r2.add(h), i = f ? i.add(t3) : i.delete(t3)) : (r2 = r2.delete(t3), i = i.delete(t3)));
    }), ne(this.query) || se(this.query))
      for (; r2.size > this.query.limit; ) {
        const t3 = ne(this.query) ? r2.last() : r2.first();
        r2 = r2.delete(t3.key), i = i.delete(t3.key), n2.track({
          type: 1,
          doc: t3
        });
      }
    return {
      fo: r2,
      mo: n2,
      Nn: o,
      mutatedKeys: i
    };
  }
  yo(t2, e) {
    return t2.hasLocalMutations && e.hasCommittedMutations && !e.hasLocalMutations;
  }
  /**
   * Updates the view with the given ViewDocumentChanges and optionally updates
   * limbo docs and sync state from the provided target change.
   * @param docChanges - The set of changes to make to the view's docs.
   * @param updateLimboDocuments - Whether to update limbo documents based on
   *        this change.
   * @param targetChange - A target change to apply for computing limbo docs and
   *        sync state.
   * @returns A new ViewChange with the given docs, changes, and sync state.
   */
  // PORTING NOTE: The iOS/Android clients always compute limbo document changes.
  applyChanges(t2, e, n2) {
    const s = this.fo;
    this.fo = t2.fo, this.mutatedKeys = t2.mutatedKeys;
    const i = t2.mo.jr();
    i.sort((t3, e2) => function(t4, e3) {
      const n3 = (t5) => {
        switch (t5) {
          case 0:
            return 1;
          case 2:
          case 3:
            return 2;
          case 1:
            return 0;
          default:
            return M2();
        }
      };
      return n3(t4) - n3(e3);
    }(t3.type, e2.type) || this.lo(t3.doc, e2.doc)), this.po(n2);
    const r2 = e ? this.Eo() : [], o = 0 === this.ho.size && this.current ? 1 : 0, c = o !== this.ao;
    if (this.ao = o, 0 !== i.length || c) {
      return {
        snapshot: new bo(
          this.query,
          t2.fo,
          s,
          i,
          t2.mutatedKeys,
          0 === o,
          c,
          /* excludesMetadataChanges= */
          false
        ),
        To: r2
      };
    }
    return {
      To: r2
    };
  }
  /**
   * Applies an OnlineState change to the view, potentially generating a
   * ViewChange if the view's syncState changes as a result.
   */
  zr(t2) {
    return this.current && "Offline" === t2 ? (
      // If we're offline, set `current` to false and then call applyChanges()
      // to refresh our syncState and generate a ViewChange as appropriate. We
      // are guaranteed to get a new TargetChange that sets `current` back to
      // true once the client is back online.
      (this.current = false, this.applyChanges(
        {
          fo: this.fo,
          mo: new Po(),
          mutatedKeys: this.mutatedKeys,
          Nn: false
        },
        /* updateLimboDocuments= */
        false
      ))
    ) : {
      To: []
    };
  }
  /**
   * Returns whether the doc for the given key should be in limbo.
   */
  Io(t2) {
    return !this.uo.has(t2) && // The local store doesn't think it's a result, so it shouldn't be in limbo.
    (!!this.fo.has(t2) && !this.fo.get(t2).hasLocalMutations);
  }
  /**
   * Updates syncedDocuments, current, and limbo docs based on the given change.
   * Returns the list of changes to which docs are in limbo.
   */
  po(t2) {
    t2 && (t2.addedDocuments.forEach((t3) => this.uo = this.uo.add(t3)), t2.modifiedDocuments.forEach((t3) => {
    }), t2.removedDocuments.forEach((t3) => this.uo = this.uo.delete(t3)), this.current = t2.current);
  }
  Eo() {
    if (!this.current)
      return [];
    const t2 = this.ho;
    this.ho = dn(), this.fo.forEach((t3) => {
      this.Io(t3.key) && (this.ho = this.ho.add(t3.key));
    });
    const e = [];
    return t2.forEach((t3) => {
      this.ho.has(t3) || e.push(new Bo(t3));
    }), this.ho.forEach((n2) => {
      t2.has(n2) || e.push(new Lo(n2));
    }), e;
  }
  /**
   * Update the in-memory state of the current view with the state read from
   * persistence.
   *
   * We update the query view whenever a client's primary status changes:
   * - When a client transitions from primary to secondary, it can miss
   *   LocalStorage updates and its query views may temporarily not be
   *   synchronized with the state on disk.
   * - For secondary to primary transitions, the client needs to update the list
   *   of `syncedDocuments` since secondary clients update their query views
   *   based purely on synthesized RemoteEvents.
   *
   * @param queryResult.documents - The documents that match the query according
   * to the LocalStore.
   * @param queryResult.remoteKeys - The keys of the documents that match the
   * query according to the backend.
   *
   * @returns The ViewChange that resulted from this synchronization.
   */
  // PORTING NOTE: Multi-tab only.
  Ao(t2) {
    this.uo = t2.Bn, this.ho = dn();
    const e = this._o(t2.documents);
    return this.applyChanges(
      e,
      /*updateLimboDocuments=*/
      true
    );
  }
  /**
   * Returns a view snapshot as if this query was just listened to. Contains
   * a document add for every existing document and the `fromCache` and
   * `hasPendingWrites` status of the already established view.
   */
  // PORTING NOTE: Multi-tab only.
  Ro() {
    return bo.fromInitialDocuments(this.query, this.fo, this.mutatedKeys, 0 === this.ao);
  }
};
var qo = class {
  constructor(t2, e, n2) {
    this.query = t2, this.targetId = e, this.view = n2;
  }
};
var Ko = class {
  constructor(t2) {
    this.key = t2, /**
     * Set to true once we've received a document. This is used in
     * getRemoteKeysForTarget() and ultimately used by WatchChangeAggregator to
     * decide whether it needs to manufacture a delete event for the target once
     * the target is CURRENT.
     */
    this.Po = false;
  }
};
var Qo = class {
  constructor(t2, e, n2, s, i, r2) {
    this.localStore = t2, this.remoteStore = e, this.eventManager = n2, this.sharedClientState = s, this.currentUser = i, this.maxConcurrentLimboResolutions = r2, this.bo = {}, this.vo = new Ni((t3) => le(t3), he), this.Vo = /* @__PURE__ */ new Map(), /**
     * The keys of documents that are in limbo for which we haven't yet started a
     * limbo resolution query. The strings in this set are the result of calling
     * `key.path.canonicalString()` where `key` is a `DocumentKey` object.
     *
     * The `Set` type was chosen because it provides efficient lookup and removal
     * of arbitrary elements and it also maintains insertion order, providing the
     * desired queue-like FIFO semantics.
     */
    this.So = /* @__PURE__ */ new Set(), /**
     * Keeps track of the target ID for each document that is in limbo with an
     * active target.
     */
    this.Do = new tn(dt.comparator), /**
     * Keeps track of the information about an active limbo resolution for each
     * active target ID that was started for the purpose of limbo resolution.
     */
    this.Co = /* @__PURE__ */ new Map(), this.No = new dr(), /** Stores user completion handlers, indexed by User and BatchId. */
    this.xo = {}, /** Stores user callbacks waiting for all pending writes to be acknowledged. */
    this.ko = /* @__PURE__ */ new Map(), this.$o = Ei.Yt(), this.onlineState = "Unknown", // The primary state is set to `true` or `false` immediately after Firestore
    // startup. In the interim, a client should only be considered primary if
    // `isPrimary` is true.
    this.Oo = void 0;
  }
  get isPrimaryClient() {
    return true === this.Oo;
  }
};
async function jo(t2, e) {
  const n2 = Ec2(t2);
  let s, i;
  const r2 = n2.vo.get(e);
  if (r2)
    s = r2.targetId, n2.sharedClientState.addLocalQueryTarget(s), i = r2.view.Ro();
  else {
    const t3 = await ir(n2.localStore, ue(e)), r3 = n2.sharedClientState.addLocalQueryTarget(t3.targetId);
    s = t3.targetId, i = await Wo(n2, e, s, "current" === r3), n2.isPrimaryClient && Jr(n2.remoteStore, t3);
  }
  return i;
}
async function Wo(t2, e, n2, s) {
  t2.Fo = (e2, n3, s2) => async function(t3, e3, n4, s3) {
    let i2 = e3.view._o(n4);
    i2.Nn && // The query has a limit and some docs were removed, so we need
    // to re-run the query against the local store to make sure we
    // didn't lose any good docs that had been past the limit.
    (i2 = await or(
      t3.localStore,
      e3.query,
      /* usePreviousResults= */
      false
    ).then(({ documents: t4 }) => e3.view._o(t4, i2)));
    const r3 = s3 && s3.targetChanges.get(e3.targetId), o2 = e3.view.applyChanges(
      i2,
      /* updateLimboDocuments= */
      t3.isPrimaryClient,
      r3
    );
    return rc2(t3, e3.targetId, o2.To), o2.snapshot;
  }(t2, e2, n3, s2);
  const i = await or(
    t2.localStore,
    e,
    /* usePreviousResults= */
    true
  ), r2 = new Uo(e, i.Bn), o = r2._o(i.documents), c = gn.createSynthesizedTargetChangeForCurrentChange(n2, s && "Offline" !== t2.onlineState), u2 = r2.applyChanges(
    o,
    /* updateLimboDocuments= */
    t2.isPrimaryClient,
    c
  );
  rc2(t2, n2, u2.To);
  const a = new qo(e, n2, r2);
  return t2.vo.set(e, a), t2.Vo.has(n2) ? t2.Vo.get(n2).push(e) : t2.Vo.set(n2, [e]), u2.snapshot;
}
async function Go(t2, e) {
  const n2 = B(t2), s = n2.vo.get(e), i = n2.Vo.get(s.targetId);
  if (i.length > 1)
    return n2.Vo.set(s.targetId, i.filter((t3) => !he(t3, e))), void n2.vo.delete(e);
  if (n2.isPrimaryClient) {
    n2.sharedClientState.removeLocalQueryTarget(s.targetId);
    n2.sharedClientState.isActiveQueryTarget(s.targetId) || await rr(
      n2.localStore,
      s.targetId,
      /*keepPersistedTargetData=*/
      false
    ).then(() => {
      n2.sharedClientState.clearQueryState(s.targetId), Yr(n2.remoteStore, s.targetId), sc2(n2, s.targetId);
    }).catch(Pi);
  } else
    sc2(n2, s.targetId), await rr(
      n2.localStore,
      s.targetId,
      /*keepPersistedTargetData=*/
      true
    );
}
async function zo(t2, e, n2) {
  const s = Tc2(t2);
  try {
    const t3 = await function(t4, e2) {
      const n3 = B(t4), s2 = W2.now(), i = e2.reduce((t5, e3) => t5.add(e3.key), dn());
      let r2;
      return n3.persistence.runTransaction("Locally write mutations", "readwrite", (t5) => n3.Mn.pn(t5, i).next((i2) => {
        r2 = i2;
        const o = [];
        for (const t6 of e2) {
          const e3 = Le(t6, r2.get(t6.key));
          null != e3 && // NOTE: The base state should only be applied if there's some
          // existing document to override, so use a Precondition of
          // exists=true
          o.push(new Ke(t6.key, e3, St(e3.value.mapValue), ke.exists(true)));
        }
        return n3._n.addMutationBatch(t5, s2, o, e2);
      })).then((t5) => (t5.applyToLocalDocumentSet(r2), {
        batchId: t5.batchId,
        changes: r2
      }));
    }(s.localStore, e);
    s.sharedClientState.addPendingMutation(t3.batchId), function(t4, e2, n3) {
      let s2 = t4.xo[t4.currentUser.toKey()];
      s2 || (s2 = new tn(K2));
      s2 = s2.insert(e2, n3), t4.xo[t4.currentUser.toKey()] = s2;
    }(s, t3.batchId, n2), await uc2(s, t3.changes), await ao(s.remoteStore);
  } catch (t3) {
    const e2 = Ao(t3, "Failed to persist write");
    n2.reject(e2);
  }
}
async function Ho(t2, e) {
  const n2 = B(t2);
  try {
    const t3 = await er(n2.localStore, e);
    e.targetChanges.forEach((t4, e2) => {
      const s = n2.Co.get(e2);
      s && // Since this is a limbo resolution lookup, it's for a single document
      // and it could be added, modified, or removed, but not a combination.
      (L2(t4.addedDocuments.size + t4.modifiedDocuments.size + t4.removedDocuments.size <= 1), t4.addedDocuments.size > 0 ? s.Po = true : t4.modifiedDocuments.size > 0 ? L2(s.Po) : t4.removedDocuments.size > 0 && (L2(s.Po), s.Po = false));
    }), await uc2(n2, t3, e);
  } catch (t3) {
    await Pi(t3);
  }
}
function Jo(t2, e, n2) {
  const s = B(t2);
  if (s.isPrimaryClient && 0 === n2 || !s.isPrimaryClient && 1 === n2) {
    const t3 = [];
    s.vo.forEach((n3, s2) => {
      const i = s2.view.zr(e);
      i.snapshot && t3.push(i.snapshot);
    }), function(t4, e2) {
      const n3 = B(t4);
      n3.onlineState = e2;
      let s2 = false;
      n3.queries.forEach((t5, n4) => {
        for (const t6 of n4.listeners)
          t6.zr(e2) && (s2 = true);
      }), s2 && xo(n3);
    }(s.eventManager, e), t3.length && s.bo._r(t3), s.onlineState = e, s.isPrimaryClient && s.sharedClientState.setOnlineState(e);
  }
}
async function Yo(t2, e, n2) {
  const s = B(t2);
  s.sharedClientState.updateQueryState(e, "rejected", n2);
  const i = s.Co.get(e), r2 = i && i.key;
  if (r2) {
    let t3 = new tn(dt.comparator);
    t3 = t3.insert(r2, Dt.newNoDocument(r2, G2.min()));
    const n3 = dn().add(r2), i2 = new mn(
      G2.min(),
      /* targetChanges= */
      /* @__PURE__ */ new Map(),
      /* targetMismatches= */
      new sn(K2),
      t3,
      n3
    );
    await Ho(s, i2), // Since this query failed, we won't want to manually unlisten to it.
    // We only remove it from bookkeeping after we successfully applied the
    // RemoteEvent. If `applyRemoteEvent()` throws, we want to re-listen to
    // this query when the RemoteStore restarts the Watch stream, which should
    // re-trigger the target failure.
    s.Do = s.Do.remove(r2), s.Co.delete(e), cc2(s);
  } else
    await rr(
      s.localStore,
      e,
      /* keepPersistedTargetData */
      false
    ).then(() => sc2(s, e, n2)).catch(Pi);
}
async function Xo(t2, e) {
  const n2 = B(t2), s = e.batch.batchId;
  try {
    const t3 = await Zi(n2.localStore, e);
    nc2(
      n2,
      s,
      /*error=*/
      null
    ), ec2(n2, s), n2.sharedClientState.updateMutationState(s, "acknowledged"), await uc2(n2, t3);
  } catch (t3) {
    await Pi(t3);
  }
}
async function Zo(t2, e, n2) {
  const s = B(t2);
  try {
    const t3 = await function(t4, e2) {
      const n3 = B(t4);
      return n3.persistence.runTransaction("Reject batch", "readwrite-primary", (t5) => {
        let s2;
        return n3._n.lookupMutationBatch(t5, e2).next((e3) => (L2(null !== e3), s2 = e3.keys(), n3._n.removeMutationBatch(t5, e3))).next(() => n3._n.performConsistencyCheck(t5)).next(() => n3.Mn.pn(t5, s2));
      });
    }(s.localStore, e);
    nc2(s, e, n2), ec2(s, e), s.sharedClientState.updateMutationState(e, "rejected", n2), await uc2(s, t3);
  } catch (n3) {
    await Pi(n3);
  }
}
async function tc2(t2, e) {
  const n2 = B(t2);
  no(n2.remoteStore) || k2("SyncEngine", "The network is disabled. The task returned by 'awaitPendingWrites()' will not complete until the network is enabled.");
  try {
    const t3 = await function(t4) {
      const e2 = B(t4);
      return e2.persistence.runTransaction("Get highest unacknowledged batch id", "readonly", (t5) => e2._n.getHighestUnacknowledgedBatchId(t5));
    }(n2.localStore);
    if (-1 === t3)
      return void e.resolve();
    const s = n2.ko.get(t3) || [];
    s.push(e), n2.ko.set(t3, s);
  } catch (t3) {
    const n3 = Ao(t3, "Initialization of waitForPendingWrites() operation failed");
    e.reject(n3);
  }
}
function ec2(t2, e) {
  (t2.ko.get(e) || []).forEach((t3) => {
    t3.resolve();
  }), t2.ko.delete(e);
}
function nc2(t2, e, n2) {
  const s = B(t2);
  let i = s.xo[s.currentUser.toKey()];
  if (i) {
    const t3 = i.get(e);
    t3 && (n2 ? t3.reject(n2) : t3.resolve(), i = i.remove(e)), s.xo[s.currentUser.toKey()] = i;
  }
}
function sc2(t2, e, n2 = null) {
  t2.sharedClientState.removeLocalQueryTarget(e);
  for (const s of t2.Vo.get(e))
    t2.vo.delete(s), n2 && t2.bo.Mo(s, n2);
  if (t2.Vo.delete(e), t2.isPrimaryClient) {
    t2.No.Zn(e).forEach((e2) => {
      t2.No.containsKey(e2) || // We removed the last reference for this key
      ic2(t2, e2);
    });
  }
}
function ic2(t2, e) {
  t2.So.delete(e.path.canonicalString());
  const n2 = t2.Do.get(e);
  null !== n2 && (Yr(t2.remoteStore, n2), t2.Do = t2.Do.remove(e), t2.Co.delete(n2), cc2(t2));
}
function rc2(t2, e, n2) {
  for (const s of n2)
    if (s instanceof Lo)
      t2.No.addReference(s.key, e), oc2(t2, s);
    else if (s instanceof Bo) {
      k2("SyncEngine", "Document no longer in limbo: " + s.key), t2.No.removeReference(s.key, e);
      t2.No.containsKey(s.key) || // We removed the last reference for this key
      ic2(t2, s.key);
    } else
      M2();
}
function oc2(t2, e) {
  const n2 = e.key, s = n2.path.canonicalString();
  t2.Do.get(n2) || t2.So.has(s) || (k2("SyncEngine", "New document in limbo: " + n2), t2.So.add(s), cc2(t2));
}
function cc2(t2) {
  for (; t2.So.size > 0 && t2.Do.size < t2.maxConcurrentLimboResolutions; ) {
    const e = t2.So.values().next().value;
    t2.So.delete(e);
    const n2 = new dt(X2.fromString(e)), s = t2.$o.next();
    t2.Co.set(s, new Ko(n2)), t2.Do = t2.Do.insert(n2, s), Jr(t2.remoteStore, new Ws(ue(ee(n2.path)), s, 2, V2.o));
  }
}
async function uc2(t2, e, n2) {
  const s = B(t2), i = [], r2 = [], o = [];
  s.vo.isEmpty() || (s.vo.forEach((t3, c) => {
    o.push(s.Fo(c, e, n2).then((t4) => {
      if (t4) {
        s.isPrimaryClient && s.sharedClientState.updateQueryState(c.targetId, t4.fromCache ? "not-current" : "current"), i.push(t4);
        const e2 = zi.vn(c.targetId, t4);
        r2.push(e2);
      }
    }));
  }), await Promise.all(o), s.bo._r(i), await async function(t3, e2) {
    const n3 = B(t3);
    try {
      await n3.persistence.runTransaction("notifyLocalViewChanges", "readwrite", (t4) => Ns.forEach(e2, (e3) => Ns.forEach(e3.Pn, (s2) => n3.persistence.referenceDelegate.addReference(t4, e3.targetId, s2)).next(() => Ns.forEach(e3.bn, (s2) => n3.persistence.referenceDelegate.removeReference(t4, e3.targetId, s2)))));
    } catch (t4) {
      if (!Fs(t4))
        throw t4;
      k2("LocalStore", "Failed to update sequence numbers: " + t4);
    }
    for (const t4 of e2) {
      const e3 = t4.targetId;
      if (!t4.fromCache) {
        const t5 = n3.kn.get(e3), s2 = t5.snapshotVersion, i2 = t5.withLastLimboFreeSnapshotVersion(s2);
        n3.kn = n3.kn.insert(e3, i2);
      }
    }
  }(s.localStore, r2));
}
async function ac2(t2, e) {
  const n2 = B(t2);
  if (!n2.currentUser.isEqual(e)) {
    k2("SyncEngine", "User change. New user:", e.toKey());
    const t3 = await Xi(n2.localStore, e);
    n2.currentUser = e, // Fails tasks waiting for pending writes requested by previous user.
    function(t4, e2) {
      t4.ko.forEach((t5) => {
        t5.forEach((t6) => {
          t6.reject(new D2(S2.CANCELLED, e2));
        });
      }), t4.ko.clear();
    }(n2, "'waitForPendingWrites' promise is rejected due to a user change."), // TODO(b/114226417): Consider calling this only in the primary tab.
    n2.sharedClientState.handleUserChange(e, t3.removedBatchIds, t3.addedBatchIds), await uc2(n2, t3.Ln);
  }
}
function hc2(t2, e) {
  const n2 = B(t2), s = n2.Co.get(e);
  if (s && s.Po)
    return dn().add(s.key);
  {
    let t3 = dn();
    const s2 = n2.Vo.get(e);
    if (!s2)
      return t3;
    for (const e2 of s2) {
      const s3 = n2.vo.get(e2);
      t3 = t3.unionWith(s3.view.wo);
    }
    return t3;
  }
}
async function lc2(t2, e) {
  const n2 = B(t2), s = await or(
    n2.localStore,
    e.query,
    /* usePreviousResults= */
    true
  ), i = e.view.Ao(s);
  return n2.isPrimaryClient && rc2(n2, e.targetId, i.To), i;
}
async function fc2(t2) {
  const e = B(t2);
  return ur(e.localStore).then((t3) => uc2(e, t3));
}
async function dc2(t2, e, n2, s) {
  const i = B(t2), r2 = await function(t3, e2) {
    const n3 = B(t3), s2 = B(n3._n);
    return n3.persistence.runTransaction("Lookup mutation documents", "readonly", (t4) => s2.jt(t4, e2).next((e3) => e3 ? n3.Mn.pn(t4, e3) : Ns.resolve(null)));
  }(i.localStore, e);
  null !== r2 ? ("pending" === n2 ? (
    // If we are the primary client, we need to send this write to the
    // backend. Secondary clients will ignore these writes since their remote
    // connection is disabled.
    await ao(i.remoteStore)
  ) : "acknowledged" === n2 || "rejected" === n2 ? (
    // NOTE: Both these methods are no-ops for batches that originated from
    // other clients.
    (nc2(i, e, s || null), ec2(i, e), function(t3, e2) {
      B(B(t3)._n).Gt(e2);
    }(i.localStore, e))
  ) : M2(), await uc2(i, r2)) : (
    // A throttled tab may not have seen the mutation before it was completed
    // and removed from the mutation queue, in which case we won't have cached
    // the affected documents. In this case we can safely ignore the update
    // since that means we didn't apply the mutation locally at all (if we
    // had, we would have cached the affected documents), and so we will just
    // see any resulting document changes via normal remote document updates
    // as applicable.
    k2("SyncEngine", "Cannot apply mutation batch with id: " + e)
  );
}
async function wc2(t2, e) {
  const n2 = B(t2);
  if (Ec2(n2), Tc2(n2), true === e && true !== n2.Oo) {
    const t3 = n2.sharedClientState.getAllActiveQueryTargets(), e2 = await _c(n2, t3.toArray());
    n2.Oo = true, await po(n2.remoteStore, true);
    for (const t4 of e2)
      Jr(n2.remoteStore, t4);
  } else if (false === e && false !== n2.Oo) {
    const t3 = [];
    let e2 = Promise.resolve();
    n2.Vo.forEach((s, i) => {
      n2.sharedClientState.isLocalQueryTarget(i) ? t3.push(i) : e2 = e2.then(() => (sc2(n2, i), rr(
        n2.localStore,
        i,
        /*keepPersistedTargetData=*/
        true
      ))), Yr(n2.remoteStore, i);
    }), await e2, await _c(n2, t3), // PORTING NOTE: Multi-Tab only.
    function(t4) {
      const e3 = B(t4);
      e3.Co.forEach((t5, n3) => {
        Yr(e3.remoteStore, n3);
      }), e3.No.ts(), e3.Co = /* @__PURE__ */ new Map(), e3.Do = new tn(dt.comparator);
    }(n2), n2.Oo = false, await po(n2.remoteStore, false);
  }
}
async function _c(t2, e, n2) {
  const s = B(t2), i = [], r2 = [];
  for (const t3 of e) {
    let e2;
    const n3 = s.Vo.get(t3);
    if (n3 && 0 !== n3.length) {
      e2 = await ir(s.localStore, ue(n3[0]));
      for (const t4 of n3) {
        const e3 = s.vo.get(t4), n4 = await lc2(s, e3);
        n4.snapshot && r2.push(n4.snapshot);
      }
    } else {
      const n4 = await cr(s.localStore, t3);
      e2 = await ir(s.localStore, n4), await Wo(
        s,
        mc2(n4),
        t3,
        /*current=*/
        false
      );
    }
    i.push(e2);
  }
  return s.bo._r(r2), i;
}
function mc2(t2) {
  return te(t2.path, t2.collectionGroup, t2.orderBy, t2.filters, t2.limit, "F", t2.startAt, t2.endAt);
}
function gc2(t2) {
  const e = B(t2);
  return B(B(e.localStore).persistence).fn();
}
async function yc(t2, e, n2, s) {
  const i = B(t2);
  if (i.Oo)
    k2("SyncEngine", "Ignoring unexpected query state notification.");
  else if (i.Vo.has(e))
    switch (n2) {
      case "current":
      case "not-current": {
        const t3 = await ur(i.localStore), s2 = mn.createSynthesizedRemoteEventForCurrentChange(e, "current" === n2);
        await uc2(i, t3, s2);
        break;
      }
      case "rejected":
        await rr(
          i.localStore,
          e,
          /* keepPersistedTargetData */
          true
        ), sc2(i, e, s);
        break;
      default:
        M2();
    }
}
async function pc2(t2, e, n2) {
  const s = Ec2(t2);
  if (s.Oo) {
    for (const t3 of e) {
      if (s.Vo.has(t3)) {
        k2("SyncEngine", "Adding an already active target " + t3);
        continue;
      }
      const e2 = await cr(s.localStore, t3), n3 = await ir(s.localStore, e2);
      await Wo(
        s,
        mc2(e2),
        n3.targetId,
        /*current=*/
        false
      ), Jr(s.remoteStore, n3);
    }
    for (const t3 of n2)
      s.Vo.has(t3) && // Release queries that are still active.
      await rr(
        s.localStore,
        t3,
        /* keepPersistedTargetData */
        false
      ).then(() => {
        Yr(s.remoteStore, t3), sc2(s, t3);
      }).catch(Pi);
  }
}
function Ec2(t2) {
  const e = B(t2);
  return e.remoteStore.remoteSyncer.applyRemoteEvent = Ho.bind(null, e), e.remoteStore.remoteSyncer.getRemoteKeysForTarget = hc2.bind(null, e), e.remoteStore.remoteSyncer.rejectListen = Yo.bind(null, e), e.bo._r = Co.bind(null, e.eventManager), e.bo.Mo = No.bind(null, e.eventManager), e;
}
function Tc2(t2) {
  const e = B(t2);
  return e.remoteStore.remoteSyncer.applySuccessfulWrite = Xo.bind(null, e), e.remoteStore.remoteSyncer.rejectFailedWrite = Zo.bind(null, e), e;
}
function Ic2(t2, e, n2) {
  const s = B(t2);
  (async function(t3, e2, n3) {
    try {
      const s2 = await e2.getMetadata();
      if (await function(t4, e3) {
        const n4 = B(t4), s3 = Cn(e3.createTime);
        return n4.persistence.runTransaction("hasNewerBundle", "readonly", (t5) => n4.Ke.getBundleMetadata(t5, e3.id)).then((t5) => !!t5 && t5.createTime.compareTo(s3) >= 0);
      }(t3.localStore, s2))
        return await e2.close(), void n3._completeWith(function(t4) {
          return {
            taskState: "Success",
            documentsLoaded: t4.totalDocuments,
            bytesLoaded: t4.totalBytes,
            totalDocuments: t4.totalDocuments,
            totalBytes: t4.totalBytes
          };
        }(s2));
      n3._updateProgress(Mo(s2));
      const i = new Fo(s2, t3.localStore, e2.R);
      let r2 = await e2.Lo();
      for (; r2; ) {
        const t4 = await i.oo(r2);
        t4 && n3._updateProgress(t4), r2 = await e2.Lo();
      }
      const o = await i.complete();
      await uc2(
        t3,
        o.wn,
        /* remoteEvent */
        void 0
      ), // Save metadata, so loading the same bundle will skip.
      await function(t4, e3) {
        const n4 = B(t4);
        return n4.persistence.runTransaction("Save bundle", "readwrite", (t5) => n4.Ke.saveBundleMetadata(t5, e3));
      }(t3.localStore, s2), n3._completeWith(o.progress);
    } catch (t4) {
      O2("SyncEngine", `Loading bundle failed with ${t4}`), n3._failWith(t4);
    }
  })(s, e, n2).then(() => {
    s.sharedClientState.notifyBundleLoaded();
  });
}
var Ac2 = class {
  constructor() {
    this.synchronizeTabs = false;
  }
  async initialize(t2) {
    this.R = Br(t2.databaseInfo.databaseId), this.sharedClientState = this.Bo(t2), this.persistence = this.Uo(t2), await this.persistence.start(), this.gcScheduler = this.qo(t2), this.localStore = this.Ko(t2);
  }
  qo(t2) {
    return null;
  }
  Ko(t2) {
    return Yi(this.persistence, new Hi(), t2.initialUser, this.R);
  }
  Uo(t2) {
    return new pr(Tr.Ps, this.R);
  }
  Bo(t2) {
    return new Nr();
  }
  async terminate() {
    this.gcScheduler && this.gcScheduler.stop(), await this.sharedClientState.shutdown(), await this.persistence.shutdown();
  }
};
var Rc2 = class extends Ac2 {
  constructor(t2, e, n2) {
    super(), this.Qo = t2, this.cacheSizeBytes = e, this.forceOwnership = n2, this.synchronizeTabs = false;
  }
  async initialize(t2) {
    await super.initialize(t2), await ar(this.localStore), await this.Qo.initialize(this, t2), // Enqueue writes from a previous session
    await Tc2(this.Qo.syncEngine), await ao(this.Qo.remoteStore);
  }
  Ko(t2) {
    return Yi(this.persistence, new Hi(), t2.initialUser, this.R);
  }
  qo(t2) {
    const e = this.persistence.referenceDelegate.garbageCollector;
    return new Vi(e, t2.asyncQueue);
  }
  Uo(t2) {
    const e = ji(t2.databaseInfo.databaseId, t2.databaseInfo.persistenceKey), n2 = void 0 !== this.cacheSizeBytes ? fi.withCacheSize(this.cacheSizeBytes) : fi.DEFAULT;
    return new qi(this.synchronizeTabs, e, t2.clientId, n2, t2.asyncQueue, Mr(), Lr(), this.R, this.sharedClientState, !!this.forceOwnership);
  }
  Bo(t2) {
    return new Nr();
  }
};
var Pc2 = class extends Rc2 {
  constructor(t2, e) {
    super(
      t2,
      e,
      /* forceOwnership= */
      false
    ), this.Qo = t2, this.cacheSizeBytes = e, this.synchronizeTabs = true;
  }
  async initialize(t2) {
    await super.initialize(t2);
    const e = this.Qo.syncEngine;
    this.sharedClientState instanceof Cr && (this.sharedClientState.syncEngine = {
      ui: dc2.bind(null, e),
      ai: yc.bind(null, e),
      hi: pc2.bind(null, e),
      fn: gc2.bind(null, e),
      ci: fc2.bind(null, e)
    }, await this.sharedClientState.start()), // NOTE: This will immediately call the listener, so we make sure to
    // set it after localStore / remoteStore are started.
    await this.persistence.He(async (t3) => {
      await wc2(this.Qo.syncEngine, t3), this.gcScheduler && (t3 && !this.gcScheduler.started ? this.gcScheduler.start(this.localStore) : t3 || this.gcScheduler.stop());
    });
  }
  Bo(t2) {
    const e = Mr();
    if (!Cr.gt(e))
      throw new D2(S2.UNIMPLEMENTED, "IndexedDB persistence is only available on platforms that support LocalStorage.");
    const n2 = ji(t2.databaseInfo.databaseId, t2.databaseInfo.persistenceKey);
    return new Cr(e, t2.asyncQueue, n2, t2.clientId, t2.initialUser);
  }
};
var bc2 = class {
  async initialize(t2, e) {
    this.localStore || (this.localStore = t2.localStore, this.sharedClientState = t2.sharedClientState, this.datastore = this.createDatastore(e), this.remoteStore = this.createRemoteStore(e), this.eventManager = this.createEventManager(e), this.syncEngine = this.createSyncEngine(
      e,
      /* startAsPrimary=*/
      !t2.synchronizeTabs
    ), this.sharedClientState.onlineStateHandler = (t3) => Jo(
      this.syncEngine,
      t3,
      1
      /* SharedClientState */
    ), this.remoteStore.remoteSyncer.handleCredentialChange = ac2.bind(null, this.syncEngine), await po(this.remoteStore, this.syncEngine.isPrimaryClient));
  }
  createEventManager(t2) {
    return new Vo();
  }
  createDatastore(t2) {
    const e = Br(t2.databaseInfo.databaseId), n2 = (s = t2.databaseInfo, new Fr(s));
    var s;
    return function(t3, e2, n3) {
      return new jr(t3, e2, n3);
    }(t2.credentials, n2, e);
  }
  createRemoteStore(t2) {
    return e = this.localStore, n2 = this.datastore, s = t2.asyncQueue, i = (t3) => Jo(
      this.syncEngine,
      t3,
      0
      /* RemoteStore */
    ), r2 = kr.gt() ? new kr() : new xr(), new Gr(e, n2, s, i, r2);
    var e, n2, s, i, r2;
  }
  createSyncEngine(t2, e) {
    return function(t3, e2, n2, s, i, r2, o) {
      const c = new Qo(t3, e2, n2, s, i, r2);
      return o && (c.Oo = true), c;
    }(this.localStore, this.remoteStore, this.eventManager, this.sharedClientState, t2.initialUser, t2.maxConcurrentLimboResolutions, e);
  }
  terminate() {
    return async function(t2) {
      const e = B(t2);
      k2("RemoteStore", "RemoteStore shutting down."), e.Fr.add(
        5
        /* Shutdown */
      ), await Hr(e), e.Lr.shutdown(), // Set the OnlineState to Unknown (rather than Offline) to avoid potentially
      // triggering spurious listener events with cached data, etc.
      e.Br.set(
        "Unknown"
        /* Unknown */
      );
    }(this.remoteStore);
  }
};
function vc2(t2, e = 10240) {
  let n2 = 0;
  return {
    async read() {
      if (n2 < t2.byteLength) {
        const s = {
          value: t2.slice(n2, n2 + e),
          done: false
        };
        return n2 += e, s;
      }
      return {
        done: true
      };
    },
    async cancel() {
    },
    releaseLock() {
    },
    closed: Promise.reject("unimplemented")
  };
}
var Vc2 = class {
  constructor(t2) {
    this.observer = t2, /**
     * When set to true, will not raise future events. Necessary to deal with
     * async detachment of listener.
     */
    this.muted = false;
  }
  next(t2) {
    this.observer.next && this.jo(this.observer.next, t2);
  }
  error(t2) {
    this.observer.error ? this.jo(this.observer.error, t2) : console.error("Uncaught Error in snapshot listener:", t2);
  }
  Wo() {
    this.muted = true;
  }
  jo(t2, e) {
    this.muted || setTimeout(() => {
      this.muted || t2(e);
    }, 0);
  }
};
var Sc2 = class {
  constructor(t2, e) {
    this.Go = t2, this.R = e, /** Cached bundle metadata. */
    this.metadata = new Cs(), /**
     * Internal buffer to hold bundle content, accumulating incomplete element
     * content.
     */
    this.buffer = new Uint8Array(), this.zo = new TextDecoder("utf-8"), // Read the metadata (which is the first element).
    this.Ho().then((t3) => {
      t3 && t3.io() ? this.metadata.resolve(t3.payload.metadata) : this.metadata.reject(new Error(`The first element of the bundle is not a metadata, it is
             ${JSON.stringify(null == t3 ? void 0 : t3.payload)}`));
    }, (t3) => this.metadata.reject(t3));
  }
  close() {
    return this.Go.cancel();
  }
  async getMetadata() {
    return this.metadata.promise;
  }
  async Lo() {
    return await this.getMetadata(), this.Ho();
  }
  /**
   * Reads from the head of internal buffer, and pulling more data from
   * underlying stream if a complete element cannot be found, until an
   * element(including the prefixed length and the JSON string) is found.
   *
   * Once a complete element is read, it is dropped from internal buffer.
   *
   * Returns either the bundled element, or null if we have reached the end of
   * the stream.
   */
  async Ho() {
    const t2 = await this.Jo();
    if (null === t2)
      return null;
    const e = this.zo.decode(t2), n2 = Number(e);
    isNaN(n2) && this.Yo(`length string (${e}) is not valid number`);
    const s = await this.Xo(n2);
    return new $o(JSON.parse(s), t2.length + n2);
  }
  /** First index of '{' from the underlying buffer. */
  Zo() {
    return this.buffer.findIndex((t2) => t2 === "{".charCodeAt(0));
  }
  /**
   * Reads from the beginning of the internal buffer, until the first '{', and
   * return the content.
   *
   * If reached end of the stream, returns a null.
   */
  async Jo() {
    for (; this.Zo() < 0; ) {
      if (await this.tc())
        break;
    }
    if (0 === this.buffer.length)
      return null;
    const t2 = this.Zo();
    t2 < 0 && this.Yo("Reached the end of bundle when a length string is expected.");
    const e = this.buffer.slice(0, t2);
    return this.buffer = this.buffer.slice(t2), e;
  }
  /**
   * Reads from a specified position from the internal buffer, for a specified
   * number of bytes, pulling more data from the underlying stream if needed.
   *
   * Returns a string decoded from the read bytes.
   */
  async Xo(t2) {
    for (; this.buffer.length < t2; ) {
      await this.tc() && this.Yo("Reached the end of bundle when more is expected.");
    }
    const e = this.zo.decode(this.buffer.slice(0, t2));
    return this.buffer = this.buffer.slice(t2), e;
  }
  Yo(t2) {
    throw this.Go.cancel(), new Error(`Invalid bundle format: ${t2}`);
  }
  /**
   * Pulls more data from underlying stream to internal buffer.
   * Returns a boolean indicating whether the stream is finished.
   */
  async tc() {
    const t2 = await this.Go.read();
    if (!t2.done) {
      const e = new Uint8Array(this.buffer.length + t2.value.length);
      e.set(this.buffer), e.set(t2.value, this.buffer.length), this.buffer = e;
    }
    return t2.done;
  }
};
var Dc2 = class {
  constructor(t2) {
    this.datastore = t2, // The version of each document that was read during this transaction.
    this.readVersions = /* @__PURE__ */ new Map(), this.mutations = [], this.committed = false, /**
     * A deferred usage error that occurred previously in this transaction that
     * will cause the transaction to fail once it actually commits.
     */
    this.lastWriteError = null, /**
     * Set of documents that have been written in the transaction.
     *
     * When there's more than one write to the same key in a transaction, any
     * writes after the first are handled differently.
     */
    this.writtenDocs = /* @__PURE__ */ new Set();
  }
  async lookup(t2) {
    if (this.ensureCommitNotCalled(), this.mutations.length > 0)
      throw new D2(S2.INVALID_ARGUMENT, "Firestore transactions require all reads to be executed before all writes.");
    const e = await async function(t3, e2) {
      const n2 = B(t3), s = Mn(n2.R) + "/documents", i = {
        documents: e2.map((t4) => kn(n2.R, t4))
      }, r2 = await n2.Oi("BatchGetDocuments", s, i), o = /* @__PURE__ */ new Map();
      r2.forEach((t4) => {
        const e3 = qn(n2.R, t4);
        o.set(e3.key.toString(), e3);
      });
      const c = [];
      return e2.forEach((t4) => {
        const e3 = o.get(t4.toString());
        L2(!!e3), c.push(e3);
      }), c;
    }(this.datastore, t2);
    return e.forEach((t3) => this.recordVersion(t3)), e;
  }
  set(t2, e) {
    this.write(e.toMutation(t2, this.precondition(t2))), this.writtenDocs.add(t2.toString());
  }
  update(t2, e) {
    try {
      this.write(e.toMutation(t2, this.preconditionForUpdate(t2)));
    } catch (t3) {
      this.lastWriteError = t3;
    }
    this.writtenDocs.add(t2.toString());
  }
  delete(t2) {
    this.write(new Ge(t2, this.precondition(t2))), this.writtenDocs.add(t2.toString());
  }
  async commit() {
    if (this.ensureCommitNotCalled(), this.lastWriteError)
      throw this.lastWriteError;
    const t2 = this.readVersions;
    this.mutations.forEach((e) => {
      t2.delete(e.key.toString());
    }), // For each document that was read but not written to, we want to perform
    // a `verify` operation.
    t2.forEach((t3, e) => {
      const n2 = dt.fromPath(e);
      this.mutations.push(new ze(n2, this.precondition(n2)));
    }), await async function(t3, e) {
      const n2 = B(t3), s = Mn(n2.R) + "/documents", i = {
        writes: e.map((t4) => Qn(n2.R, t4))
      };
      await n2.Ni("Commit", s, i);
    }(this.datastore, this.mutations), this.committed = true;
  }
  recordVersion(t2) {
    let e;
    if (t2.isFoundDocument())
      e = t2.version;
    else {
      if (!t2.isNoDocument())
        throw M2();
      e = G2.min();
    }
    const n2 = this.readVersions.get(t2.key.toString());
    if (n2) {
      if (!e.isEqual(n2))
        throw new D2(S2.ABORTED, "Document version changed between two reads.");
    } else
      this.readVersions.set(t2.key.toString(), e);
  }
  /**
   * Returns the version of this document when it was read in this transaction,
   * as a precondition, or no precondition if it was not read.
   */
  precondition(t2) {
    const e = this.readVersions.get(t2.toString());
    return !this.writtenDocs.has(t2.toString()) && e ? ke.updateTime(e) : ke.none();
  }
  /**
   * Returns the precondition for a document if the operation is an update.
   */
  preconditionForUpdate(t2) {
    const e = this.readVersions.get(t2.toString());
    if (!this.writtenDocs.has(t2.toString()) && e) {
      if (e.isEqual(G2.min()))
        throw new D2(S2.INVALID_ARGUMENT, "Can't update a document that doesn't exist.");
      return ke.updateTime(e);
    }
    return ke.exists(true);
  }
  write(t2) {
    this.ensureCommitNotCalled(), this.mutations.push(t2);
  }
  ensureCommitNotCalled() {
  }
};
var Cc = class {
  constructor(t2, e, n2, s) {
    this.asyncQueue = t2, this.datastore = e, this.updateFunction = n2, this.deferred = s, this.ec = 5, this.Zi = new Ur(
      this.asyncQueue,
      "transaction_retry"
      /* TransactionRetry */
    );
  }
  /** Runs the transaction and sets the result on deferred. */
  run() {
    this.ec -= 1, this.nc();
  }
  nc() {
    this.Zi.ji(async () => {
      const t2 = new Dc2(this.datastore), e = this.sc(t2);
      e && e.then((e2) => {
        this.asyncQueue.enqueueAndForget(() => t2.commit().then(() => {
          this.deferred.resolve(e2);
        }).catch((t3) => {
          this.ic(t3);
        }));
      }).catch((t3) => {
        this.ic(t3);
      });
    });
  }
  sc(t2) {
    try {
      const e = this.updateFunction(t2);
      return !ht(e) && e.catch && e.then ? e : (this.deferred.reject(Error("Transaction callback must return a Promise")), null);
    } catch (t3) {
      return this.deferred.reject(t3), null;
    }
  }
  ic(t2) {
    this.ec > 0 && this.rc(t2) ? (this.ec -= 1, this.asyncQueue.enqueueAndForget(() => (this.nc(), Promise.resolve()))) : this.deferred.reject(t2);
  }
  rc(t2) {
    if ("FirebaseError" === t2.name) {
      const e = t2.code;
      return "aborted" === e || "failed-precondition" === e || !Xe(e);
    }
    return false;
  }
};
var Nc2 = class {
  constructor(t2, e, n2) {
    this.credentials = t2, this.asyncQueue = e, this.databaseInfo = n2, this.user = Ir.UNAUTHENTICATED, this.clientId = q2.u(), this.credentialListener = () => Promise.resolve(), this.credentials.setChangeListener(e, async (t3) => {
      k2("FirestoreClient", "Received user=", t3.uid), await this.credentialListener(t3), this.user = t3;
    });
  }
  async getConfiguration() {
    return {
      asyncQueue: this.asyncQueue,
      databaseInfo: this.databaseInfo,
      clientId: this.clientId,
      credentials: this.credentials,
      initialUser: this.user,
      maxConcurrentLimboResolutions: 100
    };
  }
  setCredentialChangeListener(t2) {
    this.credentialListener = t2;
  }
  /**
   * Checks that the client has not been terminated. Ensures that other methods on
   * this class cannot be called after the client is terminated.
   */
  verifyNotTerminated() {
    if (this.asyncQueue.isShuttingDown)
      throw new D2(S2.FAILED_PRECONDITION, "The client has already been terminated.");
  }
  terminate() {
    this.asyncQueue.enterRestrictedMode();
    const t2 = new Cs();
    return this.asyncQueue.enqueueAndForgetEvenWhileRestricted(async () => {
      try {
        this.onlineComponents && await this.onlineComponents.terminate(), this.offlineComponents && await this.offlineComponents.terminate(), // `removeChangeListener` must be called after shutting down the
        // RemoteStore as it will prevent the RemoteStore from retrieving
        // auth tokens.
        this.credentials.removeChangeListener(), t2.resolve();
      } catch (e) {
        const n2 = Ao(e, "Failed to shutdown persistence");
        t2.reject(n2);
      }
    }), t2.promise;
  }
};
async function xc2(t2, e) {
  t2.asyncQueue.verifyOperationInProgress(), k2("FirestoreClient", "Initializing OfflineComponentProvider");
  const n2 = await t2.getConfiguration();
  await e.initialize(n2);
  let s = n2.initialUser;
  t2.setCredentialChangeListener(async (t3) => {
    s.isEqual(t3) || (await Xi(e.localStore, t3), s = t3);
  }), // When a user calls clearPersistence() in one client, all other clients
  // need to be terminated to allow the delete to succeed.
  e.persistence.setDatabaseDeletedListener(() => t2.terminate()), t2.offlineComponents = e;
}
async function kc2(t2, e) {
  t2.asyncQueue.verifyOperationInProgress();
  const n2 = await $c2(t2);
  k2("FirestoreClient", "Initializing OnlineComponentProvider");
  const s = await t2.getConfiguration();
  await e.initialize(n2, s), // The CredentialChangeListener of the online component provider takes
  // precedence over the offline component provider.
  t2.setCredentialChangeListener((t3) => async function(t4, e2) {
    const n3 = B(t4);
    n3.asyncQueue.verifyOperationInProgress(), k2("RemoteStore", "RemoteStore received new credentials");
    const s2 = no(n3);
    n3.Fr.add(
      3
      /* CredentialChange */
    ), await Hr(n3), s2 && // Don't set the network status to Unknown if we are offline.
    n3.Br.set(
      "Unknown"
      /* Unknown */
    ), await n3.remoteSyncer.handleCredentialChange(e2), n3.Fr.delete(
      3
      /* CredentialChange */
    ), await zr(n3);
  }(e.remoteStore, t3)), t2.onlineComponents = e;
}
async function $c2(t2) {
  return t2.offlineComponents || (k2("FirestoreClient", "Using default OfflineComponentProvider"), await xc2(t2, new Ac2())), t2.offlineComponents;
}
async function Oc2(t2) {
  return t2.onlineComponents || (k2("FirestoreClient", "Using default OnlineComponentProvider"), await kc2(t2, new bc2())), t2.onlineComponents;
}
function Fc2(t2) {
  return $c2(t2).then((t3) => t3.persistence);
}
function Mc2(t2) {
  return $c2(t2).then((t3) => t3.localStore);
}
function Lc2(t2) {
  return Oc2(t2).then((t3) => t3.remoteStore);
}
function Bc2(t2) {
  return Oc2(t2).then((t3) => t3.syncEngine);
}
async function Uc2(t2) {
  const e = await Oc2(t2), n2 = e.eventManager;
  return n2.onListen = jo.bind(null, e.syncEngine), n2.onUnlisten = Go.bind(null, e.syncEngine), n2;
}
function qc2(t2) {
  return t2.asyncQueue.enqueue(async () => {
    const e = await Fc2(t2), n2 = await Lc2(t2);
    return e.setNetworkEnabled(true), function(t3) {
      const e2 = B(t3);
      return e2.Fr.delete(
        0
        /* UserDisabled */
      ), zr(e2);
    }(n2);
  });
}
function Kc2(t2) {
  return t2.asyncQueue.enqueue(async () => {
    const e = await Fc2(t2), n2 = await Lc2(t2);
    return e.setNetworkEnabled(false), async function(t3) {
      const e2 = B(t3);
      e2.Fr.add(
        0
        /* UserDisabled */
      ), await Hr(e2), // Set the OnlineState to Offline so get()s return from cache, etc.
      e2.Br.set(
        "Offline"
        /* Offline */
      );
    }(n2);
  });
}
function Qc2(t2, e) {
  const n2 = new Cs();
  return t2.asyncQueue.enqueueAndForget(async () => async function(t3, e2, n3) {
    try {
      const s = await function(t4, e3) {
        const n4 = B(t4);
        return n4.persistence.runTransaction("read document", "readonly", (t5) => n4.Mn.mn(t5, e3));
      }(t3, e2);
      s.isFoundDocument() ? n3.resolve(s) : s.isNoDocument() ? n3.resolve(null) : n3.reject(new D2(S2.UNAVAILABLE, "Failed to get document from cache. (However, this document may exist on the server. Run again without setting 'source' in the GetOptions to attempt to retrieve the document from the server.)"));
    } catch (t4) {
      const s = Ao(t4, `Failed to get document '${e2} from cache`);
      n3.reject(s);
    }
  }(await Mc2(t2), e, n2)), n2.promise;
}
function jc2(t2, e, n2 = {}) {
  const s = new Cs();
  return t2.asyncQueue.enqueueAndForget(async () => function(t3, e2, n3, s2, i) {
    const r2 = new Vc2({
      next: (r3) => {
        e2.enqueueAndForget(() => Do(t3, o));
        const c = r3.docs.has(n3);
        !c && r3.fromCache ? (
          // TODO(dimond): If we're online and the document doesn't
          // exist then we resolve with a doc.exists set to false. If
          // we're offline however, we reject the Promise in this
          // case. Two options: 1) Cache the negative response from
          // the server so we can deliver that even when you're
          // offline 2) Actually reject the Promise in the online case
          // if the document doesn't exist.
          i.reject(new D2(S2.UNAVAILABLE, "Failed to get document because the client is offline."))
        ) : c && r3.fromCache && s2 && "server" === s2.source ? i.reject(new D2(S2.UNAVAILABLE, 'Failed to get document from server. (However, this document does exist in the local cache. Run again without setting source to "server" to retrieve the cached document.)')) : i.resolve(r3);
      },
      error: (t4) => i.reject(t4)
    }), o = new ko(ee(n3.path), r2, {
      includeMetadataChanges: true,
      so: true
    });
    return So(t3, o);
  }(await Uc2(t2), t2.asyncQueue, e, n2, s)), s.promise;
}
function Wc2(t2, e) {
  const n2 = new Cs();
  return t2.asyncQueue.enqueueAndForget(async () => async function(t3, e2, n3) {
    try {
      const s = await or(
        t3,
        e2,
        /* usePreviousResults= */
        true
      ), i = new Uo(e2, s.Bn), r2 = i._o(s.documents), o = i.applyChanges(
        r2,
        /* updateLimboDocuments= */
        false
      );
      n3.resolve(o.snapshot);
    } catch (t4) {
      const s = Ao(t4, `Failed to execute query '${e2} against cache`);
      n3.reject(s);
    }
  }(await Mc2(t2), e, n2)), n2.promise;
}
function Gc2(t2, e, n2 = {}) {
  const s = new Cs();
  return t2.asyncQueue.enqueueAndForget(async () => function(t3, e2, n3, s2, i) {
    const r2 = new Vc2({
      next: (n4) => {
        e2.enqueueAndForget(() => Do(t3, o)), n4.fromCache && "server" === s2.source ? i.reject(new D2(S2.UNAVAILABLE, 'Failed to get documents from server. (However, these documents may exist in the local cache. Run again without setting source to "server" to retrieve the cached documents.)')) : i.resolve(n4);
      },
      error: (t4) => i.reject(t4)
    }), o = new ko(n3, r2, {
      includeMetadataChanges: true,
      so: true
    });
    return So(t3, o);
  }(await Uc2(t2), t2.asyncQueue, e, n2, s)), s.promise;
}
function zc2(t2, e) {
  const n2 = new Vc2(e);
  return t2.asyncQueue.enqueueAndForget(async () => function(t3, e2) {
    B(t3).Gr.add(e2), // Immediately fire an initial event, indicating all existing listeners
    // are in-sync.
    e2.next();
  }(await Uc2(t2), n2)), () => {
    n2.Wo(), t2.asyncQueue.enqueueAndForget(async () => function(t3, e2) {
      B(t3).Gr.delete(e2);
    }(await Uc2(t2), n2));
  };
}
function Hc2(t2, e) {
  const n2 = new Cs();
  return t2.asyncQueue.enqueueAndForget(async () => {
    const s = await function(t3) {
      return Oc2(t3).then((t4) => t4.datastore);
    }(t2);
    new Cc(t2.asyncQueue, s, e, n2).run();
  }), n2.promise;
}
function Jc2(t2, e, n2, s) {
  const i = function(t3, e2) {
    let n3;
    n3 = "string" == typeof t3 ? new TextEncoder().encode(t3) : t3;
    return function(t4, e3) {
      return new Sc2(t4, e3);
    }(function(t4, e3) {
      if (t4 instanceof Uint8Array)
        return vc2(t4, e3);
      if (t4 instanceof ArrayBuffer)
        return vc2(new Uint8Array(t4), e3);
      if (t4 instanceof ReadableStream)
        return t4.getReader();
      throw new Error("Source of `toByteStreamReader` has to be a ArrayBuffer or ReadableStream");
    }(n3), e2);
  }(n2, Br(e));
  t2.asyncQueue.enqueueAndForget(async () => {
    Ic2(await Bc2(t2), i, s);
  });
}
function Yc2(t2, e) {
  return t2.asyncQueue.enqueue(async () => function(t3, e2) {
    const n2 = B(t3);
    return n2.persistence.runTransaction("Get named query", "readonly", (t4) => n2.Ke.getNamedQuery(t4, e2));
  }(await Mc2(t2), e));
}
var Xc2 = class {
  /**
   * Constructs a DatabaseInfo using the provided host, databaseId and
   * persistenceKey.
   *
   * @param databaseId - The database to use.
   * @param appId - The Firebase App Id.
   * @param persistenceKey - A unique identifier for this Firestore's local
   * storage (used in conjunction with the databaseId).
   * @param host - The Firestore backend host to connect to.
   * @param ssl - Whether to use SSL when connecting.
   * @param forceLongPolling - Whether to use the forceLongPolling option
   * when using WebChannel as the network transport.
   * @param autoDetectLongPolling - Whether to use the detectBufferingProxy
   * option when using WebChannel as the network transport.
   * @param useFetchStreams Whether to use the Fetch API instead of
   * XMLHTTPRequest
   */
  constructor(t2, e, n2, s, i, r2, o, c) {
    this.databaseId = t2, this.appId = e, this.persistenceKey = n2, this.host = s, this.ssl = i, this.forceLongPolling = r2, this.autoDetectLongPolling = o, this.useFetchStreams = c;
  }
};
var Zc2 = class {
  constructor(t2, e) {
    this.projectId = t2, this.database = e || "(default)";
  }
  get isDefaultDatabase() {
    return "(default)" === this.database;
  }
  isEqual(t2) {
    return t2 instanceof Zc2 && t2.projectId === this.projectId && t2.database === this.database;
  }
};
var tu = /* @__PURE__ */ new Map();
var eu = class {
  constructor(t2, e) {
    this.user = e, this.type = "OAuth", this.authHeaders = {}, // Set the headers using Object Literal notation to avoid minification
    this.authHeaders.Authorization = `Bearer ${t2}`;
  }
};
var nu = class {
  constructor() {
    this.changeListener = null;
  }
  getToken() {
    return Promise.resolve(null);
  }
  invalidateToken() {
  }
  setChangeListener(t2, e) {
    this.changeListener = e, // Fire with initial user.
    t2.enqueueRetryable(() => e(Ir.UNAUTHENTICATED));
  }
  removeChangeListener() {
    this.changeListener = null;
  }
};
var su = class {
  constructor(t2) {
    this.token = t2, /**
     * Stores the listener registered with setChangeListener()
     * This isn't actually necessary since the UID never changes, but we use this
     * to verify the listen contract is adhered to in tests.
     */
    this.changeListener = null;
  }
  getToken() {
    return Promise.resolve(this.token);
  }
  invalidateToken() {
  }
  setChangeListener(t2, e) {
    this.changeListener = e, // Fire with initial user.
    t2.enqueueRetryable(() => e(this.token.user));
  }
  removeChangeListener() {
    this.changeListener = null;
  }
};
var iu = class {
  constructor(t2) {
    this.currentUser = Ir.UNAUTHENTICATED, /** Promise that allows blocking on the initialization of Firebase Auth. */
    this.oc = new Cs(), /**
     * Counter used to detect if the token changed while a getToken request was
     * outstanding.
     */
    this.cc = 0, this.forceRefresh = false, this.auth = null, this.asyncQueue = null, this.uc = () => {
      this.cc++, this.currentUser = this.ac(), this.oc.resolve(), this.changeListener && this.asyncQueue.enqueueRetryable(() => this.changeListener(this.currentUser));
    };
    const e = (t3) => {
      k2("FirebaseCredentialsProvider", "Auth detected"), this.auth = t3, this.auth.addAuthTokenListener(this.uc);
    };
    t2.onInit((t3) => e(t3)), // Our users can initialize Auth right after Firestore, so we give it
    // a chance to register itself with the component framework before we
    // determine whether to start up in unauthenticated mode.
    setTimeout(() => {
      if (!this.auth) {
        const n2 = t2.getImmediate({
          optional: true
        });
        n2 ? e(n2) : (
          // If auth is still not available, proceed with `null` user
          (k2("FirebaseCredentialsProvider", "Auth not yet detected"), this.oc.resolve())
        );
      }
    }, 0);
  }
  getToken() {
    const t2 = this.cc, e = this.forceRefresh;
    return this.forceRefresh = false, this.auth ? this.auth.getToken(e).then((e2) => (
      // Cancel the request since the token changed while the request was
      // outstanding so the response is potentially for a previous user (which
      // user, we can't be sure).
      this.cc !== t2 ? (k2("FirebaseCredentialsProvider", "getToken aborted due to token change."), this.getToken()) : e2 ? (L2("string" == typeof e2.accessToken), new eu(e2.accessToken, this.currentUser)) : null
    )) : Promise.resolve(null);
  }
  invalidateToken() {
    this.forceRefresh = true;
  }
  setChangeListener(t2, e) {
    this.asyncQueue = t2, // Blocks the AsyncQueue until the next user is available.
    this.asyncQueue.enqueueRetryable(async () => {
      await this.oc.promise, await e(this.currentUser), this.changeListener = e;
    });
  }
  removeChangeListener() {
    this.auth && this.auth.removeAuthTokenListener(this.uc), this.changeListener = () => Promise.resolve();
  }
  // Auth.getUid() can return null even with a user logged in. It is because
  // getUid() is synchronous, but the auth code populating Uid is asynchronous.
  // This method should only be called in the AuthTokenListener callback
  // to guarantee to get the actual user.
  ac() {
    const t2 = this.auth && this.auth.getUid();
    return L2(null === t2 || "string" == typeof t2), new Ir(t2);
  }
};
var ru = class {
  constructor(t2, e, n2) {
    this.hc = t2, this.lc = e, this.fc = n2, this.type = "FirstParty", this.user = Ir.FIRST_PARTY;
  }
  get authHeaders() {
    const t2 = {
      "X-Goog-AuthUser": this.lc
    }, e = this.hc.auth.getAuthHeaderValueForFirstParty([]);
    return e && (t2.Authorization = e), this.fc && (t2["X-Goog-Iam-Authorization-Token"] = this.fc), t2;
  }
};
var ou = class {
  constructor(t2, e, n2) {
    this.hc = t2, this.lc = e, this.fc = n2;
  }
  getToken() {
    return Promise.resolve(new ru(this.hc, this.lc, this.fc));
  }
  setChangeListener(t2, e) {
    t2.enqueueRetryable(() => e(Ir.FIRST_PARTY));
  }
  removeChangeListener() {
  }
  invalidateToken() {
  }
};
function cu(t2, e, n2) {
  if (!n2)
    throw new D2(S2.INVALID_ARGUMENT, `Function ${t2}() cannot be called with an empty ${e}.`);
}
function uu(t2) {
  if (!dt.isDocumentKey(t2))
    throw new D2(S2.INVALID_ARGUMENT, `Invalid document reference. Document references must have an even number of segments, but ${t2} has ${t2.length}.`);
}
function au(t2) {
  if (dt.isDocumentKey(t2))
    throw new D2(S2.INVALID_ARGUMENT, `Invalid collection reference. Collection references must have an odd number of segments, but ${t2} has ${t2.length}.`);
}
function hu(t2) {
  if (void 0 === t2)
    return "undefined";
  if (null === t2)
    return "null";
  if ("string" == typeof t2)
    return t2.length > 20 && (t2 = `${t2.substring(0, 20)}...`), JSON.stringify(t2);
  if ("number" == typeof t2 || "boolean" == typeof t2)
    return "" + t2;
  if ("object" == typeof t2) {
    if (t2 instanceof Array)
      return "an array";
    {
      const e = (
        /** Hacky method to try to get the constructor name for an object. */
        function(t3) {
          if (t3.constructor) {
            const e2 = /function\s+([^\s(]+)\s*\(/.exec(t3.constructor.toString());
            if (e2 && e2.length > 1)
              return e2[1];
          }
          return null;
        }(t2)
      );
      return e ? `a custom ${e} object` : "an object";
    }
  }
  return "function" == typeof t2 ? "a function" : M2();
}
function lu(t2, e) {
  if ("_delegate" in t2 && // Unwrap Compat types
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  (t2 = t2._delegate), !(t2 instanceof e)) {
    if (e.name === t2.constructor.name)
      throw new D2(S2.INVALID_ARGUMENT, "Type does not match the expected instance. Did you pass a reference from a different Firestore SDK?");
    {
      const n2 = hu(t2);
      throw new D2(S2.INVALID_ARGUMENT, `Expected type '${e.name}', but it was: ${n2}`);
    }
  }
  return t2;
}
function fu(t2, e) {
  if (e <= 0)
    throw new D2(S2.INVALID_ARGUMENT, `Function ${t2}() requires a positive number, but it was: ${e}.`);
}
var du = class {
  constructor(t2) {
    var e;
    if (void 0 === t2.host) {
      if (void 0 !== t2.ssl)
        throw new D2(S2.INVALID_ARGUMENT, "Can't provide ssl option if host option is not set");
      this.host = "firestore.googleapis.com", this.ssl = true;
    } else
      this.host = t2.host, this.ssl = null === (e = t2.ssl) || void 0 === e || e;
    if (this.credentials = t2.credentials, this.ignoreUndefinedProperties = !!t2.ignoreUndefinedProperties, void 0 === t2.cacheSizeBytes)
      this.cacheSizeBytes = 41943040;
    else {
      if (-1 !== t2.cacheSizeBytes && t2.cacheSizeBytes < 1048576)
        throw new D2(S2.INVALID_ARGUMENT, "cacheSizeBytes must be at least 1048576");
      this.cacheSizeBytes = t2.cacheSizeBytes;
    }
    this.experimentalForceLongPolling = !!t2.experimentalForceLongPolling, this.experimentalAutoDetectLongPolling = !!t2.experimentalAutoDetectLongPolling, this.useFetchStreams = !!t2.useFetchStreams, function(t3, e2, n2, s) {
      if (true === e2 && true === s)
        throw new D2(S2.INVALID_ARGUMENT, `${t3} and ${n2} cannot be used together.`);
    }("experimentalForceLongPolling", t2.experimentalForceLongPolling, "experimentalAutoDetectLongPolling", t2.experimentalAutoDetectLongPolling);
  }
  isEqual(t2) {
    return this.host === t2.host && this.ssl === t2.ssl && this.credentials === t2.credentials && this.cacheSizeBytes === t2.cacheSizeBytes && this.experimentalForceLongPolling === t2.experimentalForceLongPolling && this.experimentalAutoDetectLongPolling === t2.experimentalAutoDetectLongPolling && this.ignoreUndefinedProperties === t2.ignoreUndefinedProperties && this.useFetchStreams === t2.useFetchStreams;
  }
};
var wu = class {
  /** @hideconstructor */
  constructor(t2, e) {
    this.type = "firestore-lite", this._persistenceKey = "(lite)", this._settings = new du({}), this._settingsFrozen = false, t2 instanceof Zc2 ? (this._databaseId = t2, this._credentials = new nu()) : (this._app = t2, this._databaseId = function(t3) {
      if (!Object.prototype.hasOwnProperty.apply(t3.options, ["projectId"]))
        throw new D2(S2.INVALID_ARGUMENT, '"projectId" not provided in firebase.initializeApp.');
      return new Zc2(t3.options.projectId);
    }(t2), this._credentials = new iu(e));
  }
  /**
   * The {@link @firebase/app#FirebaseApp} associated with this `Firestore` service
   * instance.
   */
  get app() {
    if (!this._app)
      throw new D2(S2.FAILED_PRECONDITION, "Firestore was not initialized using the Firebase SDK. 'app' is not available");
    return this._app;
  }
  get _initialized() {
    return this._settingsFrozen;
  }
  get _terminated() {
    return void 0 !== this._terminateTask;
  }
  _setSettings(t2) {
    if (this._settingsFrozen)
      throw new D2(S2.FAILED_PRECONDITION, "Firestore has already been started and its settings can no longer be changed. You can only modify settings before calling any other methods on a Firestore object.");
    this._settings = new du(t2), void 0 !== t2.credentials && (this._credentials = function(t3) {
      if (!t3)
        return new nu();
      switch (t3.type) {
        case "gapi":
          const e = t3.client;
          return L2(!("object" != typeof e || null === e || !e.auth || !e.auth.getAuthHeaderValueForFirstParty)), new ou(e, t3.sessionIndex || "0", t3.iamToken || null);
        case "provider":
          return t3.client;
        default:
          throw new D2(S2.INVALID_ARGUMENT, "makeCredentialsProvider failed due to invalid credential type");
      }
    }(t2.credentials));
  }
  _getSettings() {
    return this._settings;
  }
  _freezeSettings() {
    return this._settingsFrozen = true, this._settings;
  }
  _delete() {
    return this._terminateTask || (this._terminateTask = this._terminate()), this._terminateTask;
  }
  /** Returns a JSON-serializable representation of this Firestore instance. */
  toJSON() {
    return {
      app: this._app,
      databaseId: this._databaseId,
      settings: this._settings
    };
  }
  /**
   * Terminates all components used by this client. Subclasses can override
   * this method to clean up their own dependencies, but must also call this
   * method.
   *
   * Only ever called once.
   */
  _terminate() {
    return function(t2) {
      const e = tu.get(t2);
      e && (k2("ComponentProvider", "Removing Datastore"), tu.delete(t2), e.terminate());
    }(this), Promise.resolve();
  }
};
function _u(t2, e, n2, s = {}) {
  const i = (t2 = lu(t2, wu))._getSettings();
  if ("firestore.googleapis.com" !== i.host && i.host !== e && O2("Host has been set in both settings() and useEmulator(), emulator host will be used"), t2._setSettings(Object.assign(Object.assign({}, i), {
    host: `${e}:${n2}`,
    ssl: false
  })), s.mockUserToken) {
    const e2 = createMockUserToken(s.mockUserToken), n3 = s.mockUserToken.sub || s.mockUserToken.user_id;
    if (!n3)
      throw new D2(S2.INVALID_ARGUMENT, "mockUserToken must contain 'sub' or 'user_id' field!");
    t2._credentials = new su(new eu(e2, new Ir(n3)));
  }
}
var mu = class {
  /** @hideconstructor */
  constructor(t2, e, n2) {
    this.converter = e, this._key = n2, /** The type of this Firestore reference. */
    this.type = "document", this.firestore = t2;
  }
  get _path() {
    return this._key.path;
  }
  /**
   * The document's identifier within its collection.
   */
  get id() {
    return this._key.path.lastSegment();
  }
  /**
   * A string representing the path of the referenced document (relative
   * to the root of the database).
   */
  get path() {
    return this._key.path.canonicalString();
  }
  /**
   * The collection this `DocumentReference` belongs to.
   */
  get parent() {
    return new yu(this.firestore, this.converter, this._key.path.popLast());
  }
  withConverter(t2) {
    return new mu(this.firestore, t2, this._key);
  }
};
var gu = class {
  // This is the lite version of the Query class in the main SDK.
  /** @hideconstructor protected */
  constructor(t2, e, n2) {
    this.converter = e, this._query = n2, /** The type of this Firestore reference. */
    this.type = "query", this.firestore = t2;
  }
  withConverter(t2) {
    return new gu(this.firestore, t2, this._query);
  }
};
var yu = class extends gu {
  /** @hideconstructor */
  constructor(t2, e, n2) {
    super(t2, e, ee(n2)), this._path = n2, /** The type of this Firestore reference. */
    this.type = "collection";
  }
  /** The collection's identifier. */
  get id() {
    return this._query.path.lastSegment();
  }
  /**
   * A string representing the path of the referenced collection (relative
   * to the root of the database).
   */
  get path() {
    return this._query.path.canonicalString();
  }
  /**
   * A reference to the containing `DocumentReference` if this is a
   * subcollection. If this isn't a subcollection, the reference is null.
   */
  get parent() {
    const t2 = this._path.popLast();
    return t2.isEmpty() ? null : new mu(
      this.firestore,
      /* converter= */
      null,
      new dt(t2)
    );
  }
  withConverter(t2) {
    return new yu(this.firestore, t2, this._path);
  }
};
function pu(t2, e, ...n2) {
  if (t2 = getModularInstance(t2), cu("collection", "path", e), t2 instanceof wu) {
    const s = X2.fromString(e, ...n2);
    return au(s), new yu(
      t2,
      /* converter= */
      null,
      s
    );
  }
  {
    if (!(t2 instanceof mu || t2 instanceof yu))
      throw new D2(S2.INVALID_ARGUMENT, "Expected first argument to collection() to be a CollectionReference, a DocumentReference or FirebaseFirestore");
    const s = X2.fromString(t2.path, ...n2).child(X2.fromString(e));
    return au(s), new yu(
      t2.firestore,
      /* converter= */
      null,
      s
    );
  }
}
function Eu(t2, e) {
  if (t2 = lu(t2, wu), cu("collectionGroup", "collection id", e), e.indexOf("/") >= 0)
    throw new D2(S2.INVALID_ARGUMENT, `Invalid collection ID '${e}' passed to function collectionGroup(). Collection IDs must not contain '/'.`);
  return new gu(
    t2,
    /* converter= */
    null,
    /**
    * Creates a new Query for a collection group query that matches all documents
    * within the provided collection group.
    */
    function(t3) {
      return new Zt(X2.emptyPath(), t3);
    }(e)
  );
}
function Tu(t2, e, ...n2) {
  if (t2 = getModularInstance(t2), // We allow omission of 'pathString' but explicitly prohibit passing in both
  // 'undefined' and 'null'.
  1 === arguments.length && (e = q2.u()), cu("doc", "path", e), t2 instanceof wu) {
    const s = X2.fromString(e, ...n2);
    return uu(s), new mu(
      t2,
      /* converter= */
      null,
      new dt(s)
    );
  }
  {
    if (!(t2 instanceof mu || t2 instanceof yu))
      throw new D2(S2.INVALID_ARGUMENT, "Expected first argument to collection() to be a CollectionReference, a DocumentReference or FirebaseFirestore");
    const s = t2._path.child(X2.fromString(e, ...n2));
    return uu(s), new mu(t2.firestore, t2 instanceof yu ? t2.converter : null, new dt(s));
  }
}
function Iu(t2, e) {
  return t2 = getModularInstance(t2), e = getModularInstance(e), (t2 instanceof mu || t2 instanceof yu) && (e instanceof mu || e instanceof yu) && (t2.firestore === e.firestore && t2.path === e.path && t2.converter === e.converter);
}
function Au(t2, e) {
  return t2 = getModularInstance(t2), e = getModularInstance(e), t2 instanceof gu && e instanceof gu && (t2.firestore === e.firestore && he(t2._query, e._query) && t2.converter === e.converter);
}
var Ru = class {
  constructor() {
    this.dc = Promise.resolve(), // A list of retryable operations. Retryable operations are run in order and
    // retried with backoff.
    this.wc = [], // Is this AsyncQueue being shut down? Once it is set to true, it will not
    // be changed again.
    this._c = false, // Operations scheduled to be queued in the future. Operations are
    // automatically removed after they are run or canceled.
    this.mc = [], // visible for testing
    this.gc = null, // Flag set while there's an outstanding AsyncQueue operation, used for
    // assertion sanity-checks.
    this.yc = false, // List of TimerIds to fast-forward delays for.
    this.Ec = [], // Backoff timer used to schedule retries for retryable operations
    this.Zi = new Ur(
      this,
      "async_queue_retry"
      /* AsyncQueueRetry */
    ), // Visibility handler that triggers an immediate retry of all retryable
    // operations. Meant to speed up recovery when we regain file system access
    // after page comes into foreground.
    this.Tc = () => {
      const t3 = Lr();
      t3 && k2("AsyncQueue", "Visibility state changed to " + t3.visibilityState), this.Zi.Gi();
    };
    const t2 = Lr();
    t2 && "function" == typeof t2.addEventListener && t2.addEventListener("visibilitychange", this.Tc);
  }
  get isShuttingDown() {
    return this._c;
  }
  /**
   * Adds a new operation to the queue without waiting for it to complete (i.e.
   * we ignore the Promise result).
   */
  enqueueAndForget(t2) {
    this.enqueue(t2);
  }
  enqueueAndForgetEvenWhileRestricted(t2) {
    this.Ic(), // eslint-disable-next-line @typescript-eslint/no-floating-promises
    this.Ac(t2);
  }
  enterRestrictedMode() {
    if (!this._c) {
      this._c = true;
      const t2 = Lr();
      t2 && "function" == typeof t2.removeEventListener && t2.removeEventListener("visibilitychange", this.Tc);
    }
  }
  enqueue(t2) {
    return this.Ic(), this._c ? new Promise((t3) => {
    }) : this.Ac(t2);
  }
  enqueueRetryable(t2) {
    this.enqueueAndForget(() => (this.wc.push(t2), this.Rc()));
  }
  /**
   * Runs the next operation from the retryable queue. If the operation fails,
   * reschedules with backoff.
   */
  async Rc() {
    if (0 !== this.wc.length) {
      try {
        await this.wc[0](), this.wc.shift(), this.Zi.reset();
      } catch (t2) {
        if (!Fs(t2))
          throw t2;
        k2("AsyncQueue", "Operation failed with retryable error: " + t2);
      }
      this.wc.length > 0 && // If there are additional operations, we re-schedule `retryNextOp()`.
      // This is necessary to run retryable operations that failed during
      // their initial attempt since we don't know whether they are already
      // enqueued. If, for example, `op1`, `op2`, `op3` are enqueued and `op1`
      // needs to  be re-run, we will run `op1`, `op1`, `op2` using the
      // already enqueued calls to `retryNextOp()`. `op3()` will then run in the
      // call scheduled here.
      // Since `backoffAndRun()` cancels an existing backoff and schedules a
      // new backoff on every call, there is only ever a single additional
      // operation in the queue.
      this.Zi.ji(() => this.Rc());
    }
  }
  Ac(t2) {
    const e = this.dc.then(() => (this.yc = true, t2().catch((t3) => {
      this.gc = t3, this.yc = false;
      throw $(
        "INTERNAL UNHANDLED ERROR: ",
        /**
        * Chrome includes Error.message in Error.stack. Other browsers do not.
        * This returns expected output of message + stack when available.
        * @param error - Error or FirestoreError
        */
        function(t4) {
          let e2 = t4.message || "";
          t4.stack && (e2 = t4.stack.includes(t4.message) ? t4.stack : t4.message + "\n" + t4.stack);
          return e2;
        }(t3)
      ), t3;
    }).then((t3) => (this.yc = false, t3))));
    return this.dc = e, e;
  }
  enqueueAfterDelay(t2, e, n2) {
    this.Ic(), // Fast-forward delays for timerIds that have been overriden.
    this.Ec.indexOf(t2) > -1 && (e = 0);
    const s = Io.createAndSchedule(this, t2, e, n2, (t3) => this.Pc(t3));
    return this.mc.push(s), s;
  }
  Ic() {
    this.gc && M2();
  }
  verifyOperationInProgress() {
  }
  /**
   * Waits until all currently queued tasks are finished executing. Delayed
   * operations are not run.
   */
  async bc() {
    let t2;
    do {
      t2 = this.dc, await t2;
    } while (t2 !== this.dc);
  }
  /**
   * For Tests: Determine if a delayed operation with a particular TimerId
   * exists.
   */
  vc(t2) {
    for (const e of this.mc)
      if (e.timerId === t2)
        return true;
    return false;
  }
  /**
   * For Tests: Runs some or all delayed operations early.
   *
   * @param lastTimerId - Delayed operations up to and including this TimerId
   * will be drained. Pass TimerId.All to run all delayed operations.
   * @returns a Promise that resolves once all operations have been run.
   */
  Vc(t2) {
    return this.bc().then(() => {
      this.mc.sort((t3, e) => t3.targetTimeMs - e.targetTimeMs);
      for (const e of this.mc)
        if (e.skipDelay(), "all" !== t2 && e.timerId === t2)
          break;
      return this.bc();
    });
  }
  /**
   * For Tests: Skip all subsequent delays for a timer id.
   */
  Sc(t2) {
    this.Ec.push(t2);
  }
  /** Called once a DelayedOperation is run or canceled. */
  Pc(t2) {
    const e = this.mc.indexOf(t2);
    this.mc.splice(e, 1);
  }
};
function Pu(t2) {
  return function(t3, e) {
    if ("object" != typeof t3 || null === t3)
      return false;
    const n2 = t3;
    for (const t4 of e)
      if (t4 in n2 && "function" == typeof n2[t4])
        return true;
    return false;
  }(t2, ["next", "error", "complete"]);
}
var bu = class {
  constructor() {
    this._progressObserver = {}, this._taskCompletionResolver = new Cs(), this._lastProgress = {
      taskState: "Running",
      totalBytes: 0,
      totalDocuments: 0,
      bytesLoaded: 0,
      documentsLoaded: 0
    };
  }
  /**
   * Registers functions to listen to bundle loading progress events.
   * @param next - Called when there is a progress update from bundle loading. Typically `next` calls occur
   *   each time a Firestore document is loaded from the bundle.
   * @param error - Called when an error occurs during bundle loading. The task aborts after reporting the
   *   error, and there should be no more updates after this.
   * @param complete - Called when the loading task is complete.
   */
  onProgress(t2, e, n2) {
    this._progressObserver = {
      next: t2,
      error: e,
      complete: n2
    };
  }
  /**
   * Implements the `Promise<LoadBundleTaskProgress>.catch` interface.
   *
   * @param onRejected - Called when an error occurs during bundle loading.
   */
  catch(t2) {
    return this._taskCompletionResolver.promise.catch(t2);
  }
  /**
   * Implements the `Promise<LoadBundleTaskProgress>.then` interface.
   *
   * @param onFulfilled - Called on the completion of the loading task with a final `LoadBundleTaskProgress` update.
   *   The update will always have its `taskState` set to `"Success"`.
   * @param onRejected - Called when an error occurs during bundle loading.
   */
  then(t2, e) {
    return this._taskCompletionResolver.promise.then(t2, e);
  }
  /**
   * Notifies all observers that bundle loading has completed, with a provided
   * `LoadBundleTaskProgress` object.
   *
   * @private
   */
  _completeWith(t2) {
    this._updateProgress(t2), this._progressObserver.complete && this._progressObserver.complete(), this._taskCompletionResolver.resolve(t2);
  }
  /**
   * Notifies all observers that bundle loading has failed, with a provided
   * `Error` as the reason.
   *
   * @private
   */
  _failWith(t2) {
    this._lastProgress.taskState = "Error", this._progressObserver.next && this._progressObserver.next(this._lastProgress), this._progressObserver.error && this._progressObserver.error(t2), this._taskCompletionResolver.reject(t2);
  }
  /**
   * Notifies a progress update of loading a bundle.
   * @param progress - The new progress.
   *
   * @private
   */
  _updateProgress(t2) {
    this._lastProgress = t2, this._progressObserver.next && this._progressObserver.next(t2);
  }
};
var vu = -1;
var Vu = class extends wu {
  /** @hideconstructor */
  constructor(t2, e) {
    super(t2, e), this.type = "firestore", this._queue = new Ru(), this._persistenceKey = "name" in t2 ? t2.name : "[DEFAULT]";
  }
  _terminate() {
    return this._firestoreClient || // The client must be initialized to ensure that all subsequent API
    // usage throws an exception.
    Nu(this), this._firestoreClient.terminate();
  }
};
function Su(e, n2) {
  const s = _getProvider(e, "firestore-exp");
  if (s.isInitialized())
    throw new D2(S2.FAILED_PRECONDITION, "Firestore can only be initialized once per app.");
  if (void 0 !== n2.cacheSizeBytes && -1 !== n2.cacheSizeBytes && n2.cacheSizeBytes < 1048576)
    throw new D2(S2.INVALID_ARGUMENT, "cacheSizeBytes must be at least 1048576");
  return s.initialize({
    options: n2
  });
}
function Du(n2 = getApp()) {
  return _getProvider(n2, "firestore-exp").getImmediate();
}
function Cu(t2) {
  return t2._firestoreClient || Nu(t2), t2._firestoreClient.verifyNotTerminated(), t2._firestoreClient;
}
function Nu(t2) {
  var e;
  const n2 = t2._freezeSettings(), s = function(t3, e2, n3, s2) {
    return new Xc2(t3, e2, n3, s2.host, s2.ssl, s2.experimentalForceLongPolling, s2.experimentalAutoDetectLongPolling, s2.useFetchStreams);
  }(t2._databaseId, (null === (e = t2._app) || void 0 === e ? void 0 : e.options.appId) || "", t2._persistenceKey, n2);
  t2._firestoreClient = new Nc2(t2._credentials, t2._queue, s);
}
function xu(t2, e) {
  Ku(t2 = lu(t2, Vu));
  const n2 = Cu(t2), s = t2._freezeSettings(), i = new bc2();
  return $u(n2, i, new Rc2(i, s.cacheSizeBytes, null == e ? void 0 : e.forceOwnership));
}
function ku(t2) {
  Ku(t2 = lu(t2, Vu));
  const e = Cu(t2), n2 = t2._freezeSettings(), s = new bc2();
  return $u(e, s, new Pc2(s, n2.cacheSizeBytes));
}
function $u(t2, e, n2) {
  const s = new Cs();
  return t2.asyncQueue.enqueue(async () => {
    try {
      await xc2(t2, n2), await kc2(t2, e), s.resolve();
    } catch (t3) {
      if (!/**
      * Decides whether the provided error allows us to gracefully disable
      * persistence (as opposed to crashing the client).
      */
      function(t4) {
        if ("FirebaseError" === t4.name)
          return t4.code === S2.FAILED_PRECONDITION || t4.code === S2.UNIMPLEMENTED;
        if ("undefined" != typeof DOMException && t4 instanceof DOMException)
          return 22 === t4.code || 20 === t4.code || // Firefox Private Browsing mode disables IndexedDb and returns
          // INVALID_STATE for any usage.
          11 === t4.code;
        return true;
      }(t3))
        throw t3;
      console.warn("Error enabling offline persistence. Falling back to persistence disabled: " + t3), s.reject(t3);
    }
  }).then(() => s.promise);
}
function Ou(t2) {
  if (t2._initialized && !t2._terminated)
    throw new D2(S2.FAILED_PRECONDITION, "Persistence can only be cleared before a Firestore instance is initialized or after it is terminated.");
  const e = new Cs();
  return t2._queue.enqueueAndForgetEvenWhileRestricted(async () => {
    try {
      await async function(t3) {
        if (!ks.gt())
          return Promise.resolve();
        const e2 = t3 + "main";
        await ks.delete(e2);
      }(ji(t2._databaseId, t2._persistenceKey)), e.resolve();
    } catch (t3) {
      e.reject(t3);
    }
  }), e.promise;
}
function Fu(t2) {
  return function(t3) {
    const e = new Cs();
    return t3.asyncQueue.enqueueAndForget(async () => tc2(await Bc2(t3), e)), e.promise;
  }(Cu(t2 = lu(t2, Vu)));
}
function Mu(t2) {
  return qc2(Cu(t2 = lu(t2, Vu)));
}
function Lu(t2) {
  return Kc2(Cu(t2 = lu(t2, Vu)));
}
function Bu(t2) {
  return _removeServiceInstance(t2.app, "firestore-exp"), t2._delete();
}
function Uu(t2, e) {
  const n2 = Cu(t2 = lu(t2, Vu)), s = new bu();
  return Jc2(n2, t2._databaseId, e, s), s;
}
function qu(t2, e) {
  return Yc2(Cu(t2 = lu(t2, Vu)), e).then((e2) => e2 ? new gu(t2, null, e2.query) : null);
}
function Ku(t2) {
  if (t2._initialized || t2._terminated)
    throw new D2(S2.FAILED_PRECONDITION, "Firestore has already been started and persistence can no longer be enabled. You can only enable persistence before calling any other methods on a Firestore object.");
}
var Qu = class {
  /**
   * Creates a FieldPath from the provided field names. If more than one field
   * name is provided, the path will point to a nested field in a document.
   *
   * @param fieldNames - A list of field names.
   */
  constructor(...t2) {
    for (let e = 0; e < t2.length; ++e)
      if (0 === t2[e].length)
        throw new D2(S2.INVALID_ARGUMENT, "Invalid field name at argument $(i + 1). Field names must not be empty.");
    this._internalPath = new tt(t2);
  }
  /**
   * Returns true if this `FieldPath` is equal to the provided one.
   *
   * @param other - The `FieldPath` to compare against.
   * @returns true if this `FieldPath` is equal to the provided one.
   */
  isEqual(t2) {
    return this._internalPath.isEqual(t2._internalPath);
  }
};
function ju() {
  return new Qu("__name__");
}
var Wu = class {
  /** @hideconstructor */
  constructor(t2) {
    this._byteString = t2;
  }
  /**
   * Creates a new `Bytes` object from the given Base64 string, converting it to
   * bytes.
   *
   * @param base64 - The Base64 string used to create the `Bytes` object.
   */
  static fromBase64String(t2) {
    try {
      return new Wu(nt.fromBase64String(t2));
    } catch (t3) {
      throw new D2(S2.INVALID_ARGUMENT, "Failed to construct data from Base64 string: " + t3);
    }
  }
  /**
   * Creates a new `Bytes` object from the given Uint8Array.
   *
   * @param array - The Uint8Array used to create the `Bytes` object.
   */
  static fromUint8Array(t2) {
    return new Wu(nt.fromUint8Array(t2));
  }
  /**
   * Returns the underlying bytes as a Base64-encoded string.
   *
   * @returns The Base64-encoded string created from the `Bytes` object.
   */
  toBase64() {
    return this._byteString.toBase64();
  }
  /**
   * Returns the underlying bytes in a new `Uint8Array`.
   *
   * @returns The Uint8Array created from the `Bytes` object.
   */
  toUint8Array() {
    return this._byteString.toUint8Array();
  }
  /**
   * Returns a string representation of the `Bytes` object.
   *
   * @returns A string representation of the `Bytes` object.
   */
  toString() {
    return "Bytes(base64: " + this.toBase64() + ")";
  }
  /**
   * Returns true if this `Bytes` object is equal to the provided one.
   *
   * @param other - The `Bytes` object to compare against.
   * @returns true if this `Bytes` object is equal to the provided one.
   */
  isEqual(t2) {
    return this._byteString.isEqual(t2._byteString);
  }
};
var Gu = class {
  /**
   * @param _methodName - The public API endpoint that returns this class.
   * @hideconstructor
   */
  constructor(t2) {
    this._methodName = t2;
  }
};
var zu = class {
  /**
   * Creates a new immutable `GeoPoint` object with the provided latitude and
   * longitude values.
   * @param latitude - The latitude as number between -90 and 90.
   * @param longitude - The longitude as number between -180 and 180.
   */
  constructor(t2, e) {
    if (!isFinite(t2) || t2 < -90 || t2 > 90)
      throw new D2(S2.INVALID_ARGUMENT, "Latitude must be a number between -90 and 90, but was: " + t2);
    if (!isFinite(e) || e < -180 || e > 180)
      throw new D2(S2.INVALID_ARGUMENT, "Longitude must be a number between -180 and 180, but was: " + e);
    this._lat = t2, this._long = e;
  }
  /**
   * The latitude of this `GeoPoint` instance.
   */
  get latitude() {
    return this._lat;
  }
  /**
   * The longitude of this `GeoPoint` instance.
   */
  get longitude() {
    return this._long;
  }
  /**
   * Returns true if this `GeoPoint` is equal to the provided one.
   *
   * @param other - The `GeoPoint` to compare against.
   * @returns true if this `GeoPoint` is equal to the provided one.
   */
  isEqual(t2) {
    return this._lat === t2._lat && this._long === t2._long;
  }
  /** Returns a JSON-serializable representation of this GeoPoint. */
  toJSON() {
    return {
      latitude: this._lat,
      longitude: this._long
    };
  }
  /**
   * Actually private to JS consumers of our API, so this function is prefixed
   * with an underscore.
   */
  _compareTo(t2) {
    return K2(this._lat, t2._lat) || K2(this._long, t2._long);
  }
};
var Hu = /^__.*__$/;
var Ju = class {
  constructor(t2, e, n2) {
    this.data = t2, this.fieldMask = e, this.fieldTransforms = n2;
  }
  toMutation(t2, e) {
    return null !== this.fieldMask ? new Ke(t2, this.data, this.fieldMask, e, this.fieldTransforms) : new qe(t2, this.data, e, this.fieldTransforms);
  }
};
var Yu = class {
  constructor(t2, e, n2) {
    this.data = t2, this.fieldMask = e, this.fieldTransforms = n2;
  }
  toMutation(t2, e) {
    return new Ke(t2, this.data, this.fieldMask, e, this.fieldTransforms);
  }
};
function Xu(t2) {
  switch (t2) {
    case 0:
    case 2:
    case 1:
      return true;
    case 3:
    case 4:
      return false;
    default:
      throw M2();
  }
}
var Zu = class {
  /**
   * Initializes a ParseContext with the given source and path.
   *
   * @param settings - The settings for the parser.
   * @param databaseId - The database ID of the Firestore instance.
   * @param serializer - The serializer to use to generate the Value proto.
   * @param ignoreUndefinedProperties - Whether to ignore undefined properties
   * rather than throw.
   * @param fieldTransforms - A mutable list of field transforms encountered
   * while parsing the data.
   * @param fieldMask - A mutable list of field paths encountered while parsing
   * the data.
   *
   * TODO(b/34871131): We don't support array paths right now, so path can be
   * null to indicate the context represents any location within an array (in
   * which case certain features will not work and errors will be somewhat
   * compromised).
   */
  constructor(t2, e, n2, s, i, r2) {
    this.settings = t2, this.databaseId = e, this.R = n2, this.ignoreUndefinedProperties = s, // Minor hack: If fieldTransforms is undefined, we assume this is an
    // external call and we need to validate the entire path.
    void 0 === i && this.Dc(), this.fieldTransforms = i || [], this.fieldMask = r2 || [];
  }
  get path() {
    return this.settings.path;
  }
  get Cc() {
    return this.settings.Cc;
  }
  /** Returns a new context with the specified settings overwritten. */
  Nc(t2) {
    return new Zu(Object.assign(Object.assign({}, this.settings), t2), this.databaseId, this.R, this.ignoreUndefinedProperties, this.fieldTransforms, this.fieldMask);
  }
  xc(t2) {
    var e;
    const n2 = null === (e = this.path) || void 0 === e ? void 0 : e.child(t2), s = this.Nc({
      path: n2,
      kc: false
    });
    return s.$c(t2), s;
  }
  Oc(t2) {
    var e;
    const n2 = null === (e = this.path) || void 0 === e ? void 0 : e.child(t2), s = this.Nc({
      path: n2,
      kc: false
    });
    return s.Dc(), s;
  }
  Fc(t2) {
    return this.Nc({
      path: void 0,
      kc: true
    });
  }
  Mc(t2) {
    return pa2(t2, this.settings.methodName, this.settings.Lc || false, this.path, this.settings.Bc);
  }
  /** Returns 'true' if 'fieldPath' was traversed when creating this context. */
  contains(t2) {
    return void 0 !== this.fieldMask.find((e) => t2.isPrefixOf(e)) || void 0 !== this.fieldTransforms.find((e) => t2.isPrefixOf(e.field));
  }
  Dc() {
    if (this.path)
      for (let t2 = 0; t2 < this.path.length; t2++)
        this.$c(this.path.get(t2));
  }
  $c(t2) {
    if (0 === t2.length)
      throw this.Mc("Document fields must not be empty");
    if (Xu(this.Cc) && Hu.test(t2))
      throw this.Mc('Document fields cannot begin and end with "__"');
  }
};
var ta2 = class {
  constructor(t2, e, n2) {
    this.databaseId = t2, this.ignoreUndefinedProperties = e, this.R = n2 || Br(t2);
  }
  /** Creates a new top-level parse context. */
  Uc(t2, e, n2, s = false) {
    return new Zu({
      Cc: t2,
      methodName: e,
      Bc: n2,
      path: tt.emptyPath(),
      kc: false,
      Lc: s
    }, this.databaseId, this.R, this.ignoreUndefinedProperties);
  }
};
function ea2(t2) {
  const e = t2._freezeSettings(), n2 = Br(t2._databaseId);
  return new ta2(t2._databaseId, !!e.ignoreUndefinedProperties, n2);
}
function na2(t2, e, n2, s, i, r2 = {}) {
  const o = t2.Uc(r2.merge || r2.mergeFields ? 2 : 0, e, n2, i);
  _a("Data must be an object, but it was:", o, s);
  const c = da2(s, o);
  let u2, a;
  if (r2.merge)
    u2 = new et(o.fieldMask), a = o.fieldTransforms;
  else if (r2.mergeFields) {
    const t3 = [];
    for (const s2 of r2.mergeFields) {
      const i2 = ma2(e, s2, n2);
      if (!o.contains(i2))
        throw new D2(S2.INVALID_ARGUMENT, `Field '${i2}' is specified in your field mask but missing from your input data.`);
      Ea2(t3, i2) || t3.push(i2);
    }
    u2 = new et(t3), a = o.fieldTransforms.filter((t4) => u2.covers(t4.field));
  } else
    u2 = null, a = o.fieldTransforms;
  return new Ju(new Vt(c), u2, a);
}
var sa2 = class extends Gu {
  _toFieldTransform(t2) {
    if (2 !== t2.Cc)
      throw 1 === t2.Cc ? t2.Mc(`${this._methodName}() can only appear at the top level of your update data`) : t2.Mc(`${this._methodName}() cannot be used with set() unless you pass {merge:true}`);
    return t2.fieldMask.push(t2.path), null;
  }
  isEqual(t2) {
    return t2 instanceof sa2;
  }
};
function ia2(t2, e, n2) {
  return new Zu({
    Cc: 3,
    Bc: e.settings.Bc,
    methodName: t2._methodName,
    kc: n2
  }, e.databaseId, e.R, e.ignoreUndefinedProperties);
}
var ra2 = class extends Gu {
  _toFieldTransform(t2) {
    return new Ce(t2.path, new Ae());
  }
  isEqual(t2) {
    return t2 instanceof ra2;
  }
};
var oa2 = class extends Gu {
  constructor(t2, e) {
    super(t2), this.qc = e;
  }
  _toFieldTransform(t2) {
    const e = ia2(
      this,
      t2,
      /*array=*/
      true
    ), n2 = this.qc.map((t3) => fa2(t3, e)), s = new Re(n2);
    return new Ce(t2.path, s);
  }
  isEqual(t2) {
    return this === t2;
  }
};
var ca2 = class extends Gu {
  constructor(t2, e) {
    super(t2), this.qc = e;
  }
  _toFieldTransform(t2) {
    const e = ia2(
      this,
      t2,
      /*array=*/
      true
    ), n2 = this.qc.map((t3) => fa2(t3, e)), s = new be(n2);
    return new Ce(t2.path, s);
  }
  isEqual(t2) {
    return this === t2;
  }
};
var ua2 = class extends Gu {
  constructor(t2, e) {
    super(t2), this.Kc = e;
  }
  _toFieldTransform(t2) {
    const e = new Ve(t2.R, ye(t2.R, this.Kc));
    return new Ce(t2.path, e);
  }
  isEqual(t2) {
    return this === t2;
  }
};
function aa2(t2, e, n2, s) {
  const i = t2.Uc(1, e, n2);
  _a("Data must be an object, but it was:", i, s);
  const r2 = [], o = Vt.empty();
  H2(s, (t3, s2) => {
    const c2 = ya2(e, t3, n2);
    s2 = getModularInstance(s2);
    const u2 = i.Oc(c2);
    if (s2 instanceof sa2)
      r2.push(c2);
    else {
      const t4 = fa2(s2, u2);
      null != t4 && (r2.push(c2), o.set(c2, t4));
    }
  });
  const c = new et(r2);
  return new Yu(o, c, i.fieldTransforms);
}
function ha2(t2, e, n2, s, i, r2) {
  const o = t2.Uc(1, e, n2), c = [ma2(e, s, n2)], u2 = [i];
  if (r2.length % 2 != 0)
    throw new D2(S2.INVALID_ARGUMENT, `Function ${e}() needs to be called with an even number of arguments that alternate between field names and values.`);
  for (let t3 = 0; t3 < r2.length; t3 += 2)
    c.push(ma2(e, r2[t3])), u2.push(r2[t3 + 1]);
  const a = [], h = Vt.empty();
  for (let t3 = c.length - 1; t3 >= 0; --t3)
    if (!Ea2(a, c[t3])) {
      const e2 = c[t3];
      let n3 = u2[t3];
      n3 = getModularInstance(n3);
      const s2 = o.Oc(e2);
      if (n3 instanceof sa2)
        a.push(e2);
      else {
        const t4 = fa2(n3, s2);
        null != t4 && (a.push(e2), h.set(e2, t4));
      }
    }
  const l = new et(a);
  return new Yu(h, l, o.fieldTransforms);
}
function la(t2, e, n2, s = false) {
  return fa2(n2, t2.Uc(s ? 4 : 3, e));
}
function fa2(t2, e) {
  if (wa(
    // Unwrap the API type from the Compat SDK. This will return the API type
    // from firestore-exp.
    t2 = getModularInstance(t2)
  ))
    return _a("Unsupported field value:", e, t2), da2(t2, e);
  if (t2 instanceof Gu)
    return function(t3, e2) {
      if (!Xu(e2.Cc))
        throw e2.Mc(`${t3._methodName}() can only be used with update() and set()`);
      if (!e2.path)
        throw e2.Mc(`${t3._methodName}() is not currently supported inside arrays`);
      const n2 = t3._toFieldTransform(e2);
      n2 && e2.fieldTransforms.push(n2);
    }(t2, e), null;
  if (void 0 === t2 && e.ignoreUndefinedProperties)
    return null;
  if (
    // If context.path is null we are inside an array and we don't support
    // field mask paths more granular than the top-level array.
    e.path && e.fieldMask.push(e.path), t2 instanceof Array
  ) {
    if (e.settings.kc && 4 !== e.Cc)
      throw e.Mc("Nested arrays are not supported");
    return function(t3, e2) {
      const n2 = [];
      let s = 0;
      for (const i of t3) {
        let t4 = fa2(i, e2.Fc(s));
        null == t4 && // Just include nulls in the array for fields being replaced with a
        // sentinel.
        (t4 = {
          nullValue: "NULL_VALUE"
        }), n2.push(t4), s++;
      }
      return {
        arrayValue: {
          values: n2
        }
      };
    }(t2, e);
  }
  return function(t3, e2) {
    if (null === (t3 = getModularInstance(t3)))
      return {
        nullValue: "NULL_VALUE"
      };
    if ("number" == typeof t3)
      return ye(e2.R, t3);
    if ("boolean" == typeof t3)
      return {
        booleanValue: t3
      };
    if ("string" == typeof t3)
      return {
        stringValue: t3
      };
    if (t3 instanceof Date) {
      const n2 = W2.fromDate(t3);
      return {
        timestampValue: Vn(e2.R, n2)
      };
    }
    if (t3 instanceof W2) {
      const n2 = new W2(t3.seconds, 1e3 * Math.floor(t3.nanoseconds / 1e3));
      return {
        timestampValue: Vn(e2.R, n2)
      };
    }
    if (t3 instanceof zu)
      return {
        geoPointValue: {
          latitude: t3.latitude,
          longitude: t3.longitude
        }
      };
    if (t3 instanceof Wu)
      return {
        bytesValue: Sn(e2.R, t3._byteString)
      };
    if (t3 instanceof mu) {
      const n2 = e2.databaseId, s = t3.firestore._databaseId;
      if (!s.isEqual(n2))
        throw e2.Mc(`Document reference is for database ${s.projectId}/${s.database} but should be for database ${n2.projectId}/${n2.database}`);
      return {
        referenceValue: Nn(t3.firestore._databaseId || e2.databaseId, t3._key.path)
      };
    }
    throw e2.Mc(`Unsupported field value: ${hu(t3)}`);
  }(t2, e);
}
function da2(t2, e) {
  const n2 = {};
  return J2(t2) ? (
    // If we encounter an empty object, we explicitly add it to the update
    // mask to ensure that the server creates a map entry.
    e.path && e.path.length > 0 && e.fieldMask.push(e.path)
  ) : H2(t2, (t3, s) => {
    const i = fa2(s, e.xc(t3));
    null != i && (n2[t3] = i);
  }), {
    mapValue: {
      fields: n2
    }
  };
}
function wa(t2) {
  return !("object" != typeof t2 || null === t2 || t2 instanceof Array || t2 instanceof Date || t2 instanceof W2 || t2 instanceof zu || t2 instanceof Wu || t2 instanceof mu || t2 instanceof Gu);
}
function _a(t2, e, n2) {
  if (!wa(n2) || !function(t3) {
    return "object" == typeof t3 && null !== t3 && (Object.getPrototypeOf(t3) === Object.prototype || null === Object.getPrototypeOf(t3));
  }(n2)) {
    const s = hu(n2);
    throw "an object" === s ? e.Mc(t2 + " a custom object") : e.Mc(t2 + " " + s);
  }
}
function ma2(t2, e, n2) {
  if (
    // If required, replace the FieldPath Compat class with with the firestore-exp
    // FieldPath.
    (e = getModularInstance(e)) instanceof Qu
  )
    return e._internalPath;
  if ("string" == typeof e)
    return ya2(t2, e);
  throw pa2(
    "Field path arguments must be of type string or FieldPath.",
    t2,
    /* hasConverter= */
    false,
    /* path= */
    void 0,
    n2
  );
}
var ga = new RegExp("[~\\*/\\[\\]]");
function ya2(t2, e, n2) {
  if (e.search(ga) >= 0)
    throw pa2(
      `Invalid field path (${e}). Paths must not contain '~', '*', '/', '[', or ']'`,
      t2,
      /* hasConverter= */
      false,
      /* path= */
      void 0,
      n2
    );
  try {
    return new Qu(...e.split("."))._internalPath;
  } catch (s) {
    throw pa2(
      `Invalid field path (${e}). Paths must not be empty, begin with '.', end with '.', or contain '..'`,
      t2,
      /* hasConverter= */
      false,
      /* path= */
      void 0,
      n2
    );
  }
}
function pa2(t2, e, n2, s, i) {
  const r2 = s && !s.isEmpty(), o = void 0 !== i;
  let c = `Function ${e}() called with invalid data`;
  n2 && (c += " (via `toFirestore()`)"), c += ". ";
  let u2 = "";
  return (r2 || o) && (u2 += " (found", r2 && (u2 += ` in field ${s}`), o && (u2 += ` in document ${i}`), u2 += ")"), new D2(S2.INVALID_ARGUMENT, c + t2 + u2);
}
function Ea2(t2, e) {
  return t2.some((t3) => t3.isEqual(e));
}
var Ta2 = class {
  // Note: This class is stripped down version of the DocumentSnapshot in
  // the legacy SDK. The changes are:
  // - No support for SnapshotMetadata.
  // - No support for SnapshotOptions.
  /** @hideconstructor protected */
  constructor(t2, e, n2, s, i) {
    this._firestore = t2, this._userDataWriter = e, this._key = n2, this._document = s, this._converter = i;
  }
  /** Property of the `DocumentSnapshot` that provides the document's ID. */
  get id() {
    return this._key.path.lastSegment();
  }
  /**
   * The `DocumentReference` for the document included in the `DocumentSnapshot`.
   */
  get ref() {
    return new mu(this._firestore, this._converter, this._key);
  }
  /**
   * Signals whether or not the document at the snapshot's location exists.
   *
   * @returns true if the document exists.
   */
  exists() {
    return null !== this._document;
  }
  /**
   * Retrieves all fields in the document as an `Object`. Returns `undefined` if
   * the document doesn't exist.
   *
   * @returns An `Object` containing all fields in the document or `undefined`
   * if the document doesn't exist.
   */
  data() {
    if (this._document) {
      if (this._converter) {
        const t2 = new Ia2(
          this._firestore,
          this._userDataWriter,
          this._key,
          this._document,
          /* converter= */
          null
        );
        return this._converter.fromFirestore(t2);
      }
      return this._userDataWriter.convertValue(this._document.data.value);
    }
  }
  /**
   * Retrieves the field specified by `fieldPath`. Returns `undefined` if the
   * document or field doesn't exist.
   *
   * @param fieldPath - The path (for example 'foo' or 'foo.bar') to a specific
   * field.
   * @returns The data at the specified field location or undefined if no such
   * field exists in the document.
   */
  // We are using `any` here to avoid an explicit cast by our users.
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  get(t2) {
    if (this._document) {
      const e = this._document.data.field(Aa("DocumentSnapshot.get", t2));
      if (null !== e)
        return this._userDataWriter.convertValue(e);
    }
  }
};
var Ia2 = class extends Ta2 {
  /**
   * Retrieves all fields in the document as an `Object`.
   *
   * @override
   * @returns An `Object` containing all fields in the document.
   */
  data() {
    return super.data();
  }
};
function Aa(t2, e) {
  return "string" == typeof e ? ya2(t2, e) : e instanceof Qu ? e._internalPath : e._delegate._internalPath;
}
var Ra2 = class {
  /** @hideconstructor */
  constructor(t2, e) {
    this.hasPendingWrites = t2, this.fromCache = e;
  }
  /**
   * Returns true if this `SnapshotMetadata` is equal to the provided one.
   *
   * @param other - The `SnapshotMetadata` to compare against.
   * @returns true if this `SnapshotMetadata` is equal to the provided one.
   */
  isEqual(t2) {
    return this.hasPendingWrites === t2.hasPendingWrites && this.fromCache === t2.fromCache;
  }
};
var Pa = class extends Ta2 {
  /** @hideconstructor protected */
  constructor(t2, e, n2, s, i, r2) {
    super(t2, e, n2, s, r2), this._firestore = t2, this._firestoreImpl = t2, this.metadata = i;
  }
  /**
   * Property of the `DocumentSnapshot` that signals whether or not the data
   * exists. True if the document exists.
   */
  exists() {
    return super.exists();
  }
  /**
   * Retrieves all fields in the document as an `Object`. Returns `undefined` if
   * the document doesn't exist.
   *
   * By default, `FieldValue.serverTimestamp()` values that have not yet been
   * set to their final value will be returned as `null`. You can override
   * this by passing an options object.
   *
   * @param options - An options object to configure how data is retrieved from
   * the snapshot (for example the desired behavior for server timestamps that
   * have not yet been set to their final value).
   * @returns An `Object` containing all fields in the document or `undefined` if
   * the document doesn't exist.
   */
  data(t2 = {}) {
    if (this._document) {
      if (this._converter) {
        const e = new ba2(
          this._firestore,
          this._userDataWriter,
          this._key,
          this._document,
          this.metadata,
          /* converter= */
          null
        );
        return this._converter.fromFirestore(e, t2);
      }
      return this._userDataWriter.convertValue(this._document.data.value, t2.serverTimestamps);
    }
  }
  /**
   * Retrieves the field specified by `fieldPath`. Returns `undefined` if the
   * document or field doesn't exist.
   *
   * By default, a `FieldValue.serverTimestamp()` that has not yet been set to
   * its final value will be returned as `null`. You can override this by
   * passing an options object.
   *
   * @param fieldPath - The path (for example 'foo' or 'foo.bar') to a specific
   * field.
   * @param options - An options object to configure how the field is retrieved
   * from the snapshot (for example the desired behavior for server timestamps
   * that have not yet been set to their final value).
   * @returns The data at the specified field location or undefined if no such
   * field exists in the document.
   */
  // We are using `any` here to avoid an explicit cast by our users.
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  get(t2, e = {}) {
    if (this._document) {
      const n2 = this._document.data.field(Aa("DocumentSnapshot.get", t2));
      if (null !== n2)
        return this._userDataWriter.convertValue(n2, e.serverTimestamps);
    }
  }
};
var ba2 = class extends Pa {
  /**
   * Retrieves all fields in the document as an `Object`.
   *
   * By default, `FieldValue.serverTimestamp()` values that have not yet been
   * set to their final value will be returned as `null`. You can override
   * this by passing an options object.
   *
   * @override
   * @param options - An options object to configure how data is retrieved from
   * the snapshot (for example the desired behavior for server timestamps that
   * have not yet been set to their final value).
   * @returns An `Object` containing all fields in the document.
   */
  data(t2 = {}) {
    return super.data(t2);
  }
};
var va = class {
  /** @hideconstructor */
  constructor(t2, e, n2, s) {
    this._firestore = t2, this._userDataWriter = e, this._snapshot = s, this.metadata = new Ra2(s.hasPendingWrites, s.fromCache), this.query = n2;
  }
  /** An array of all the documents in the `QuerySnapshot`. */
  get docs() {
    const t2 = [];
    return this.forEach((e) => t2.push(e)), t2;
  }
  /** The number of documents in the `QuerySnapshot`. */
  get size() {
    return this._snapshot.docs.size;
  }
  /** True if there are no documents in the `QuerySnapshot`. */
  get empty() {
    return 0 === this.size;
  }
  /**
   * Enumerates all of the documents in the `QuerySnapshot`.
   *
   * @param callback - A callback to be called with a `QueryDocumentSnapshot` for
   * each document in the snapshot.
   * @param thisArg - The `this` binding for the callback.
   */
  forEach(t2, e) {
    this._snapshot.docs.forEach((n2) => {
      t2.call(e, new ba2(this._firestore, this._userDataWriter, n2.key, n2, new Ra2(this._snapshot.mutatedKeys.has(n2.key), this._snapshot.fromCache), this.query.converter));
    });
  }
  /**
   * Returns an array of the documents changes since the last snapshot. If this
   * is the first snapshot, all documents will be in the list as 'added'
   * changes.
   *
   * @param options - `SnapshotListenOptions` that control whether metadata-only
   * changes (i.e. only `DocumentSnapshot.metadata` changed) should trigger
   * snapshot events.
   */
  docChanges(t2 = {}) {
    const e = !!t2.includeMetadataChanges;
    if (e && this._snapshot.excludesMetadataChanges)
      throw new D2(S2.INVALID_ARGUMENT, "To include metadata changes with your document changes, you must also pass { includeMetadataChanges:true } to onSnapshot().");
    return this._cachedChanges && this._cachedChangesIncludeMetadataChanges === e || (this._cachedChanges = /** Calculates the array of DocumentChanges for a given ViewSnapshot. */
    function(t3, e2) {
      if (t3._snapshot.oldDocs.isEmpty()) {
        let e3 = 0;
        return t3._snapshot.docChanges.map((n2) => ({
          type: "added",
          doc: new ba2(t3._firestore, t3._userDataWriter, n2.doc.key, n2.doc, new Ra2(t3._snapshot.mutatedKeys.has(n2.doc.key), t3._snapshot.fromCache), t3.query.converter),
          oldIndex: -1,
          newIndex: e3++
        }));
      }
      {
        let n2 = t3._snapshot.oldDocs;
        return t3._snapshot.docChanges.filter((t4) => e2 || 3 !== t4.type).map((e3) => {
          const s = new ba2(t3._firestore, t3._userDataWriter, e3.doc.key, e3.doc, new Ra2(t3._snapshot.mutatedKeys.has(e3.doc.key), t3._snapshot.fromCache), t3.query.converter);
          let i = -1, r2 = -1;
          return 0 !== e3.type && (i = n2.indexOf(e3.doc.key), n2 = n2.delete(e3.doc.key)), 1 !== e3.type && (n2 = n2.add(e3.doc), r2 = n2.indexOf(e3.doc.key)), {
            type: Va2(e3.type),
            doc: s,
            oldIndex: i,
            newIndex: r2
          };
        });
      }
    }(this, e), this._cachedChangesIncludeMetadataChanges = e), this._cachedChanges;
  }
};
function Va2(t2) {
  switch (t2) {
    case 0:
      return "added";
    case 2:
    case 3:
      return "modified";
    case 1:
      return "removed";
    default:
      return M2();
  }
}
function Sa(t2, e) {
  return t2 instanceof Pa && e instanceof Pa ? t2._firestore === e._firestore && t2._key.isEqual(e._key) && (null === t2._document ? null === e._document : t2._document.isEqual(e._document)) && t2._converter === e._converter : t2 instanceof va && e instanceof va && (t2._firestore === e._firestore && Au(t2.query, e.query) && t2.metadata.isEqual(e.metadata) && t2._snapshot.isEqual(e._snapshot));
}
function Da2(t2) {
  if (se(t2) && 0 === t2.explicitOrderBy.length)
    throw new D2(S2.UNIMPLEMENTED, "limitToLast() queries require specifying at least one orderBy() clause");
}
var Ca2 = class {
};
function Na(t2, ...e) {
  for (const n2 of e)
    t2 = n2._apply(t2);
  return t2;
}
var xa2 = class extends Ca2 {
  constructor(t2, e, n2) {
    super(), this.Qc = t2, this.jc = e, this.Wc = n2, this.type = "where";
  }
  _apply(t2) {
    const e = ea2(t2.firestore), n2 = function(t3, e2, n3, s, i, r2, o) {
      let c;
      if (i.isKeyField()) {
        if ("array-contains" === r2 || "array-contains-any" === r2)
          throw new D2(S2.INVALID_ARGUMENT, `Invalid Query. You can't perform '${r2}' queries on FieldPath.documentId().`);
        if ("in" === r2 || "not-in" === r2) {
          za2(o, r2);
          const e3 = [];
          for (const n4 of o)
            e3.push(Ga2(s, t3, n4));
          c = {
            arrayValue: {
              values: e3
            }
          };
        } else
          c = Ga2(s, t3, o);
      } else
        "in" !== r2 && "not-in" !== r2 && "array-contains-any" !== r2 || za2(o, r2), c = la(
          n3,
          e2,
          o,
          /* allowArrays= */
          "in" === r2 || "not-in" === r2
        );
      const u2 = Ft.create(i, r2, c);
      return function(t4, e3) {
        if (e3.g()) {
          const n5 = re(t4);
          if (null !== n5 && !n5.isEqual(e3.field))
            throw new D2(S2.INVALID_ARGUMENT, `Invalid query. All where filters with an inequality (<, <=, !=, not-in, >, or >=) must be on the same field. But you have inequality filters on '${n5.toString()}' and '${e3.field.toString()}'`);
          const s2 = ie(t4);
          null !== s2 && Ha2(t4, e3.field, s2);
        }
        const n4 = function(t5, e4) {
          for (const n5 of t5.filters)
            if (e4.indexOf(n5.op) >= 0)
              return n5.op;
          return null;
        }(
          t4,
          /**
          * Given an operator, returns the set of operators that cannot be used with it.
          *
          * Operators in a query must adhere to the following set of rules:
          * 1. Only one array operator is allowed.
          * 2. Only one disjunctive operator is allowed.
          * 3. NOT_EQUAL cannot be used with another NOT_EQUAL operator.
          * 4. NOT_IN cannot be used with array, disjunctive, or NOT_EQUAL operators.
          *
          * Array operators: ARRAY_CONTAINS, ARRAY_CONTAINS_ANY
          * Disjunctive operators: IN, ARRAY_CONTAINS_ANY, NOT_IN
          */
          function(t5) {
            switch (t5) {
              case "!=":
                return [
                  "!=",
                  "not-in"
                  /* NOT_IN */
                ];
              case "array-contains":
                return [
                  "array-contains",
                  "array-contains-any",
                  "not-in"
                  /* NOT_IN */
                ];
              case "in":
                return [
                  "array-contains-any",
                  "in",
                  "not-in"
                  /* NOT_IN */
                ];
              case "array-contains-any":
                return [
                  "array-contains",
                  "array-contains-any",
                  "in",
                  "not-in"
                  /* NOT_IN */
                ];
              case "not-in":
                return [
                  "array-contains",
                  "array-contains-any",
                  "in",
                  "not-in",
                  "!="
                  /* NOT_EQUAL */
                ];
              default:
                return [];
            }
          }(e3.op)
        );
        if (null !== n4)
          throw n4 === e3.op ? new D2(S2.INVALID_ARGUMENT, `Invalid query. You cannot use more than one '${e3.op.toString()}' filter.`) : new D2(S2.INVALID_ARGUMENT, `Invalid query. You cannot use '${e3.op.toString()}' filters with '${n4.toString()}' filters.`);
      }(t3, u2), u2;
    }(t2._query, "where", e, t2.firestore._databaseId, this.Qc, this.jc, this.Wc);
    return new gu(t2.firestore, t2.converter, function(t3, e2) {
      const n3 = t3.filters.concat([e2]);
      return new Zt(t3.path, t3.collectionGroup, t3.explicitOrderBy.slice(), n3, t3.limit, t3.limitType, t3.startAt, t3.endAt);
    }(t2._query, n2));
  }
};
function ka2(t2, e, n2) {
  const s = e, i = Aa("where", t2);
  return new xa2(i, s, n2);
}
var $a2 = class extends Ca2 {
  constructor(t2, e) {
    super(), this.Qc = t2, this.Gc = e, this.type = "orderBy";
  }
  _apply(t2) {
    const e = function(t3, e2, n2) {
      if (null !== t3.startAt)
        throw new D2(S2.INVALID_ARGUMENT, "Invalid query. You must not call startAt() or startAfter() before calling orderBy().");
      if (null !== t3.endAt)
        throw new D2(S2.INVALID_ARGUMENT, "Invalid query. You must not call endAt() or endBefore() before calling orderBy().");
      const s = new Ht(e2, n2);
      return function(t4, e3) {
        if (null === ie(t4)) {
          const n3 = re(t4);
          null !== n3 && Ha2(t4, n3, e3.field);
        }
      }(t3, s), s;
    }(t2._query, this.Qc, this.Gc);
    return new gu(t2.firestore, t2.converter, function(t3, e2) {
      const n2 = t3.explicitOrderBy.concat([e2]);
      return new Zt(t3.path, t3.collectionGroup, n2, t3.filters.slice(), t3.limit, t3.limitType, t3.startAt, t3.endAt);
    }(t2._query, e));
  }
};
function Oa(t2, e = "asc") {
  const n2 = e, s = Aa("orderBy", t2);
  return new $a2(s, n2);
}
var Fa2 = class extends Ca2 {
  constructor(t2, e, n2) {
    super(), this.type = t2, this.zc = e, this.Hc = n2;
  }
  _apply(t2) {
    return new gu(t2.firestore, t2.converter, ae(t2._query, this.zc, this.Hc));
  }
};
function Ma2(t2) {
  return fu("limit", t2), new Fa2(
    "limit",
    t2,
    "F"
    /* First */
  );
}
function La2(t2) {
  return fu("limitToLast", t2), new Fa2(
    "limitToLast",
    t2,
    "L"
    /* Last */
  );
}
var Ba = class extends Ca2 {
  constructor(t2, e, n2) {
    super(), this.type = t2, this.Jc = e, this.Yc = n2;
  }
  _apply(t2) {
    const e = Wa2(t2, this.type, this.Jc, this.Yc);
    return new gu(t2.firestore, t2.converter, function(t3, e2) {
      return new Zt(t3.path, t3.collectionGroup, t3.explicitOrderBy.slice(), t3.filters.slice(), t3.limit, t3.limitType, e2, t3.endAt);
    }(t2._query, e));
  }
};
function Ua2(...t2) {
  return new Ba(
    "startAt",
    t2,
    /*before=*/
    true
  );
}
function qa2(...t2) {
  return new Ba(
    "startAfter",
    t2,
    /*before=*/
    false
  );
}
var Ka2 = class extends Ca2 {
  constructor(t2, e, n2) {
    super(), this.type = t2, this.Jc = e, this.Yc = n2;
  }
  _apply(t2) {
    const e = Wa2(t2, this.type, this.Jc, this.Yc);
    return new gu(t2.firestore, t2.converter, function(t3, e2) {
      return new Zt(t3.path, t3.collectionGroup, t3.explicitOrderBy.slice(), t3.filters.slice(), t3.limit, t3.limitType, t3.startAt, e2);
    }(t2._query, e));
  }
};
function Qa2(...t2) {
  return new Ka2(
    "endBefore",
    t2,
    /*before=*/
    true
  );
}
function ja(...t2) {
  return new Ka2(
    "endAt",
    t2,
    /*before=*/
    false
  );
}
function Wa2(t2, e, n2, s) {
  if (n2[0] = getModularInstance(n2[0]), n2[0] instanceof Ta2)
    return function(t3, e2, n3, s2, i) {
      if (!s2)
        throw new D2(S2.NOT_FOUND, `Can't use a DocumentSnapshot that doesn't exist for ${n3}().`);
      const r2 = [];
      for (const n4 of ce(t3))
        if (n4.field.isKeyField())
          r2.push(Tt(e2, s2.key));
        else {
          const t4 = s2.data.field(n4.field);
          if (ct(t4))
            throw new D2(S2.INVALID_ARGUMENT, 'Invalid query. You are trying to start or end a query using a document for which the field "' + n4.field + '" is an uncommitted server timestamp. (Since the value of this field is unknown, you cannot start/end a query with it.)');
          if (null === t4) {
            const t5 = n4.field.canonicalString();
            throw new D2(S2.INVALID_ARGUMENT, `Invalid query. You are trying to start or end a query using a document for which the field '${t5}' (used as the orderBy) does not exist.`);
          }
          r2.push(t4);
        }
      return new Gt(r2, i);
    }(t2._query, t2.firestore._databaseId, e, n2[0]._document, s);
  {
    const i = ea2(t2.firestore);
    return function(t3, e2, n3, s2, i2, r2) {
      const o = t3.explicitOrderBy;
      if (i2.length > o.length)
        throw new D2(S2.INVALID_ARGUMENT, `Too many arguments provided to ${s2}(). The number of arguments must be less than or equal to the number of orderBy() clauses`);
      const c = [];
      for (let r3 = 0; r3 < i2.length; r3++) {
        const u2 = i2[r3];
        if (o[r3].field.isKeyField()) {
          if ("string" != typeof u2)
            throw new D2(S2.INVALID_ARGUMENT, `Invalid query. Expected a string for document ID in ${s2}(), but got a ${typeof u2}`);
          if (!oe(t3) && -1 !== u2.indexOf("/"))
            throw new D2(S2.INVALID_ARGUMENT, `Invalid query. When querying a collection and ordering by FieldPath.documentId(), the value passed to ${s2}() must be a plain document ID, but '${u2}' contains a slash.`);
          const n4 = t3.path.child(X2.fromString(u2));
          if (!dt.isDocumentKey(n4))
            throw new D2(S2.INVALID_ARGUMENT, `Invalid query. When querying a collection group and ordering by FieldPath.documentId(), the value passed to ${s2}() must result in a valid document path, but '${n4}' is not because it contains an odd number of segments.`);
          const i3 = new dt(n4);
          c.push(Tt(e2, i3));
        } else {
          const t4 = la(n3, s2, u2);
          c.push(t4);
        }
      }
      return new Gt(c, r2);
    }(t2._query, t2.firestore._databaseId, i, e, n2, s);
  }
}
function Ga2(t2, e, n2) {
  if ("string" == typeof (n2 = getModularInstance(n2))) {
    if ("" === n2)
      throw new D2(S2.INVALID_ARGUMENT, "Invalid query. When querying with FieldPath.documentId(), you must provide a valid document ID, but it was an empty string.");
    if (!oe(e) && -1 !== n2.indexOf("/"))
      throw new D2(S2.INVALID_ARGUMENT, `Invalid query. When querying a collection by FieldPath.documentId(), you must provide a plain document ID, but '${n2}' contains a '/' character.`);
    const s = e.path.child(X2.fromString(n2));
    if (!dt.isDocumentKey(s))
      throw new D2(S2.INVALID_ARGUMENT, `Invalid query. When querying a collection group by FieldPath.documentId(), the value provided must result in a valid document path, but '${s}' is not because it has an odd number of segments (${s.length}).`);
    return Tt(t2, new dt(s));
  }
  if (n2 instanceof mu)
    return Tt(t2, n2._key);
  throw new D2(S2.INVALID_ARGUMENT, `Invalid query. When querying with FieldPath.documentId(), you must provide a valid string or a DocumentReference, but it was: ${hu(n2)}.`);
}
function za2(t2, e) {
  if (!Array.isArray(t2) || 0 === t2.length)
    throw new D2(S2.INVALID_ARGUMENT, `Invalid Query. A non-empty array is required for '${e.toString()}' filters.`);
  if (t2.length > 10)
    throw new D2(S2.INVALID_ARGUMENT, `Invalid Query. '${e.toString()}' filters support a maximum of 10 elements in the value array.`);
}
function Ha2(t2, e, n2) {
  if (!n2.isEqual(e))
    throw new D2(S2.INVALID_ARGUMENT, `Invalid query. You have a where filter with an inequality (<, <=, !=, not-in, >, or >=) on field '${e.toString()}' and so you must also use '${e.toString()}' as your first argument to orderBy(), but your first orderBy() is on field '${n2.toString()}' instead.`);
}
var Ja2 = class {
  convertValue(t2, e = "none") {
    switch (wt(t2)) {
      case 0:
        return null;
      case 1:
        return t2.booleanValue;
      case 2:
        return rt(t2.integerValue || t2.doubleValue);
      case 3:
        return this.convertTimestamp(t2.timestampValue);
      case 4:
        return this.convertServerTimestamp(t2, e);
      case 5:
        return t2.stringValue;
      case 6:
        return this.convertBytes(ot(t2.bytesValue));
      case 7:
        return this.convertReference(t2.referenceValue);
      case 8:
        return this.convertGeoPoint(t2.geoPointValue);
      case 9:
        return this.convertArray(t2.arrayValue, e);
      case 10:
        return this.convertObject(t2.mapValue, e);
      default:
        throw M2();
    }
  }
  convertObject(t2, e) {
    const n2 = {};
    return H2(t2.fields, (t3, s) => {
      n2[t3] = this.convertValue(s, e);
    }), n2;
  }
  convertGeoPoint(t2) {
    return new zu(rt(t2.latitude), rt(t2.longitude));
  }
  convertArray(t2, e) {
    return (t2.values || []).map((t3) => this.convertValue(t3, e));
  }
  convertServerTimestamp(t2, e) {
    switch (e) {
      case "previous":
        const n2 = ut(t2);
        return null == n2 ? null : this.convertValue(n2, e);
      case "estimate":
        return this.convertTimestamp(at(t2));
      default:
        return null;
    }
  }
  convertTimestamp(t2) {
    const e = it(t2);
    return new W2(e.seconds, e.nanos);
  }
  convertDocumentKey(t2, e) {
    const n2 = X2.fromString(t2);
    L2(cs(n2));
    const s = new Zc2(n2.get(1), n2.get(3)), i = new dt(n2.popFirst(5));
    return s.isEqual(e) || // TODO(b/64130202): Somehow support foreign references.
    $(`Document ${i} contains a document reference within a different database (${s.projectId}/${s.database}) which is not supported. It will be treated as a reference in the current database (${e.projectId}/${e.database}) instead.`), i;
  }
};
function Ya2(t2, e, n2) {
  let s;
  return s = t2 ? n2 && (n2.merge || n2.mergeFields) ? t2.toFirestore(e, n2) : t2.toFirestore(e) : e, s;
}
var Xa2 = class extends Ja2 {
  constructor(t2) {
    super(), this.firestore = t2;
  }
  convertBytes(t2) {
    return new Wu(t2);
  }
  convertReference(t2) {
    const e = this.convertDocumentKey(t2, this.firestore._databaseId);
    return new mu(
      this.firestore,
      /* converter= */
      null,
      e
    );
  }
};
var Za2 = class {
  /** @hideconstructor */
  constructor(t2, e) {
    this._firestore = t2, this._commitHandler = e, this._mutations = [], this._committed = false, this._dataReader = ea2(t2);
  }
  set(t2, e, n2) {
    this._verifyNotCommitted();
    const s = th(t2, this._firestore), i = Ya2(s.converter, e, n2), r2 = na2(this._dataReader, "WriteBatch.set", s._key, i, null !== s.converter, n2);
    return this._mutations.push(r2.toMutation(s._key, ke.none())), this;
  }
  update(t2, e, n2, ...s) {
    this._verifyNotCommitted();
    const i = th(t2, this._firestore);
    let r2;
    return r2 = "string" == typeof (e = getModularInstance(e)) || e instanceof Qu ? ha2(this._dataReader, "WriteBatch.update", i._key, e, n2, s) : aa2(this._dataReader, "WriteBatch.update", i._key, e), this._mutations.push(r2.toMutation(i._key, ke.exists(true))), this;
  }
  /**
   * Deletes the document referred to by the provided {@link DocumentReference}.
   *
   * @param documentRef - A reference to the document to be deleted.
   * @returns This `WriteBatch` instance. Used for chaining method calls.
   */
  delete(t2) {
    this._verifyNotCommitted();
    const e = th(t2, this._firestore);
    return this._mutations = this._mutations.concat(new Ge(e._key, ke.none())), this;
  }
  /**
   * Commits all of the writes in this write batch as a single atomic unit.
   *
   * The result of these writes will only be reflected in document reads that
   * occur after the returned Promise resolves. If the client is offline, the
   * write fails. If you would like to see local modifications or buffer writes
   * until the client is online, use the full Firestore SDK.
   *
   * @returns A Promise resolved once all of the writes in the batch have been
   * successfully written to the backend as an atomic unit (note that it won't
   * resolve while you're offline).
   */
  commit() {
    return this._verifyNotCommitted(), this._committed = true, this._mutations.length > 0 ? this._commitHandler(this._mutations) : Promise.resolve();
  }
  _verifyNotCommitted() {
    if (this._committed)
      throw new D2(S2.FAILED_PRECONDITION, "A write batch can no longer be used after commit() has been called.");
  }
};
function th(t2, e) {
  if ((t2 = getModularInstance(t2)).firestore !== e)
    throw new D2(S2.INVALID_ARGUMENT, "Provided document reference is from a different Firestore instance.");
  return t2;
}
function eh(t2) {
  t2 = lu(t2, mu);
  const e = lu(t2.firestore, Vu);
  return jc2(Cu(e), t2._key).then((n2) => _h(e, t2, n2));
}
var nh = class extends Ja2 {
  constructor(t2) {
    super(), this.firestore = t2;
  }
  convertBytes(t2) {
    return new Wu(t2);
  }
  convertReference(t2) {
    const e = this.convertDocumentKey(t2, this.firestore._databaseId);
    return new mu(
      this.firestore,
      /* converter= */
      null,
      e
    );
  }
};
function sh(t2) {
  t2 = lu(t2, mu);
  const e = lu(t2.firestore, Vu), n2 = Cu(e), s = new nh(e);
  return Qc2(n2, t2._key).then((n3) => new Pa(e, s, t2._key, n3, new Ra2(
    null !== n3 && n3.hasLocalMutations,
    /* fromCache= */
    true
  ), t2.converter));
}
function ih(t2) {
  t2 = lu(t2, mu);
  const e = lu(t2.firestore, Vu);
  return jc2(Cu(e), t2._key, {
    source: "server"
  }).then((n2) => _h(e, t2, n2));
}
function rh(t2) {
  t2 = lu(t2, gu);
  const e = lu(t2.firestore, Vu), n2 = Cu(e), s = new nh(e);
  return Da2(t2._query), Gc2(n2, t2._query).then((n3) => new va(e, s, t2, n3));
}
function oh(t2) {
  t2 = lu(t2, gu);
  const e = lu(t2.firestore, Vu), n2 = Cu(e), s = new nh(e);
  return Wc2(n2, t2._query).then((n3) => new va(e, s, t2, n3));
}
function ch(t2) {
  t2 = lu(t2, gu);
  const e = lu(t2.firestore, Vu), n2 = Cu(e), s = new nh(e);
  return Gc2(n2, t2._query, {
    source: "server"
  }).then((n3) => new va(e, s, t2, n3));
}
function uh(t2, e, n2) {
  t2 = lu(t2, mu);
  const s = lu(t2.firestore, Vu), i = Ya2(t2.converter, e, n2);
  return wh(s, [na2(ea2(s), "setDoc", t2._key, i, null !== t2.converter, n2).toMutation(t2._key, ke.none())]);
}
function ah(t2, e, n2, ...s) {
  t2 = lu(t2, mu);
  const i = lu(t2.firestore, Vu), r2 = ea2(i);
  let o;
  o = "string" == typeof // For Compat types, we have to "extract" the underlying types before
  // performing validation.
  (e = getModularInstance(e)) || e instanceof Qu ? ha2(r2, "updateDoc", t2._key, e, n2, s) : aa2(r2, "updateDoc", t2._key, e);
  return wh(i, [o.toMutation(t2._key, ke.exists(true))]);
}
function hh(t2) {
  return wh(lu(t2.firestore, Vu), [new Ge(t2._key, ke.none())]);
}
function lh(t2, e) {
  const n2 = lu(t2.firestore, Vu), s = Tu(t2), i = Ya2(t2.converter, e);
  return wh(n2, [na2(ea2(t2.firestore), "addDoc", s._key, i, null !== t2.converter, {}).toMutation(s._key, ke.exists(false))]).then(() => s);
}
function fh(t2, ...e) {
  var n2, s, i;
  t2 = getModularInstance(t2);
  let r2 = {
    includeMetadataChanges: false
  }, o = 0;
  "object" != typeof e[o] || Pu(e[o]) || (r2 = e[o], o++);
  const c = {
    includeMetadataChanges: r2.includeMetadataChanges
  };
  if (Pu(e[o])) {
    const t3 = e[o];
    e[o] = null === (n2 = t3.next) || void 0 === n2 ? void 0 : n2.bind(t3), e[o + 1] = null === (s = t3.error) || void 0 === s ? void 0 : s.bind(t3), e[o + 2] = null === (i = t3.complete) || void 0 === i ? void 0 : i.bind(t3);
  }
  let u2, a, h;
  if (t2 instanceof mu)
    a = lu(t2.firestore, Vu), h = ee(t2._key.path), u2 = {
      next: (n3) => {
        e[o] && e[o](_h(a, t2, n3));
      },
      error: e[o + 1],
      complete: e[o + 2]
    };
  else {
    const n3 = lu(t2, gu);
    a = lu(n3.firestore, Vu), h = n3._query;
    const s2 = new nh(a);
    u2 = {
      next: (t3) => {
        e[o] && e[o](new va(a, s2, n3, t3));
      },
      error: e[o + 1],
      complete: e[o + 2]
    }, Da2(t2._query);
  }
  return function(t3, e2, n3, s2) {
    const i2 = new Vc2(s2), r3 = new ko(e2, i2, n3);
    return t3.asyncQueue.enqueueAndForget(async () => So(await Uc2(t3), r3)), () => {
      i2.Wo(), t3.asyncQueue.enqueueAndForget(async () => Do(await Uc2(t3), r3));
    };
  }(Cu(a), h, c, u2);
}
function dh(t2, e) {
  return zc2(Cu(t2 = lu(t2, Vu)), Pu(e) ? e : {
    next: e
  });
}
function wh(t2, e) {
  return function(t3, e2) {
    const n2 = new Cs();
    return t3.asyncQueue.enqueueAndForget(async () => zo(await Bc2(t3), e2, n2)), n2.promise;
  }(Cu(t2), e);
}
function _h(t2, e, n2) {
  const s = n2.docs.get(e._key), i = new nh(t2);
  return new Pa(t2, i, e._key, s, new Ra2(n2.hasPendingWrites, n2.fromCache), e.converter);
}
var mh = class extends class {
  /** @hideconstructor */
  constructor(t2, e) {
    this._firestore = t2, this._transaction = e, this._dataReader = ea2(t2);
  }
  /**
   * Reads the document referenced by the provided {@link DocumentReference}.
   *
   * @param documentRef - A reference to the document to be read.
   * @returns A `DocumentSnapshot` with the read data.
   */
  get(t2) {
    const e = th(t2, this._firestore), n2 = new Xa2(this._firestore);
    return this._transaction.lookup([e._key]).then((t3) => {
      if (!t3 || 1 !== t3.length)
        return M2();
      const s = t3[0];
      if (s.isFoundDocument())
        return new Ta2(this._firestore, n2, s.key, s, e.converter);
      if (s.isNoDocument())
        return new Ta2(this._firestore, n2, e._key, null, e.converter);
      throw M2();
    });
  }
  set(t2, e, n2) {
    const s = th(t2, this._firestore), i = Ya2(s.converter, e, n2), r2 = na2(this._dataReader, "Transaction.set", s._key, i, null !== s.converter, n2);
    return this._transaction.set(s._key, r2), this;
  }
  update(t2, e, n2, ...s) {
    const i = th(t2, this._firestore);
    let r2;
    return r2 = "string" == typeof (e = getModularInstance(e)) || e instanceof Qu ? ha2(this._dataReader, "Transaction.update", i._key, e, n2, s) : aa2(this._dataReader, "Transaction.update", i._key, e), this._transaction.update(i._key, r2), this;
  }
  /**
   * Deletes the document referred to by the provided {@link DocumentReference}.
   *
   * @param documentRef - A reference to the document to be deleted.
   * @returns This `Transaction` instance. Used for chaining method calls.
   */
  delete(t2) {
    const e = th(t2, this._firestore);
    return this._transaction.delete(e._key), this;
  }
} {
  // This class implements the same logic as the Transaction API in the Lite SDK
  // but is subclassed in order to return its own DocumentSnapshot types.
  /** @hideconstructor */
  constructor(t2, e) {
    super(t2, e), this._firestore = t2;
  }
  /**
   * Reads the document referenced by the provided {@link DocumentReference}.
   *
   * @param documentRef - A reference to the document to be read.
   * @returns A `DocumentSnapshot` with the read data.
   */
  get(t2) {
    const e = th(t2, this._firestore), n2 = new nh(this._firestore);
    return super.get(t2).then((t3) => new Pa(this._firestore, n2, e._key, t3._document, new Ra2(
      /* hasPendingWrites= */
      false,
      /* fromCache= */
      false
    ), e.converter));
  }
};
function gh(t2, e) {
  return Hc2(Cu(t2), (n2) => e(new mh(t2, n2)));
}
function yh() {
  return new sa2("deleteField");
}
function ph() {
  return new ra2("serverTimestamp");
}
function Eh(...t2) {
  return new oa2("arrayUnion", t2);
}
function Th(...t2) {
  return new ca2("arrayRemove", t2);
}
function Ih(t2) {
  return new ua2("increment", t2);
}
function Ah(t2) {
  return Cu(t2 = lu(t2, Vu)), new Za2(t2, (e) => wh(t2, e));
}
var Rh;
!function(t2) {
  v = t2;
}(SDK_VERSION), _registerComponent(new Component(
  "firestore-exp",
  (t2, { options: e }) => {
    const n2 = t2.getProvider("app-exp").getImmediate(), s = new Vu(n2, t2.getProvider("auth-internal"));
    return e = Object.assign({
      useFetchStreams: false
    }, e), s._setSettings(e), s;
  },
  "PUBLIC"
  /* PUBLIC */
)), registerVersion("@firebase/firestore", "0.0.900-exp.f43d0c698", Rh);
export {
  Ja2 as AbstractUserDataWriter,
  Wu as Bytes,
  vu as CACHE_SIZE_UNLIMITED,
  yu as CollectionReference,
  mu as DocumentReference,
  Pa as DocumentSnapshot,
  Qu as FieldPath,
  Gu as FieldValue,
  Vu as FirebaseFirestore,
  D2 as FirestoreError,
  zu as GeoPoint,
  bu as LoadBundleTask,
  gu as Query,
  Ca2 as QueryConstraint,
  ba2 as QueryDocumentSnapshot,
  va as QuerySnapshot,
  Ra2 as SnapshotMetadata,
  W2 as Timestamp,
  mh as Transaction,
  Za2 as WriteBatch,
  lh as addDoc,
  Th as arrayRemove,
  Eh as arrayUnion,
  Ou as clearIndexedDbPersistence,
  pu as collection,
  Eu as collectionGroup,
  hh as deleteDoc,
  yh as deleteField,
  Lu as disableNetwork,
  Tu as doc,
  ju as documentId,
  xu as enableIndexedDbPersistence,
  ku as enableMultiTabIndexedDbPersistence,
  Mu as enableNetwork,
  ja as endAt,
  Qa2 as endBefore,
  Cu as ensureFirestoreConfigured,
  wh as executeWrite,
  eh as getDoc,
  sh as getDocFromCache,
  ih as getDocFromServer,
  rh as getDocs,
  oh as getDocsFromCache,
  ch as getDocsFromServer,
  Du as getFirestore,
  Ih as increment,
  Su as initializeFirestore,
  Ma2 as limit,
  La2 as limitToLast,
  Uu as loadBundle,
  qu as namedQuery,
  fh as onSnapshot,
  dh as onSnapshotsInSync,
  Oa as orderBy,
  Na as query,
  Au as queryEqual,
  Iu as refEqual,
  gh as runTransaction,
  ph as serverTimestamp,
  uh as setDoc,
  x2 as setLogLevel,
  Sa as snapshotEqual,
  qa2 as startAfter,
  Ua2 as startAt,
  Bu as terminate,
  ah as updateDoc,
  _u as useFirestoreEmulator,
  Fu as waitForPendingWrites,
  ka2 as where,
  Ah as writeBatch
};
/*! Bundled license information:

@firebase/webchannel-wrapper/dist/index.esm.js:
  (*! *****************************************************************************
  Copyright (c) Microsoft Corporation.
  
  Permission to use, copy, modify, and/or distribute this software for any
  purpose with or without fee is hereby granted.
  
  THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH
  REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY
  AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,
  INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM
  LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR
  OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
  PERFORMANCE OF THIS SOFTWARE.
  ***************************************************************************** *)

@firebase/firestore/dist/exp/index.browser.esm2017.js:
  (**
   * @license
   * Copyright 2017 Google LLC
   *
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   *   http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *)
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   *   http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *)
  (**
   * @license
   * Copyright 2020 Google LLC
   *
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   *   http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *)
  (**
   * @license
   * Copyright 2019 Google LLC
   *
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   *   http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *)
*/
//# sourceMappingURL=firebase_firestore.js.map
